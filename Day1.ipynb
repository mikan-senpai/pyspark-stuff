{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b94c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef4948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Demo\").master(\"local[2]\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b395718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-LJE0474:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1604ce6fe10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096ac717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e1,babjee,50000,10',\n",
       " 'e2,naveen,40000,20',\n",
       " 'e3,praveen,60000,10',\n",
       " 'e4,sundar,20000,10',\n",
       " 'e5,raheem,80000,30']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create RDD using textFile API\n",
    "rdd = spark.sparkContext.textFile('c:/practice/emp.txt')\n",
    "rdd.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b35f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1,babjee,50000,10\n",
      "e2,naveen,40000,20\n",
      "e3,praveen,60000,10\n",
      "e4,sundar,20000,10\n",
      "e5,raheem,80000,30\n"
     ]
    }
   ],
   "source": [
    "for i in rdd.take(5):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7233efb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d7f30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[633]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the Number of elements in each partition\n",
    "rdd.glom().map(len).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0339af6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e1,babjee,50000,10',\n",
       " 'e2,naveen,40000,20',\n",
       " 'e3,praveen,60000,10',\n",
       " 'e4,sundar,20000,10',\n",
       " 'e5,raheem,80000,30']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create RDD using textFile API and a defined number of partitions\n",
    "rdd = spark.sparkContext.textFile('c:/practice/emp.txt',10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a1b694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the Number of Partitions in the RDD\n",
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "804e2e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 63, 63, 63, 63, 64, 63, 63, 63, 64]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the Number of elements in each partition\n",
    "rdd.glom().map(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5d1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#Create a RDD from a Python List\n",
    "lst = [1,2,3,4,5,6,7]\n",
    "rdd = spark.sparkContext.parallelize(lst)\n",
    "for i in rdd.take(5) : print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c934917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e1,babjee,50000,10\n",
      "e2,naveen,40000,20\n",
      "e3,praveen,60000,10\n",
      "e4,sundar,20000,10\n",
      "e5,raheem,80000,30\n"
     ]
    }
   ],
   "source": [
    "#Create a RDD from local file\n",
    "lst = open('c:/practice/emp.txt').read().splitlines()\n",
    "lst[0:10]\n",
    "rdd = spark.sparkContext.parallelize(lst)\n",
    "for i in rdd.take(5) : print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69c84bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Create RDD from range function\n",
    "lst1 = range(10)\n",
    "rdd = spark.sparkContext.parallelize(lst1)\n",
    "for i in rdd.take(5) : print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a9718a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n",
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|robert| 35|\n",
      "|  Mike| 45|\n",
      "+------+---+\n",
      "\n",
      "Row(name='robert', age=35)\n",
      "Row(name='Mike', age=45)\n"
     ]
    }
   ],
   "source": [
    "#Create RDD from a DataFrame\n",
    "df=spark.createDataFrame(data=(('robert',35),('Mike',45)),schema=('name','age'))\n",
    "df.printSchema()\n",
    "df.show()\n",
    "rdd1= df.rdd\n",
    "type(rdd1)\n",
    "for i in rdd1.take(2) : print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe3886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord =spark.sparkContext.textFile('c:/practice/orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf0dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordItems=spark.sparkContext.textFile('c:/practice/order_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d13f0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f53402a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99',\n",
       " '5,4,897,2,49.98,24.99']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57560409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#project OrderIds\n",
    "mapRdd =ord.map(lambda x :x.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2355d083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4eb2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#project OrderIds and Status\n",
    "maprdd=ord.map(lambda x :(x.split(',')[0], x.split(',')[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e9fcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'CLOSED'),\n",
       " ('2', 'PENDING_PAYMENT'),\n",
       " ('3', 'COMPLETE'),\n",
       " ('4', 'CLOSED'),\n",
       " ('5', 'COMPLETE')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maprdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67d5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine OrderIds and Status with #\n",
    "maprdd=ord.map(lambda x :x.split(',')[0]+\"#\" +x.split(',')[3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7762bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1#CLOSED\n",
      "2#PENDING_PAYMENT\n",
      "3#COMPLETE\n",
      "4#CLOSED\n",
      "5#COMPLETE\n"
     ]
    }
   ],
   "source": [
    "for i in maprdd.take(5):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ed104",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5588a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Order date into yyyy/mm/dd format\n",
    "maprdd = ord.map(lambda x : x.split(',')[1])\\\n",
    ".map(lambda x : x.split(' ')[0].replace('-','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "355c81f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013/07/25', '2013/07/25', '2013/07/25', '2013/07/25', '2013/07/25']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maprdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6079a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create key-value pair with key as Order id and vlue as whole record\n",
    "maprdd = ord.map(lambda x : x.split(',')[0]+\":\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64a28139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1,2013-07-25 00:00:00.0,11599,CLOSED\n",
      "2:2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT\n",
      "3:3,2013-07-25 00:00:00.0,12111,COMPLETE\n",
      "4:4,2013-07-25 00:00:00.0,8827,CLOSED\n",
      "5:5,2013-07-25 00:00:00.0,11318,COMPLETE\n"
     ]
    }
   ],
   "source": [
    "for i in maprdd.take(5):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a22fc288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99',\n",
       " '5,4,897,2,49.98,24.99']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#project all order_item_ids and subtotal\n",
    "ordItems.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "153abd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "maprdd =ordItems.map(lambda x:(x.split(',')[0] , x.split(',')[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd676f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '299.98'),\n",
       " ('2', '199.99'),\n",
       " ('3', '250.0'),\n",
       " ('4', '129.99'),\n",
       " ('5', '49.98')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maprdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0700fbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply user defined function to convert status to lower case\n",
    "\n",
    "ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf3abc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lwcase(str):\n",
    "    return str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53410b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maprdd = ord.map(lambda x :lwcase(x.split(',')[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f0fab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['closed', 'pending_payment', 'complete', 'closed', 'complete']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maprdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0f60720",
   "metadata": {},
   "outputs": [],
   "source": [
    "maprdd =ord.map(lambda x :x.split(',')[3].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15b4b71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['closed', 'pending_payment', 'complete', 'closed', 'complete']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maprdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db33c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat Map \n",
    "#number of words in order file\n",
    "maprdd =ord.flatMap(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20d6f8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2013-07-25 00:00:00.0', '11599', 'CLOSED', '2']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maprdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be043554",
   "metadata": {},
   "outputs": [],
   "source": [
    "maprdd =ord.flatMap(lambda x: x.split(',')).map(lambda w: (w,1)).reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2604bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2013-07-25 00:00:00.0', 143),\n",
       " ('11599', 6),\n",
       " ('CLOSED', 7556),\n",
       " ('256', 11),\n",
       " ('3', 8),\n",
       " ('12111', 7),\n",
       " ('COMPLETE', 22899),\n",
       " ('4', 7),\n",
       " ('8827', 7),\n",
       " ('5', 5),\n",
       " ('6', 5),\n",
       " ('7130', 8),\n",
       " ('7', 9),\n",
       " ('4530', 11),\n",
       " ('2911', 7),\n",
       " ('PROCESSING', 8275),\n",
       " ('10', 3),\n",
       " ('918', 6),\n",
       " ('PAYMENT_REVIEW', 729),\n",
       " ('13', 7),\n",
       " ('14', 10),\n",
       " ('15', 5),\n",
       " ('16', 8),\n",
       " ('17', 6),\n",
       " ('18', 9),\n",
       " ('9488', 8),\n",
       " ('21', 5),\n",
       " ('22', 7),\n",
       " ('333', 7),\n",
       " ('4367', 6),\n",
       " ('24', 6),\n",
       " ('9503', 4),\n",
       " ('26', 6),\n",
       " ('29', 4),\n",
       " ('10039', 11),\n",
       " ('31', 7),\n",
       " ('6983', 7),\n",
       " ('32', 6),\n",
       " ('33', 3),\n",
       " ('5793', 4),\n",
       " ('34', 8),\n",
       " ('4840', 3),\n",
       " ('5649', 3),\n",
       " ('38', 7),\n",
       " ('11586', 10),\n",
       " ('8214', 6),\n",
       " ('40', 8),\n",
       " ('8136', 8),\n",
       " ('9776', 6),\n",
       " ('43', 3),\n",
       " ('44', 7),\n",
       " ('45', 7),\n",
       " ('2636', 7),\n",
       " ('1549', 5),\n",
       " ('8487', 8),\n",
       " ('12186', 5),\n",
       " ('1871', 9),\n",
       " ('5225', 10),\n",
       " ('CANCELED', 1428),\n",
       " ('51', 9),\n",
       " ('4701', 5),\n",
       " ('10628', 8),\n",
       " ('55', 7),\n",
       " ('2052', 8),\n",
       " ('10519', 7),\n",
       " ('57', 7),\n",
       " ('7073', 4),\n",
       " ('58', 10),\n",
       " ('9213', 9),\n",
       " ('8365', 10),\n",
       " ('61', 6),\n",
       " ('62', 5),\n",
       " ('64', 4),\n",
       " ('5579', 12),\n",
       " ('5903', 8),\n",
       " ('68', 4),\n",
       " ('2821', 6),\n",
       " ('SUSPECTED_FRAUD', 1558),\n",
       " ('70', 8),\n",
       " ('11809', 5),\n",
       " ('8646', 5),\n",
       " ('72', 9),\n",
       " ('73', 7),\n",
       " ('662', 10),\n",
       " ('75', 8),\n",
       " ('2505', 6),\n",
       " ('76', 6),\n",
       " ('77', 10),\n",
       " ('78', 3),\n",
       " ('8619', 5),\n",
       " ('79', 7),\n",
       " ('80', 5),\n",
       " ('3007', 10),\n",
       " ('83', 6),\n",
       " ('1265', 9),\n",
       " ('84', 5),\n",
       " ('1485', 8),\n",
       " ('3809', 7),\n",
       " ('89', 9),\n",
       " ('90', 7)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maprdd.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3b8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter\n",
    "#Print the all the all orders which are close or complete and ordered in the year 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f206e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filrdd=ord.filter(lambda x :  x.split(',')[3]in ['COMPLETE','CLOSED'] \\\n",
    "                  and  x.split(',')[1].split('-')[0]=='2013' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea057983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE',\n",
       " '6,2013-07-25 00:00:00.0,7130,COMPLETE',\n",
       " '7,2013-07-25 00:00:00.0,4530,COMPLETE',\n",
       " '12,2013-07-25 00:00:00.0,1837,CLOSED',\n",
       " '15,2013-07-25 00:00:00.0,2568,COMPLETE',\n",
       " '17,2013-07-25 00:00:00.0,2667,COMPLETE',\n",
       " '18,2013-07-25 00:00:00.0,1205,CLOSED']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filrdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b68002c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13624"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filrdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b690368",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =spark.sparkContext.parallelize\\\n",
    "([(\"a\",[1,2,3,4]) ,(\"b\",[2,4,5,6]) , (\"a\",[1,2,3,4,5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc7f9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapValues api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1000c676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 4), ('b', 4), ('a', 5)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapValues(len).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7aea81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 10), ('b', 17), ('a', 15)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapValues(sum).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60d49f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user defined function\n",
    "def f(num):return len(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15503ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 4), ('b', 4), ('a', 5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.mapValues(f).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a02c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join api\n",
    "#join\n",
    "#left outer join\n",
    "#right outer join\n",
    "#full outer join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f856e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = spark.sparkContext.textFile('c:/practice/orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df682c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5688ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordItems = spark.sparkContext.textFile('c:/practice/order_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0aedd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99',\n",
       " '5,4,897,2,49.98,24.99']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a76dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the subtotal for each customerid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ea54cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordMap= ord.map(lambda x:(x.split(',')[0] , x.split(',')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f480243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '11599'), ('2', '256'), ('3', '12111'), ('4', '8827'), ('5', '11318')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordMap.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e230c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordItemMap = ordItems.map(lambda x : (x.split(',')[1] ,x.split(',')[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5967ad7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '299.98'),\n",
       " ('2', '199.99'),\n",
       " ('2', '250.0'),\n",
       " ('2', '129.99'),\n",
       " ('4', '49.98')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItemMap.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e04ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinRdd =ordMap.join(ordItemMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ff67fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4', ('8827', '49.98')),\n",
       " ('4', ('8827', '299.95')),\n",
       " ('4', ('8827', '150.0')),\n",
       " ('4', ('8827', '199.92')),\n",
       " ('5', ('11318', '299.98'))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc70a7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8827', '49.98'),\n",
       " ('8827', '299.95'),\n",
       " ('8827', '150.0'),\n",
       " ('8827', '199.92'),\n",
       " ('11318', '299.98')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinRdd.map(lambda x : x[1]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a52fd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8827,49.98', '8827,299.95', '8827,150.0', '8827,199.92', '11318,299.98']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinRdd.map(lambda x :x[1][0]+','+ x[1][1]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "286090ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8827,49.98'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinRdd.map(lambda x :x[1][0]+','+ x[1][1]).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a6dfca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empRdd=spark.sparkContext.textFile('c:/practice/emp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "362f869d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e1,babjee,50000,10',\n",
       " 'e2,naveen,40000,20',\n",
       " 'e3,praveen,60000,10',\n",
       " 'e4,sundar,20000,10',\n",
       " 'e5,raheem,80000,30']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "745fa45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "deptRdd=spark.sparkContext.textFile('c:/practice/dept.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eae712d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10,Accounts', '20,hr', '40,it']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deptRdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dd4e9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapEmp =empRdd.map(lambda x:(x.split(',')[3],x.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f3662d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 'babjee'),\n",
       " ('20', 'naveen'),\n",
       " ('10', 'praveen'),\n",
       " ('10', 'sundar'),\n",
       " ('30', 'raheem')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapEmp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ca2029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapDept=deptRdd.map(lambda x:(x.split(',')[0],x.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "267a9a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 'Accounts'), ('20', 'hr'), ('40', 'it')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapDept.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e4201f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinRdd =mapEmp.join(mapDept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2140fefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', ('babjee', 'Accounts')),\n",
       " ('10', ('praveen', 'Accounts')),\n",
       " ('10', ('sundar', 'Accounts')),\n",
       " ('20', ('naveen', 'hr'))]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joinRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "76683785",
   "metadata": {},
   "outputs": [],
   "source": [
    "empleftRdd=mapEmp.leftOuterJoin(mapDept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ad4d3fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', ('babjee', 'Accounts')),\n",
       " ('10', ('praveen', 'Accounts')),\n",
       " ('10', ('sundar', 'Accounts')),\n",
       " ('20', ('naveen', 'hr')),\n",
       " ('30', ('raheem', None)),\n",
       " ('30', ('suil', None))]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empleftRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0afd0214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 'babjee', 'Accounts'),\n",
       " ('10', 'praveen', 'Accounts'),\n",
       " ('10', 'sundar', 'Accounts'),\n",
       " ('20', 'naveen', 'hr'),\n",
       " ('30', 'raheem', None),\n",
       " ('30', 'suil', None)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empleftRdd.map(lambda x : (x[0] , x[1][0] ,x[1][1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "32b5af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "emprightRdd=mapEmp.rightOuterJoin(mapDept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ea37f7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', ('babjee', 'Accounts')),\n",
       " ('10', ('praveen', 'Accounts')),\n",
       " ('10', ('sundar', 'Accounts')),\n",
       " ('20', ('naveen', 'hr')),\n",
       " ('40', (None, 'it'))]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emprightRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9e41ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "empFullRdd=emprightRdd=mapEmp.fullOuterJoin(mapDept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7ae1fd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', ('babjee', 'Accounts')),\n",
       " ('10', ('praveen', 'Accounts')),\n",
       " ('10', ('sundar', 'Accounts')),\n",
       " ('20', ('naveen', 'hr')),\n",
       " ('40', (None, 'it')),\n",
       " ('30', ('raheem', None)),\n",
       " ('30', ('suil', None))]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empFullRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43b8d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c5457e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spark.sparkContext.parallelize([('a',2 ), ('b',4)])\n",
    "y = spark.sparkContext.parallelize([('a',3 ), ('b',5)])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ffe36e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = x.cogroup(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "51d2aecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x28049ad7110>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x28049228210>)),\n",
       " ('a',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x28049c1e010>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x28049c1df90>))]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "77c4cb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b [[4], [5]]\n",
      "a [[2], [3]]\n"
     ]
    }
   ],
   "source": [
    "for i, j in xy.collect():\n",
    "    print(i, list(map(list,j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "657f3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33624bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2449c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (2, 1), (3, 1), (2, 2), (2, 3), (3, 2), (3, 3)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.cartesian(rdd).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a631a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3, 2), (3, 3)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rdd.cartesian(rdd).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df000dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Aggriation (Actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba7cf8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4353f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99',\n",
       " '5,4,897,2,49.98,24.99']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "329365d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the Number of orde which are closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b7c688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordfilter = ord.filter(lambda x : x.split(',')[3]=='CLOSED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd23b9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7556"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordfilter.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af8cef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the total quantity sold for order id 1-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be77edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbabcfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99',\n",
       " '5,4,897,2,49.98,24.99']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97bb0bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.filter(lambda x : int(x.split(',')[1]) <11).\\\n",
    "map(lambda x : int(x.split(',')[3])).reduce(lambda x , y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8575a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e1d919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.filter(lambda x : int(x.split(',')[1]) <11).\\\n",
    "map(lambda x : int(x.split(',')[3])).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76ab8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For given order 10  find the maximum subtotal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84aa9b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99',\n",
       " '5,4,897,2,49.98,24.99']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6608a182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24,10,1073,1,199.99,199.99',\n",
       " '25,10,1014,2,99.96,49.98',\n",
       " '26,10,403,1,129.99,129.99',\n",
       " '27,10,917,1,21.99,21.99',\n",
       " '28,10,1073,1,199.99,199.99']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.filter(lambda x : int(x.split(',')[1]) ==10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53cd0e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28,10,1073,1,199.99,199.99'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.filter(lambda x : int(x.split(',')[1]) ==10).\\\n",
    "reduce(lambda a,b : a if (float(a .split(',')[4]) ) > \\\n",
    "       (float(b .split(',')[4]) ) else b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff50d90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.99"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.filter(lambda x : int(x.split(',')[1]) ==10).\\\n",
    "map(lambda x : float(x.split(',')[4])).reduce(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e536220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group By key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2155d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find total revenue for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9cdcf823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99',\n",
       " '5,4,897,2,49.98,24.99']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a3020cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter =ordItems.filter(lambda x:len(x.split(',')[2])== 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e603d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "037119b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordGrp = ordItems.map(lambda x : ( int(x.split(',')[2]) , \\\n",
    "                                  float(x.split(',')[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a16fd16f",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 38.0 failed 1 times, most recent failure: Lost task 0.0 in stage 38.0 (TID 66) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1237, in process\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 3983, in combineLocally\n    merger.mergeValues(iterator)\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\shuffle.py\", line 258, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\n           ^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\nTypeError: 'float' object is not iterable\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1237, in process\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 3983, in combineLocally\n    merger.mergeValues(iterator)\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\shuffle.py\", line 258, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\n           ^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\nTypeError: 'float' object is not iterable\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ordGrp\u001b[38;5;241m.\u001b[39mreduceByKey(\u001b[38;5;28msum\u001b[39m)\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m, takeUpToNumLeft, p)\n\u001b[0;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc(), mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd, partitions)\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 38.0 failed 1 times, most recent failure: Lost task 0.0 in stage 38.0 (TID 66) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1237, in process\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 3983, in combineLocally\n    merger.mergeValues(iterator)\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\shuffle.py\", line 258, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\n           ^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\nTypeError: 'float' object is not iterable\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1237, in process\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 3983, in combineLocally\n    merger.mergeValues(iterator)\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\shuffle.py\", line 258, in mergeValues\n    d[k] = comb(d[k], v) if k in d else creator(v)\n           ^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\nTypeError: 'float' object is not iterable\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\r\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\r\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "ordGrp.reduceByKey(sum).take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1685b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08245c0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 33.0 failed 1 times, most recent failure: Lost task 0.0 in stage 33.0 (TID 59) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ordGrp\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m, takeUpToNumLeft, p)\n\u001b[0;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc(), mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd, partitions)\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 33.0 failed 1 times, most recent failure: Lost task 0.0 in stage 33.0 (TID 59) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "ordGrp.take(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27cae333",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 54) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m, takeUpToNumLeft, p)\n\u001b[0;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc(), mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd, partitions)\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 30.0 failed 1 times, most recent failure: Lost task 0.0 in stage 30.0 (TID 54) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\4211828731.py\", line 2, in <lambda>\nValueError: invalid literal for int() with base 10: '299.98'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "result.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f52b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apple', <pyspark.resultiterable.ResultIterable object at 0x00000191FAB5C910>), ('banana', <pyspark.resultiterable.ResultIterable object at 0x00000191FBD2C2D0>), ('orange', <pyspark.resultiterable.ResultIterable object at 0x0000019180D1F610>)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sales_data = [(\"apple\", 3), (\"banana\", 5), (\"orange\", 2), (\"apple\", 4), (\"banana\", 3), (\"orange\", 6)] \n",
    "sales_rdd = spark.sparkContext.parallelize(sales_data) \n",
    "\n",
    "# Group sales data by product using groupByKey \n",
    "grouped_sales_rdd = sales_rdd.groupByKey()\n",
    "\n",
    "# Collect and print the results \n",
    "print(grouped_sales_rdd.collect()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0af5c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce By Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a1ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5e5aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize( [('a',10),('b',20),('a',20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a490c81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 20), ('a', 30)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "rdd.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb0fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total revenue for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec6ac28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,1,957,1,299.98,299.98',\n",
       " '2,2,1073,1,199.99,199.99',\n",
       " '3,2,502,5,250.0,50.0',\n",
       " '4,2,403,1,129.99,129.99']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651d0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordGrp = ordItems.map(lambda x : ( int(x.split(',')[1]),float(x.split(',')[4])  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b46a2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 299.98), (2, 199.99), (2, 250.0), (2, 129.99), (4, 49.98)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordGrp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31808c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(502, 3147800.0),\n",
       " (1014, 2888993.9399996493),\n",
       " (926, 14870.699999999972),\n",
       " (134, 20025.0),\n",
       " (276, 29398.809999999947),\n",
       " (1004, 6929653.499999708),\n",
       " (828, 28982.939999999948),\n",
       " (810, 16031.97999999997),\n",
       " (906, 22865.84999999997),\n",
       " (924, 14151.149999999976),\n",
       " (886, 21766.289999999954),\n",
       " (572, 35191.19999999998),\n",
       " (778, 21116.549999999963),\n",
       " (278, 36576.86999999999),\n",
       " (642, 27840.0),\n",
       " (804, 18810.589999999967),\n",
       " (564, 27210.0),\n",
       " (792, 12951.359999999982),\n",
       " (172, 27210.0),\n",
       " (822, 38391.99999999997),\n",
       " (818, 41415.37),\n",
       " (116, 44585.09000000002),\n",
       " (282, 27127.519999999957),\n",
       " (728, 61490.0),\n",
       " (44, 56330.61000000003),\n",
       " (666, 9349.149999999987),\n",
       " (858, 11799.40999999999),\n",
       " (24, 18477.689999999988),\n",
       " (982, 8999.39999999999),\n",
       " (652, 7539.419999999991),\n",
       " (724, 22700.0),\n",
       " (306, 17638.039999999997),\n",
       " (646, 20697.929999999997),\n",
       " (730, 15600.0),\n",
       " (216, 12096.0),\n",
       " (258, 19567.93999999999),\n",
       " (786, 11699.34999999999),\n",
       " (78, 18598.139999999992),\n",
       " (364, 10799.639999999994),\n",
       " (58, 8699.709999999995),\n",
       " (768, 10199.659999999994),\n",
       " (226, 5999.899999999999),\n",
       " (208, 29999.85000000001),\n",
       " (60, 9999.9),\n",
       " (860, 6599.8899999999985),\n",
       " (957, 4118425.419999785),\n",
       " (1073, 3099844.999999871),\n",
       " (403, 2891757.5399998166),\n",
       " (897, 20566.769999999964),\n",
       " (365, 4421143.019999638),\n",
       " (191, 3667633.1999997487),\n",
       " (917, 20450.69999999996),\n",
       " (627, 1269082.649999932),\n",
       " (93, 20866.649999999965),\n",
       " (37, 27327.18999999996),\n",
       " (825, 25751.949999999953),\n",
       " (821, 44243.490000000005),\n",
       " (775, 8871.11999999998),\n",
       " (835, 29686.71999999996),\n",
       " (565, 67830.0),\n",
       " (135, 19426.0),\n",
       " (797, 15993.10999999997),\n",
       " (235, 29601.53999999995),\n",
       " (905, 22366.04999999996),\n",
       " (771, 34671.32999999999),\n",
       " (977, 29930.019999999968),\n",
       " (823, 47206.920000000006),\n",
       " (567, 21475.0),\n",
       " (273, 22252.049999999967),\n",
       " (703, 17731.12999999997),\n",
       " (893, 22166.12999999996),\n",
       " (249, 46559.58999999997),\n",
       " (793, 13311.11999999997),\n",
       " (885, 23940.419999999955),\n",
       " (725, 8208.0),\n",
       " (625, 12599.36999999999),\n",
       " (981, 17919.0),\n",
       " (691, 11598.549999999994),\n",
       " (705, 8399.299999999988),\n",
       " (715, 8839.319999999989),\n",
       " (647, 9449.299999999988),\n",
       " (743, 10369.38999999999),\n",
       " (19, 7999.35999999999),\n",
       " (35, 10399.34999999999),\n",
       " (607, 19249.230000000007),\n",
       " (295, 18690.649999999994),\n",
       " (671, 13649.34999999999),\n",
       " (305, 13333.0),\n",
       " (251, 19077.879999999994),\n",
       " (311, 5937.299999999995),\n",
       " (773, 13499.45999999999),\n",
       " (777, 16637.919999999987),\n",
       " (677, 19298.069999999992),\n",
       " (359, 20597.939999999995),\n",
       " (203, 12799.679999999995),\n",
       " (1059, 13999.599999999993),\n",
       " (127, 8909.729999999996),\n",
       " (845, 10799.639999999994),\n",
       " (303, 13999.649999999994),\n",
       " (61, 8399.719999999996)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordGrp.reduceByKey(add).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "968b956d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 299.98),\n",
       " (2, 579.98),\n",
       " (4, 699.85),\n",
       " (5, 1129.8600000000001),\n",
       " (7, 579.9200000000001),\n",
       " (8, 729.8399999999999),\n",
       " (9, 599.96),\n",
       " (10, 651.9200000000001),\n",
       " (11, 919.79),\n",
       " (12, 1299.8700000000001),\n",
       " (13, 127.96),\n",
       " (14, 549.94),\n",
       " (15, 925.9100000000001),\n",
       " (16, 419.93),\n",
       " (17, 694.84),\n",
       " (18, 449.96000000000004),\n",
       " (19, 699.96),\n",
       " (20, 879.8599999999999),\n",
       " (21, 372.91),\n",
       " (23, 299.98),\n",
       " (24, 829.97),\n",
       " (25, 399.98),\n",
       " (27, 749.97),\n",
       " (28, 1159.9),\n",
       " (29, 1109.85),\n",
       " (30, 100.0),\n",
       " (31, 499.95),\n",
       " (33, 659.89),\n",
       " (34, 299.98),\n",
       " (35, 129.99),\n",
       " (36, 799.96),\n",
       " (37, 159.95),\n",
       " (38, 359.96000000000004),\n",
       " (39, 199.99),\n",
       " (41, 327.88),\n",
       " (42, 739.9200000000001),\n",
       " (43, 529.96),\n",
       " (44, 399.98),\n",
       " (45, 499.84999999999997),\n",
       " (46, 229.95),\n",
       " (48, 99.96),\n",
       " (49, 549.95),\n",
       " (50, 429.97),\n",
       " (51, 449.98),\n",
       " (52, 399.84000000000003),\n",
       " (56, 699.89),\n",
       " (57, 637.9),\n",
       " (58, 799.94),\n",
       " (59, 619.95),\n",
       " (61, 639.92),\n",
       " (62, 1149.94),\n",
       " (63, 899.9200000000001),\n",
       " (64, 659.97),\n",
       " (65, 299.98),\n",
       " (66, 679.94),\n",
       " (67, 150.0),\n",
       " (68, 299.98),\n",
       " (69, 239.96),\n",
       " (70, 629.96),\n",
       " (71, 659.92),\n",
       " (72, 463.9200000000001),\n",
       " (73, 1279.65),\n",
       " (74, 119.98),\n",
       " (75, 779.97),\n",
       " (77, 729.89),\n",
       " (81, 649.8299999999999),\n",
       " (83, 199.99),\n",
       " (84, 1499.8700000000001),\n",
       " (87, 119.97),\n",
       " (88, 279.93),\n",
       " (91, 699.9300000000001),\n",
       " (92, 199.92),\n",
       " (93, 99.96),\n",
       " (94, 739.9100000000001),\n",
       " (95, 199.95),\n",
       " (96, 529.9300000000001),\n",
       " (97, 124.95),\n",
       " (98, 229.99),\n",
       " (99, 1099.93),\n",
       " (100, 549.94),\n",
       " (101, 899.94),\n",
       " (103, 829.9200000000001),\n",
       " (104, 549.95),\n",
       " (105, 429.94000000000005),\n",
       " (106, 99.99),\n",
       " (107, 1039.95),\n",
       " (110, 594.93),\n",
       " (111, 249.9),\n",
       " (112, 979.8800000000001),\n",
       " (113, 619.87),\n",
       " (114, 239.96),\n",
       " (115, 599.96),\n",
       " (116, 795.91),\n",
       " (117, 785.88),\n",
       " (118, 309.98),\n",
       " (119, 485.88),\n",
       " (120, 809.96),\n",
       " (121, 1029.93),\n",
       " (122, 939.9000000000001),\n",
       " (123, 529.94),\n",
       " (124, 399.98),\n",
       " (127, 579.97),\n",
       " (129, 249.9),\n",
       " (130, 629.9200000000001),\n",
       " (131, 824.9100000000001),\n",
       " (132, 614.92),\n",
       " (133, 639.9100000000001),\n",
       " (134, 59.99),\n",
       " (135, 209.97),\n",
       " (136, 299.98),\n",
       " (137, 599.9),\n",
       " (139, 509.95000000000005),\n",
       " (140, 1249.9),\n",
       " (141, 289.96),\n",
       " (142, 129.99),\n",
       " (143, 1139.9),\n",
       " (145, 289.92),\n",
       " (146, 629.95),\n",
       " (147, 429.96000000000004),\n",
       " (148, 479.99),\n",
       " (149, 429.87),\n",
       " (150, 129.99),\n",
       " (151, 325.96000000000004),\n",
       " (152, 577.88),\n",
       " (154, 799.85),\n",
       " (155, 119.98),\n",
       " (156, 49.98),\n",
       " (157, 199.98),\n",
       " (158, 399.98),\n",
       " (159, 1033.81),\n",
       " (160, 199.98),\n",
       " (161, 749.97),\n",
       " (162, 1029.93),\n",
       " (163, 159.94),\n",
       " (164, 1369.81),\n",
       " (165, 1333.84),\n",
       " (166, 619.9300000000001),\n",
       " (167, 919.94),\n",
       " (168, 699.94),\n",
       " (170, 629.89),\n",
       " (171, 1239.87),\n",
       " (172, 819.9300000000001),\n",
       " (173, 139.96),\n",
       " (174, 659.9100000000001),\n",
       " (175, 419.95000000000005),\n",
       " (177, 799.9100000000001),\n",
       " (178, 449.96000000000004),\n",
       " (179, 239.96),\n",
       " (180, 1029.9),\n",
       " (181, 514.94),\n",
       " (182, 399.98),\n",
       " (184, 699.88),\n",
       " (185, 539.85),\n",
       " (186, 699.96),\n",
       " (188, 1299.91),\n",
       " (189, 729.9100000000001),\n",
       " (190, 859.9200000000001),\n",
       " (191, 39.99),\n",
       " (192, 1151.93),\n",
       " (193, 1149.93),\n",
       " (194, 699.9200000000001),\n",
       " (195, 577.85),\n",
       " (196, 239.96),\n",
       " (197, 379.99),\n",
       " (198, 399.96),\n",
       " (200, 959.86),\n",
       " (201, 449.82),\n",
       " (202, 195.99),\n",
       " (204, 439.90999999999997),\n",
       " (205, 459.97),\n",
       " (206, 729.96),\n",
       " (207, 993.8900000000001),\n",
       " (208, 129.99),\n",
       " (209, 939.9300000000001),\n",
       " (211, 369.94),\n",
       " (212, 159.96),\n",
       " (213, 699.9300000000001),\n",
       " (214, 689.82),\n",
       " (215, 199.99),\n",
       " (216, 794.9000000000001),\n",
       " (219, 349.96),\n",
       " (220, 931.95),\n",
       " (221, 1059.91),\n",
       " (222, 519.9399999999999),\n",
       " (223, 779.89),\n",
       " (224, 39.99),\n",
       " (225, 529.97),\n",
       " (226, 919.9300000000001),\n",
       " (227, 495.92999999999995),\n",
       " (228, 799.8700000000001),\n",
       " (229, 709.9),\n",
       " (230, 100.0),\n",
       " (231, 559.9300000000001),\n",
       " (232, 351.96000000000004),\n",
       " (234, 89.97),\n",
       " (235, 399.98),\n",
       " (236, 739.9100000000001),\n",
       " (237, 799.9100000000001),\n",
       " (238, 713.8900000000001),\n",
       " (239, 829.8800000000001),\n",
       " (240, 829.86),\n",
       " (241, 739.95),\n",
       " (242, 329.97),\n",
       " (243, 1179.89),\n",
       " (244, 679.9100000000001),\n",
       " (245, 399.98),\n",
       " (246, 1007.9300000000001),\n",
       " (247, 999.9200000000001),\n",
       " (248, 299.90999999999997),\n",
       " (249, 899.97),\n",
       " (250, 479.92),\n",
       " (251, 129.99),\n",
       " (252, 499.96000000000004),\n",
       " (253, 649.95),\n",
       " (254, 469.98),\n",
       " (255, 879.81),\n",
       " (256, 589.9100000000001),\n",
       " (257, 509.94000000000005),\n",
       " (259, 409.94000000000005),\n",
       " (260, 449.98),\n",
       " (262, 879.8599999999999),\n",
       " (263, 100.0),\n",
       " (264, 899.9200000000001),\n",
       " (265, 629.94),\n",
       " (266, 199.99),\n",
       " (267, 299.97),\n",
       " (268, 239.96),\n",
       " (269, 150.0),\n",
       " (271, 889.87),\n",
       " (272, 191.96),\n",
       " (273, 629.96),\n",
       " (274, 459.96000000000004),\n",
       " (275, 1029.8899999999999),\n",
       " (277, 209.97000000000003),\n",
       " (278, 735.88),\n",
       " (279, 199.98),\n",
       " (280, 129.99),\n",
       " (281, 989.8500000000001),\n",
       " (282, 299.95),\n",
       " (283, 569.86),\n",
       " (284, 1349.8300000000002),\n",
       " (285, 329.98),\n",
       " (286, 389.97),\n",
       " (287, 1089.89),\n",
       " (288, 99.99),\n",
       " (289, 1229.9),\n",
       " (290, 265.91999999999996),\n",
       " (292, 1299.8600000000001),\n",
       " (293, 419.94000000000005),\n",
       " (294, 609.84),\n",
       " (295, 199.95),\n",
       " (296, 139.96),\n",
       " (297, 674.88),\n",
       " (299, 39.99),\n",
       " (300, 544.96),\n",
       " (301, 439.97),\n",
       " (302, 479.95000000000005),\n",
       " (303, 449.99),\n",
       " (304, 1019.9000000000001),\n",
       " (305, 44.99),\n",
       " (306, 229.98000000000002),\n",
       " (307, 849.9200000000001),\n",
       " (308, 539.91),\n",
       " (311, 1045.81),\n",
       " (312, 374.95000000000005),\n",
       " (313, 179.94),\n",
       " (314, 744.95),\n",
       " (315, 809.88),\n",
       " (316, 129.99),\n",
       " (318, 129.99),\n",
       " (319, 319.91999999999996),\n",
       " (320, 329.98),\n",
       " (321, 299.95),\n",
       " (323, 959.84),\n",
       " (324, 849.9),\n",
       " (325, 277.9),\n",
       " (326, 319.94),\n",
       " (327, 839.9200000000001),\n",
       " (328, 484.93),\n",
       " (330, 709.9000000000001),\n",
       " (332, 649.94),\n",
       " (333, 689.94),\n",
       " (334, 599.95),\n",
       " (335, 1199.8200000000002),\n",
       " (336, 299.98),\n",
       " (337, 399.9),\n",
       " (338, 1099.8600000000001),\n",
       " (339, 745.9100000000001),\n",
       " (342, 119.98),\n",
       " (343, 579.99),\n",
       " (345, 1099.94),\n",
       " (347, 150.0),\n",
       " (348, 199.99),\n",
       " (349, 929.9300000000001),\n",
       " (350, 829.85),\n",
       " (351, 1043.8400000000001),\n",
       " (352, 1159.89),\n",
       " (353, 559.86),\n",
       " (354, 299.98),\n",
       " (355, 549.88),\n",
       " (356, 589.9),\n",
       " (357, 227.98000000000002),\n",
       " (358, 599.85),\n",
       " (359, 863.89),\n",
       " (360, 809.83),\n",
       " (362, 929.96),\n",
       " (363, 999.9300000000001),\n",
       " (364, 449.98),\n",
       " (365, 129.99),\n",
       " (366, 509.95000000000005),\n",
       " (367, 999.8600000000001),\n",
       " (368, 709.9000000000001),\n",
       " (370, 359.94),\n",
       " (372, 429.97),\n",
       " (373, 619.96),\n",
       " (375, 94.99),\n",
       " (376, 789.9200000000001),\n",
       " (377, 199.99),\n",
       " (378, 401.93),\n",
       " (381, 99.95),\n",
       " (382, 699.95),\n",
       " (383, 529.9300000000001),\n",
       " (384, 1039.9),\n",
       " (385, 739.9000000000001),\n",
       " (386, 549.9200000000001),\n",
       " (387, 249.9),\n",
       " (388, 119.97),\n",
       " (389, 699.81),\n",
       " (390, 719.9300000000001),\n",
       " (391, 129.99),\n",
       " (392, 1209.84),\n",
       " (393, 299.98),\n",
       " (394, 50.0),\n",
       " (395, 120.0),\n",
       " (396, 283.0),\n",
       " (397, 263.97),\n",
       " (398, 1049.94),\n",
       " (399, 1259.8700000000001),\n",
       " (401, 129.99),\n",
       " (402, 799.82),\n",
       " (403, 1029.8600000000001),\n",
       " (404, 1209.8300000000002),\n",
       " (405, 699.84),\n",
       " (407, 379.89),\n",
       " (408, 59.99),\n",
       " (409, 229.98000000000002),\n",
       " (410, 499.95),\n",
       " (411, 699.9300000000001),\n",
       " (413, 839.8100000000001),\n",
       " (414, 959.9300000000001),\n",
       " (415, 277.97),\n",
       " (416, 199.99),\n",
       " (417, 1379.88),\n",
       " (418, 579.97),\n",
       " (419, 899.94),\n",
       " (421, 399.98),\n",
       " (422, 599.9),\n",
       " (423, 549.88),\n",
       " (424, 179.97),\n",
       " (425, 99.96),\n",
       " (427, 879.8400000000001),\n",
       " (428, 639.95),\n",
       " (429, 564.91),\n",
       " (430, 899.9100000000001),\n",
       " (431, 639.94),\n",
       " (432, 253.96),\n",
       " (433, 150.0),\n",
       " (436, 629.9000000000001),\n",
       " (437, 849.9300000000001),\n",
       " (438, 119.98),\n",
       " (441, 1129.88),\n",
       " (442, 1229.91),\n",
       " (443, 899.94),\n",
       " (444, 399.98),\n",
       " (446, 399.98),\n",
       " (447, 299.98),\n",
       " (449, 659.97),\n",
       " (450, 50.0),\n",
       " (451, 1079.82),\n",
       " (453, 399.98),\n",
       " (454, 199.99),\n",
       " (455, 819.9000000000001),\n",
       " (456, 699.86),\n",
       " (458, 639.87),\n",
       " (459, 299.96000000000004),\n",
       " (461, 399.98),\n",
       " (462, 599.97),\n",
       " (463, 829.9200000000001),\n",
       " (465, 359.94),\n",
       " (466, 899.94),\n",
       " (467, 759.84),\n",
       " (468, 724.95),\n",
       " (470, 499.84),\n",
       " (471, 169.98000000000002),\n",
       " (472, 589.97),\n",
       " (473, 849.88),\n",
       " (474, 774.8199999999999),\n",
       " (475, 649.89),\n",
       " (476, 199.99),\n",
       " (477, 1249.91),\n",
       " (478, 199.99),\n",
       " (479, 749.96),\n",
       " (480, 609.9300000000001),\n",
       " (481, 100.0),\n",
       " (482, 30.0),\n",
       " (483, 659.9200000000001),\n",
       " (484, 599.96),\n",
       " (485, 1159.94),\n",
       " (486, 1179.8600000000001),\n",
       " (487, 759.95),\n",
       " (488, 299.98),\n",
       " (489, 299.98),\n",
       " (490, 459.97),\n",
       " (491, 299.99),\n",
       " (492, 1029.93),\n",
       " (493, 1129.94),\n",
       " (494, 279.93),\n",
       " (495, 929.9200000000001),\n",
       " (496, 441.95000000000005),\n",
       " (497, 44.97),\n",
       " (498, 429.97),\n",
       " (499, 599.97),\n",
       " (500, 589.9100000000001),\n",
       " (501, 199.95),\n",
       " (502, 31.98),\n",
       " (503, 399.98),\n",
       " (504, 839.89),\n",
       " (505, 199.92),\n",
       " (506, 939.95),\n",
       " (508, 934.9100000000001),\n",
       " (509, 849.9000000000001),\n",
       " (510, 849.9100000000001),\n",
       " (511, 469.90999999999997),\n",
       " (512, 459.97),\n",
       " (513, 579.94),\n",
       " (515, 399.98),\n",
       " (516, 729.97),\n",
       " (517, 1209.91),\n",
       " (518, 299.98),\n",
       " (519, 349.93),\n",
       " (520, 499.98),\n",
       " (521, 909.8600000000001),\n",
       " (522, 369.98),\n",
       " (524, 439.88),\n",
       " (525, 644.9100000000001),\n",
       " (526, 129.99),\n",
       " (527, 529.9000000000001),\n",
       " (528, 529.97),\n",
       " (529, 889.9200000000001),\n",
       " (530, 879.95),\n",
       " (531, 499.9),\n",
       " (532, 759.86),\n",
       " (534, 50.0),\n",
       " (535, 749.9300000000001),\n",
       " (536, 969.88),\n",
       " (537, 849.96),\n",
       " (538, 1119.8600000000001),\n",
       " (539, 499.94000000000005),\n",
       " (540, 609.9300000000001),\n",
       " (541, 299.98),\n",
       " (542, 509.95000000000005),\n",
       " (543, 189.98000000000002),\n",
       " (544, 529.97),\n",
       " (545, 449.95),\n",
       " (546, 674.94),\n",
       " (547, 629.87),\n",
       " (548, 409.98),\n",
       " (549, 889.9300000000001),\n",
       " (550, 479.95000000000005),\n",
       " (551, 469.94),\n",
       " (552, 49.98),\n",
       " (554, 250.0),\n",
       " (555, 719.94),\n",
       " (556, 629.96),\n",
       " (557, 744.9200000000001),\n",
       " (558, 399.98),\n",
       " (560, 411.98),\n",
       " (561, 100.0),\n",
       " (562, 679.97),\n",
       " (563, 329.98),\n",
       " (565, 374.9),\n",
       " (567, 199.97000000000003),\n",
       " (568, 689.88),\n",
       " (571, 539.9200000000001),\n",
       " (572, 529.97),\n",
       " (575, 309.89),\n",
       " (577, 159.98),\n",
       " (579, 463.96000000000004),\n",
       " (580, 1199.91),\n",
       " (581, 599.97),\n",
       " (582, 699.94),\n",
       " (583, 714.8100000000001),\n",
       " (584, 199.99),\n",
       " (585, 189.98000000000002),\n",
       " (586, 249.96),\n",
       " (587, 899.87),\n",
       " (589, 829.95),\n",
       " (591, 51.99),\n",
       " (592, 869.9000000000001),\n",
       " (593, 609.94),\n",
       " (594, 599.98),\n",
       " (595, 859.9100000000001),\n",
       " (596, 729.96),\n",
       " (599, 1024.93),\n",
       " (600, 937.78),\n",
       " (601, 130.0),\n",
       " (602, 689.85),\n",
       " (603, 129.99),\n",
       " (604, 279.93),\n",
       " (605, 399.98),\n",
       " (607, 819.84),\n",
       " (608, 199.99),\n",
       " (609, 629.96),\n",
       " (611, 599.8),\n",
       " (613, 393.91999999999996),\n",
       " (614, 1499.8700000000001),\n",
       " (615, 267.99),\n",
       " (616, 159.97),\n",
       " (618, 739.9),\n",
       " (619, 573.86),\n",
       " (620, 249.9),\n",
       " (621, 1189.79),\n",
       " (622, 939.9200000000001),\n",
       " (623, 239.96),\n",
       " (624, 429.97),\n",
       " (625, 769.9300000000001),\n",
       " (626, 259.94),\n",
       " (627, 959.9100000000001),\n",
       " (628, 716.83),\n",
       " (629, 280.0),\n",
       " (630, 359.98),\n",
       " (631, 1199.91),\n",
       " (632, 199.99),\n",
       " (633, 499.98),\n",
       " (634, 199.99),\n",
       " (636, 1119.88),\n",
       " (637, 459.97),\n",
       " (638, 229.98000000000002),\n",
       " (639, 659.94),\n",
       " (640, 299.97),\n",
       " (641, 299.98),\n",
       " (643, 599.97),\n",
       " (644, 749.9000000000001),\n",
       " (645, 499.94),\n",
       " (646, 959.94),\n",
       " (647, 983.9000000000001),\n",
       " (648, 869.85),\n",
       " (649, 249.97),\n",
       " (650, 599.97),\n",
       " (651, 649.96),\n",
       " (652, 59.99),\n",
       " (653, 249.9),\n",
       " (654, 759.9300000000001),\n",
       " (655, 579.98),\n",
       " (656, 629.86),\n",
       " (657, 719.88),\n",
       " (659, 1049.92),\n",
       " (660, 929.9100000000001),\n",
       " (661, 749.9200000000001),\n",
       " (662, 329.91),\n",
       " (663, 599.97),\n",
       " (664, 649.98),\n",
       " (665, 289.95000000000005),\n",
       " (666, 759.9200000000001),\n",
       " (667, 249.97000000000003),\n",
       " (668, 439.90999999999997),\n",
       " (669, 519.96),\n",
       " (670, 150.0),\n",
       " (671, 250.0),\n",
       " (672, 299.98),\n",
       " (673, 619.91),\n",
       " (674, 649.9300000000001),\n",
       " (675, 529.97),\n",
       " (676, 459.98),\n",
       " (677, 1389.8600000000001),\n",
       " (678, 499.95),\n",
       " (679, 379.89),\n",
       " (680, 129.99),\n",
       " (681, 857.89),\n",
       " (682, 895.8700000000001),\n",
       " (684, 589.95),\n",
       " (685, 663.95),\n",
       " (686, 75.0),\n",
       " (687, 249.97000000000003),\n",
       " (688, 449.89),\n",
       " (689, 119.98),\n",
       " (690, 199.99),\n",
       " (691, 1279.8700000000001),\n",
       " (692, 159.96),\n",
       " (693, 299.98),\n",
       " (694, 519.91),\n",
       " (695, 1049.94),\n",
       " (696, 449.95000000000005),\n",
       " (697, 249.93),\n",
       " (698, 489.94000000000005),\n",
       " (699, 619.91),\n",
       " (700, 1389.8600000000001),\n",
       " (701, 985.9100000000001),\n",
       " (702, 799.96),\n",
       " (703, 899.95),\n",
       " (705, 129.99),\n",
       " (706, 595.87),\n",
       " (707, 899.9100000000001),\n",
       " (708, 949.94),\n",
       " (709, 143.97),\n",
       " (710, 39.98),\n",
       " (711, 689.92),\n",
       " (712, 250.0),\n",
       " (715, 979.79),\n",
       " (716, 349.86),\n",
       " (717, 271.95),\n",
       " (719, 1059.81),\n",
       " (721, 229.99),\n",
       " (722, 1079.92),\n",
       " (723, 669.98),\n",
       " (725, 639.9300000000001),\n",
       " (726, 599.96),\n",
       " (727, 549.94),\n",
       " (728, 701.9000000000001),\n",
       " (730, 1359.9),\n",
       " (731, 474.94000000000005),\n",
       " (732, 805.9300000000001),\n",
       " (734, 399.98),\n",
       " (735, 129.99),\n",
       " (736, 594.95),\n",
       " (737, 49.98),\n",
       " (738, 731.9200000000001),\n",
       " (739, 659.85),\n",
       " (740, 199.99),\n",
       " (741, 1129.9),\n",
       " (742, 299.98),\n",
       " (743, 399.98),\n",
       " (745, 579.95),\n",
       " (746, 499.96000000000004),\n",
       " (747, 499.97),\n",
       " (748, 1249.94),\n",
       " (749, 899.89),\n",
       " (750, 959.9100000000001),\n",
       " (753, 1129.75),\n",
       " (754, 59.99),\n",
       " (755, 574.9300000000001),\n",
       " (756, 1219.91),\n",
       " (757, 719.94),\n",
       " (758, 669.9200000000001),\n",
       " (759, 789.9100000000001),\n",
       " (760, 539.91),\n",
       " (761, 349.86),\n",
       " (762, 1117.83),\n",
       " (763, 829.8900000000001),\n",
       " (764, 159.96),\n",
       " (765, 1033.83),\n",
       " (766, 399.98),\n",
       " (768, 519.95),\n",
       " (769, 129.99),\n",
       " (770, 1249.93),\n",
       " (771, 376.90000000000003),\n",
       " (772, 539.91),\n",
       " (773, 399.98),\n",
       " (774, 899.8),\n",
       " (776, 269.92),\n",
       " (777, 469.94000000000005),\n",
       " (778, 769.87),\n",
       " (779, 1089.92),\n",
       " (780, 524.98),\n",
       " (782, 1299.8600000000001),\n",
       " (783, 999.86),\n",
       " (785, 789.83),\n",
       " (786, 899.96),\n",
       " (787, 299.98),\n",
       " (788, 799.94),\n",
       " (789, 699.96),\n",
       " (790, 609.9000000000001),\n",
       " (791, 389.99),\n",
       " (792, 199.99),\n",
       " (793, 629.97),\n",
       " (794, 599.9399999999999),\n",
       " (795, 429.91),\n",
       " (796, 119.97),\n",
       " (797, 439.88),\n",
       " (798, 519.95),\n",
       " (799, 549.98),\n",
       " (800, 555.94),\n",
       " (801, 779.97),\n",
       " (802, 649.98),\n",
       " (803, 199.99),\n",
       " (805, 199.99),\n",
       " (806, 159.99),\n",
       " (807, 845.85),\n",
       " (808, 899.94),\n",
       " (809, 559.8699999999999),\n",
       " (810, 1349.9),\n",
       " (812, 739.9300000000001),\n",
       " (813, 939.84),\n",
       " (814, 519.97),\n",
       " (815, 929.7),\n",
       " (816, 1239.89),\n",
       " (817, 299.95),\n",
       " (818, 1059.85),\n",
       " (819, 1249.78),\n",
       " (820, 299.95),\n",
       " (821, 459.91),\n",
       " (822, 669.9300000000001),\n",
       " (823, 559.96),\n",
       " (824, 1079.92),\n",
       " (825, 719.88),\n",
       " (826, 609.97),\n",
       " (827, 309.99),\n",
       " (830, 657.9200000000001),\n",
       " (831, 579.95),\n",
       " (834, 579.95),\n",
       " (836, 849.88),\n",
       " (840, 39.99),\n",
       " (841, 649.88),\n",
       " (842, 329.90999999999997),\n",
       " (843, 909.9200000000001),\n",
       " (844, 299.95),\n",
       " (845, 667.95),\n",
       " (846, 1229.85),\n",
       " (847, 259.98),\n",
       " (849, 499.96000000000004),\n",
       " (850, 1339.7900000000002),\n",
       " (851, 121.97),\n",
       " (852, 399.84),\n",
       " (853, 979.84),\n",
       " (854, 709.8299999999999),\n",
       " (855, 679.95),\n",
       " (856, 1179.94),\n",
       " (857, 299.98),\n",
       " (858, 100.0),\n",
       " (859, 887.9300000000001),\n",
       " (860, 199.99),\n",
       " (861, 1179.9),\n",
       " (862, 359.95),\n",
       " (863, 1069.8700000000001),\n",
       " (864, 243.95),\n",
       " (865, 1029.95),\n",
       " (866, 899.94),\n",
       " (867, 569.92),\n",
       " (868, 1189.9),\n",
       " (869, 599.9),\n",
       " (870, 339.92),\n",
       " (871, 879.95),\n",
       " (872, 629.96),\n",
       " (874, 1009.86),\n",
       " (875, 24.99),\n",
       " (877, 1099.94),\n",
       " (878, 1049.79),\n",
       " (879, 749.94),\n",
       " (880, 959.94),\n",
       " (881, 1079.83),\n",
       " (883, 299.98),\n",
       " (884, 874.9000000000001),\n",
       " (885, 564.9100000000001),\n",
       " (886, 350.0),\n",
       " (887, 399.98),\n",
       " (888, 264.99),\n",
       " (889, 155.96),\n",
       " (890, 399.98),\n",
       " (891, 439.88),\n",
       " (893, 189.98000000000002),\n",
       " (894, 449.89),\n",
       " (895, 429.96000000000004),\n",
       " (897, 1129.9),\n",
       " (898, 699.89),\n",
       " (899, 200.0),\n",
       " (900, 1149.95),\n",
       " (902, 449.98),\n",
       " (904, 464.97),\n",
       " (905, 250.0),\n",
       " (906, 874.8700000000001),\n",
       " (907, 99.96),\n",
       " (908, 1099.92),\n",
       " (909, 200.0),\n",
       " (910, 619.93),\n",
       " (912, 729.95),\n",
       " (913, 949.9300000000001),\n",
       " (914, 929.84),\n",
       " (915, 395.91999999999996),\n",
       " (916, 579.9200000000001),\n",
       " (917, 429.94),\n",
       " (918, 619.9),\n",
       " (919, 865.9100000000001),\n",
       " (920, 1149.91),\n",
       " (921, 249.92),\n",
       " (922, 699.85),\n",
       " (923, 319.97),\n",
       " (924, 419.95000000000005),\n",
       " (925, 129.99),\n",
       " (926, 269.98),\n",
       " (927, 909.9200000000001),\n",
       " (928, 889.9200000000001),\n",
       " (929, 279.99),\n",
       " (930, 1299.8500000000001),\n",
       " (931, 1029.92),\n",
       " (933, 299.90999999999997),\n",
       " (934, 349.95),\n",
       " (935, 233.95),\n",
       " (936, 979.9300000000001),\n",
       " (939, 199.99),\n",
       " (940, 699.8900000000001),\n",
       " (942, 179.97),\n",
       " (943, 299.97),\n",
       " (944, 349.98),\n",
       " (946, 249.9),\n",
       " (947, 359.94),\n",
       " (948, 379.93),\n",
       " (949, 399.98),\n",
       " (950, 239.97),\n",
       " (951, 200.0),\n",
       " (952, 250.0),\n",
       " (955, 529.8299999999999),\n",
       " (956, 159.98000000000002),\n",
       " (957, 1219.8200000000002),\n",
       " (958, 189.96),\n",
       " (959, 909.89),\n",
       " (960, 469.85),\n",
       " (961, 809.96),\n",
       " (962, 649.9200000000001),\n",
       " (964, 739.8800000000001),\n",
       " (965, 269.92),\n",
       " (966, 1029.94),\n",
       " (968, 559.9300000000001),\n",
       " (969, 369.95000000000005),\n",
       " (970, 769.9300000000001),\n",
       " (972, 599.97),\n",
       " (973, 629.89),\n",
       " (974, 129.99),\n",
       " (976, 939.9200000000001),\n",
       " (977, 709.9100000000001),\n",
       " (978, 149.94),\n",
       " (979, 409.97),\n",
       " (980, 729.96),\n",
       " (981, 749.94),\n",
       " (982, 599.97),\n",
       " (983, 909.9300000000001),\n",
       " (984, 749.98),\n",
       " (985, 449.92999999999995),\n",
       " (986, 254.96),\n",
       " (988, 327.95),\n",
       " (991, 1179.93),\n",
       " (992, 819.8900000000001),\n",
       " (993, 249.9),\n",
       " (994, 200.0),\n",
       " (995, 519.9200000000001),\n",
       " (996, 759.84),\n",
       " (998, 1039.92),\n",
       " (999, 909.81),\n",
       " (1000, 279.93),\n",
       " (1001, 649.81),\n",
       " (1002, 949.9200000000001),\n",
       " (1003, 1029.91),\n",
       " (1005, 599.9300000000001),\n",
       " (1006, 1039.91),\n",
       " (1007, 629.83),\n",
       " (1009, 349.86),\n",
       " (1010, 489.86),\n",
       " (1011, 849.94),\n",
       " (1013, 129.99),\n",
       " (1016, 719.9000000000001),\n",
       " (1017, 1079.88),\n",
       " (1018, 679.97),\n",
       " (1019, 199.99),\n",
       " (1020, 249.96),\n",
       " (1021, 619.95),\n",
       " (1022, 239.96),\n",
       " (1023, 129.99),\n",
       " (1024, 529.97),\n",
       " (1025, 529.89),\n",
       " (1026, 699.96),\n",
       " (1027, 609.95),\n",
       " (1028, 369.84000000000003),\n",
       " (1029, 329.96000000000004),\n",
       " (1030, 569.95),\n",
       " (1031, 579.98),\n",
       " (1033, 484.87),\n",
       " (1035, 989.96),\n",
       " (1037, 879.87),\n",
       " (1038, 299.98),\n",
       " (1039, 299.98),\n",
       " (1040, 404.95000000000005),\n",
       " (1041, 649.94),\n",
       " (1042, 577.97),\n",
       " (1044, 769.87),\n",
       " (1045, 1139.88),\n",
       " (1047, 529.93),\n",
       " (1049, 509.87),\n",
       " (1050, 249.99),\n",
       " (1051, 129.99),\n",
       " (1052, 579.94),\n",
       " (1053, 879.9300000000001),\n",
       " (1054, 299.98),\n",
       " (1056, 50.0),\n",
       " (1057, 709.9100000000001),\n",
       " (1058, 799.9200000000001),\n",
       " (1059, 699.85),\n",
       " (1060, 1079.8500000000001),\n",
       " (1061, 959.94),\n",
       " (1062, 229.95),\n",
       " (1063, 1329.93),\n",
       " (1065, 479.99),\n",
       " (1066, 849.8600000000001),\n",
       " (1067, 199.98),\n",
       " (1068, 629.96),\n",
       " (1069, 649.87),\n",
       " (1071, 329.94),\n",
       " (1072, 129.99),\n",
       " (1074, 200.0),\n",
       " (1076, 219.93),\n",
       " (1077, 99.99),\n",
       " (1078, 119.98),\n",
       " (1079, 669.9000000000001),\n",
       " (1080, 799.9200000000001),\n",
       " (1081, 879.81),\n",
       " (1082, 389.97),\n",
       " (1083, 559.94),\n",
       " (1084, 100.0),\n",
       " (1085, 599.96),\n",
       " (1086, 1019.86),\n",
       " (1087, 309.9),\n",
       " (1088, 249.97000000000003),\n",
       " (1089, 879.9000000000001),\n",
       " (1090, 1169.79),\n",
       " (1091, 719.94),\n",
       " (1092, 499.89),\n",
       " (1093, 519.89),\n",
       " (1094, 199.99),\n",
       " (1095, 574.8100000000001),\n",
       " (1096, 1159.91),\n",
       " (1097, 250.0),\n",
       " (1098, 829.9200000000001),\n",
       " (1099, 524.8299999999999),\n",
       " (1100, 99.96),\n",
       " (1102, 499.98),\n",
       " (1103, 254.95),\n",
       " (1104, 599.97),\n",
       " (1105, 819.89),\n",
       " (1106, 259.95),\n",
       " (1107, 179.97),\n",
       " (1108, 31.99),\n",
       " (1109, 79.98),\n",
       " (1110, 1084.75),\n",
       " (1111, 1239.89),\n",
       " (1112, 754.89),\n",
       " (1114, 269.98),\n",
       " (1116, 499.93),\n",
       " (1117, 99.96),\n",
       " (1118, 359.95000000000005),\n",
       " (1119, 150.0),\n",
       " (1120, 759.84),\n",
       " (1121, 419.95000000000005),\n",
       " (1122, 1599.89),\n",
       " (1123, 649.98),\n",
       " (1124, 79.98),\n",
       " (1125, 399.98),\n",
       " (1127, 200.0),\n",
       " (1128, 679.94),\n",
       " (1129, 210.0),\n",
       " (1130, 899.94),\n",
       " (1131, 769.86),\n",
       " (1132, 549.95),\n",
       " (1133, 559.89),\n",
       " (1134, 419.91999999999996),\n",
       " (1135, 635.9000000000001),\n",
       " (1137, 99.96),\n",
       " (1138, 1149.8500000000001),\n",
       " (1139, 329.98),\n",
       " (1142, 849.9000000000001),\n",
       " (1143, 369.95000000000005),\n",
       " (1145, 299.97),\n",
       " (1146, 549.88),\n",
       " (1147, 559.96),\n",
       " (1149, 549.95),\n",
       " (1150, 859.95),\n",
       " (1151, 119.97),\n",
       " (1152, 299.98),\n",
       " (1153, 99.96),\n",
       " (1154, 1099.8300000000002),\n",
       " (1156, 399.97),\n",
       " (1157, 1149.85),\n",
       " (1158, 299.95),\n",
       " (1159, 124.95),\n",
       " (1160, 939.94),\n",
       " (1161, 1074.89),\n",
       " (1162, 509.98),\n",
       " (1163, 494.95),\n",
       " (1165, 619.9300000000001),\n",
       " (1166, 829.9200000000001),\n",
       " (1167, 879.83),\n",
       " (1169, 529.94),\n",
       " (1170, 729.95),\n",
       " (1172, 1249.76),\n",
       " (1173, 629.92),\n",
       " (1174, 1059.91),\n",
       " (1175, 1129.8600000000001),\n",
       " (1178, 239.94),\n",
       " (1179, 100.0),\n",
       " (1181, 719.97),\n",
       " (1182, 804.9200000000001),\n",
       " (1183, 699.88),\n",
       " (1184, 1549.91),\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ordGrp.reduceByKey(lambda x,y : x+y).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd889695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find maximu revenue for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84db41b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19, 124.99),\n",
       " (24, 399.95),\n",
       " (35, 159.99),\n",
       " (37, 174.95),\n",
       " (44, 299.95),\n",
       " (58, 299.99),\n",
       " (60, 999.99),\n",
       " (61, 299.99),\n",
       " (78, 499.95),\n",
       " (93, 124.95),\n",
       " (116, 224.95),\n",
       " (127, 329.99),\n",
       " (134, 125.0),\n",
       " (135, 110.0),\n",
       " (172, 150.0),\n",
       " (191, 499.95),\n",
       " (203, 399.99),\n",
       " (208, 1999.99),\n",
       " (216, 189.0),\n",
       " (226, 599.99),\n",
       " (235, 174.95),\n",
       " (249, 274.85),\n",
       " (251, 449.95),\n",
       " (258, 474.95),\n",
       " (273, 139.95),\n",
       " (276, 159.95),\n",
       " (278, 224.95),\n",
       " (282, 159.95),\n",
       " (295, 499.75),\n",
       " (303, 399.99),\n",
       " (305, 199.0),\n",
       " (306, 449.95),\n",
       " (311, 109.95),\n",
       " (359, 499.95),\n",
       " (364, 299.99),\n",
       " (365, 299.95),\n",
       " (403, 129.99),\n",
       " (502, 250.0),\n",
       " (564, 150.0),\n",
       " (565, 350.0),\n",
       " (567, 125.0),\n",
       " (572, 199.95),\n",
       " (607, 249.99),\n",
       " (625, 199.99),\n",
       " (627, 199.95),\n",
       " (642, 150.0),\n",
       " (646, 499.95),\n",
       " (647, 134.99),\n",
       " (652, 129.99),\n",
       " (666, 109.99),\n",
       " (671, 209.99),\n",
       " (677, 499.95),\n",
       " (691, 399.95),\n",
       " (703, 99.95),\n",
       " (705, 119.99),\n",
       " (715, 129.99),\n",
       " (724, 500.0),\n",
       " (725, 108.0),\n",
       " (728, 325.0),\n",
       " (730, 400.0),\n",
       " (743, 169.99),\n",
       " (768, 299.99),\n",
       " (771, 199.95),\n",
       " (773, 249.99),\n",
       " (775, 49.95),\n",
       " (777, 399.95),\n",
       " (778, 124.95),\n",
       " (786, 179.99),\n",
       " (792, 74.95),\n",
       " (793, 74.95),\n",
       " (797, 89.95),\n",
       " (804, 99.95),\n",
       " (810, 99.95),\n",
       " (818, 239.95),\n",
       " (821, 259.95),\n",
       " (822, 239.95),\n",
       " (823, 259.95),\n",
       " (825, 159.95),\n",
       " (828, 159.95),\n",
       " (835, 159.95),\n",
       " (845, 299.99),\n",
       " (858, 199.99),\n",
       " (860, 599.99),\n",
       " (885, 124.95),\n",
       " (886, 124.95),\n",
       " (893, 124.95),\n",
       " (897, 124.95),\n",
       " (905, 124.95),\n",
       " (906, 124.95),\n",
       " (917, 109.95),\n",
       " (924, 79.95),\n",
       " (926, 79.95),\n",
       " (957, 299.98),\n",
       " (977, 149.95),\n",
       " (981, 495.0),\n",
       " (982, 149.99),\n",
       " (1004, 399.98),\n",
       " (1014, 249.9),\n",
       " (1059, 349.99),\n",
       " (1073, 199.99)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ordGrp.reduceByKey(max).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6381564d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 250.0), (4, 299.95), (8, 299.95), (10, 199.99)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.map(lambda x : ( int(x.split(',')[1]),float(x.split(',')[4])  )).reduceByKey(lambda x,y :x if x >y else y).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54e55988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, '3,2,502,5,250.0,50.0'),\n",
       " (4, '6,4,365,5,299.95,59.99'),\n",
       " (8, '18,8,365,5,299.95,59.99'),\n",
       " (10, '28,10,1073,1,199.99,199.99')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordItems.map(lambda x : ( int(x.split(',')[1]),x  )).\\\n",
    "reduceByKey(lambda x,y :x if float(x.split(',')[4]) > float(y.split(',')[4]) else y).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f6f405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[(2,'joseph',200),(2,'jimmy',250),(2,'tina',130),(4,'jimmy',50),(4,'tina',300),(4,'joseph',150),(4,'ram',200),\n",
    "     (7,'joseph',300),(7,'jimmy',80)]\n",
    "orditems=spark.sparkContext.parallelize(lst,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdbf8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordPair =orditems.map(lambda x: (x[0],(x[1],x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e39c220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, ('joseph', 200)),\n",
       " (2, ('jimmy', 250)),\n",
       " (2, ('tina', 130)),\n",
       " (4, ('jimmy', 50)),\n",
       " (4, ('tina', 300))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordPair.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54e25cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_val =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aac89e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_opp(acc,ele):\n",
    "    if acc > ele[1]:\n",
    "        return acc\n",
    "    else:\n",
    "        return ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a148f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_opp(acc1,acc2):\n",
    "    if acc1 > acc2:\n",
    "        return acc1\n",
    "    else:\n",
    "        return acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76441e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result =ordPair.aggregateByKey(zero_val,seq_opp,comb_opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2cd8a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 250), (4, 300), (7, 300)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_result.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64502b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return customer_name along with max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c588d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_val =('',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdd95a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_opp(acc,ele):\n",
    "    if acc[1] > ele[1]:\n",
    "        return acc\n",
    "    else:\n",
    "        return ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be4f1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb_opp(acc1,acc2):\n",
    "    if acc1[1] > acc2[1]:\n",
    "        return acc1\n",
    "    else:\n",
    "        return acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "333cdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_result =ordPair.aggregateByKey(zero_val,seq_opp,comb_opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebee16bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, ('jimmy', 250))\n",
      "(4, ('tina', 300))\n",
      "(7, ('joseph', 300))\n"
     ]
    }
   ],
   "source": [
    "for i in agg_result.collect():print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43c60359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum all revenues and number of records for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f44456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#County By Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ba9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13797db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SparkDemo\").master(\"local[1]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e70a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord = spark.sparkContext.textFile('c:/practice/orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6da61c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a69bbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordMap = ord.map(lambda x: (x.split(',')[3],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f9ecc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CLOSED', 1),\n",
       " ('PENDING_PAYMENT', 1),\n",
       " ('COMPLETE', 1),\n",
       " ('CLOSED', 1),\n",
       " ('COMPLETE', 1)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordMap.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f4c885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ordMap.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "257eb573",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.defaultdict' object has no attribute 'collect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.defaultdict' object has no attribute 'collect'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "36d46dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOSED 7556\n",
      "PENDING_PAYMENT 15030\n",
      "COMPLETE 22899\n",
      "PROCESSING 8275\n",
      "PAYMENT_REVIEW 729\n",
      "PENDING 7610\n",
      "ON_HOLD 3798\n",
      "CANCELED 1428\n",
      "SUSPECTED_FRAUD 1558\n"
     ]
    }
   ],
   "source": [
    "for k,v in result.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c60d11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91ebfb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort orders using customer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e14c401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80c1e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordPair = ord.map(lambda x:(int(x.split(',')[2]),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d2b9afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11599, '1,2013-07-25 00:00:00.0,11599,CLOSED'),\n",
       " (256, '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT'),\n",
       " (12111, '3,2013-07-25 00:00:00.0,12111,COMPLETE'),\n",
       " (8827, '4,2013-07-25 00:00:00.0,8827,CLOSED'),\n",
       " (11318, '5,2013-07-25 00:00:00.0,11318,COMPLETE')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordPair.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "833af91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtRdd =ordPair.sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75652f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '22945,2013-12-13 00:00:00.0,1,COMPLETE'),\n",
       " (2, '15192,2013-10-29 00:00:00.0,2,PENDING_PAYMENT'),\n",
       " (2, '33865,2014-02-18 00:00:00.0,2,COMPLETE'),\n",
       " (2, '57963,2013-08-02 00:00:00.0,2,ON_HOLD'),\n",
       " (2, '67863,2013-11-30 00:00:00.0,2,COMPLETE'),\n",
       " (3, '22646,2013-12-11 00:00:00.0,3,COMPLETE'),\n",
       " (3, '23662,2013-12-19 00:00:00.0,3,COMPLETE'),\n",
       " (3, '35158,2014-02-26 00:00:00.0,3,COMPLETE'),\n",
       " (3, '46399,2014-05-09 00:00:00.0,3,PROCESSING'),\n",
       " (3, '56178,2014-07-15 00:00:00.0,3,PENDING')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srtRdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c18ed600",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtRdd =ordPair.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c1c605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41643,2014-04-08 00:00:00.0,12435,PENDING\n",
      "61629,2013-12-21 00:00:00.0,12435,CANCELED\n",
      "1868,2013-08-03 00:00:00.0,12434,CLOSED\n",
      "4799,2013-08-23 00:00:00.0,12434,PENDING_PAYMENT\n",
      "5303,2013-08-26 00:00:00.0,12434,PENDING\n",
      "6160,2013-09-02 00:00:00.0,12434,COMPLETE\n",
      "13544,2013-10-16 00:00:00.0,12434,PENDING\n",
      "42915,2014-04-16 00:00:00.0,12434,COMPLETE\n",
      "51800,2014-06-14 00:00:00.0,12434,ON_HOLD\n",
      "61777,2013-12-26 00:00:00.0,12434,COMPLETE\n"
     ]
    }
   ],
   "source": [
    "for i in srtRdd.take(10):print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "731794d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort Order using Customer and Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a8ce2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordPair = ord.map(lambda x :((int(x.split(',')[2]), x.split(',')[3]) ,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd17618f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((11599, 'CLOSED'), '1,2013-07-25 00:00:00.0,11599,CLOSED'),\n",
       " ((256, 'PENDING_PAYMENT'), '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT'),\n",
       " ((12111, 'COMPLETE'), '3,2013-07-25 00:00:00.0,12111,COMPLETE'),\n",
       " ((8827, 'CLOSED'), '4,2013-07-25 00:00:00.0,8827,CLOSED'),\n",
       " ((11318, 'COMPLETE'), '5,2013-07-25 00:00:00.0,11318,COMPLETE')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordPair.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0867272",
   "metadata": {},
   "outputs": [],
   "source": [
    "srtRdd =ordPair.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91303cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41643,2014-04-08 00:00:00.0,12435,PENDING\n",
      "61629,2013-12-21 00:00:00.0,12435,CANCELED\n",
      "1868,2013-08-03 00:00:00.0,12434,CLOSED\n",
      "4799,2013-08-23 00:00:00.0,12434,PENDING_PAYMENT\n",
      "5303,2013-08-26 00:00:00.0,12434,PENDING\n",
      "6160,2013-09-02 00:00:00.0,12434,COMPLETE\n",
      "13544,2013-10-16 00:00:00.0,12434,PENDING\n",
      "42915,2014-04-16 00:00:00.0,12434,COMPLETE\n",
      "51800,2014-06-14 00:00:00.0,12434,ON_HOLD\n",
      "61777,2013-12-26 00:00:00.0,12434,COMPLETE\n"
     ]
    }
   ],
   "source": [
    "for i in srtRdd.take(10):print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d813742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "27c06c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = spark.sparkContext.textFile('c:/practice/product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5107bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy\n",
      "2,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\n",
      "3,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\n",
      "4,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\n",
      "5,2,Riddell Youth Revolution Speed Custom Footbal,,199.99,http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet\n"
     ]
    }
   ],
   "source": [
    "for i in prod.take(5):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee478cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prodPair = prod.map(lambda x : (float(x.split(',')[3]),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6fedd0cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 63.0 failed 1 times, most recent failure: Lost task 0.0 in stage 63.0 (TID 110) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\1381186240.py\", line 1, in <lambda>\nValueError: could not convert string to float: ''\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\1381186240.py\", line 1, in <lambda>\nValueError: could not convert string to float: ''\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prodPair\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py:2855\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2852\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2854\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2855\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m, takeUpToNumLeft, p)\n\u001b[0;32m   2857\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2858\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\context.py:2510\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2508\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2510\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD\u001b[38;5;241m.\u001b[39mrunJob(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc(), mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd, partitions)\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 63.0 failed 1 times, most recent failure: Lost task 0.0 in stage 63.0 (TID 110) (DESKTOP-LJE0474 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\1381186240.py\", line 1, in <lambda>\nValueError: could not convert string to float: ''\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:181)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1247, in main\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 1239, in process\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\rdd.py\", line 2849, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"C:\\Spark\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\babje\\AppData\\Local\\Temp\\ipykernel_15884\\1381186240.py\", line 1, in <lambda>\nValueError: could not convert string to float: ''\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\r\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\r\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\r\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\r\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\r\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\r\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\r\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\r\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\r\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\r\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\r\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\r\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:181)\r\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2438)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "prodPair.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "946713d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['685,31,\"TaylorMade SLDR Irons - (Steel) 4-PW, AW\",,899.99,http://images.acmesports.sports/TaylorMade+SLDR+Irons+-+%28Steel%29+4-PW%2C+AW']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.filter(lambda x : x.split(',')[4]=='').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d07c3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1 =prod.filter(lambda x : x.split(',')[4]!='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca8b028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prodPair = prod1.map(lambda x : (float(x.split(',')[4]),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "72b033c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59.98, '1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy')\n",
      "(129.99, \"2,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\")\n",
      "(89.99, \"3,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\")\n",
      "(89.99, \"4,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\")\n",
      "(199.99, '5,2,Riddell Youth Revolution Speed Custom Footbal,,199.99,http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet')\n"
     ]
    }
   ],
   "source": [
    "for i in prodPair.take(5):print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "73e4e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5rdd =prodPair.sortByKey(ascending=False).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d3a54f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208,10,SOLE E35 Elliptical,,1999.99,http://images.acmesports.sports/SOLE+E35+Elliptical\n",
      "66,4,SOLE F85 Treadmill,,1799.99,http://images.acmesports.sports/SOLE+F85+Treadmill\n",
      "199,10,SOLE F85 Treadmill,,1799.99,http://images.acmesports.sports/SOLE+F85+Treadmill\n",
      "496,22,SOLE F85 Treadmill,,1799.99,http://images.acmesports.sports/SOLE+F85+Treadmill\n",
      "1048,47,\"Spalding Beast 60\"\" Glass Portable Basketball \",,1099.99,http://images.acmesports.sports/Spalding+Beast+60%22+Glass+Portable+Basketball+Hoop\n"
     ]
    }
   ],
   "source": [
    "for i in top5rdd:print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "058efa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takeOrder api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f0cc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =spark.sparkContext.parallelize([10,8,20,15,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "47a2a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.takeOrdered(3).sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f0958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4134045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 20]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeOrdered(2,lambda x : -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ef8d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy',\n",
       " \"2,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"3,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " \"4,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " '5,2,Riddell Youth Revolution Speed Custom Footbal,,199.99,http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b8b7efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['208,10,SOLE E35 Elliptical,,1999.99,http://images.acmesports.sports/SOLE+E35+Elliptical',\n",
       " '66,4,SOLE F85 Treadmill,,1799.99,http://images.acmesports.sports/SOLE+F85+Treadmill']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1.takeOrdered(2, lambda x : -float(x.split(',')[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d84ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking Per Group\n",
    "#Top 2 products per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9c2bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "prodDf = prod.filter(lambda x: int(x.split(',')[1] )in (2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f80b3a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5cac928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy',\n",
       " \"2,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"3,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " \"4,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " '5,2,Riddell Youth Revolution Speed Custom Footbal,,199.99,http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet',\n",
       " \"6,2,Jordan Men's VI Retro TD Football Cleat,,134.99,http://images.acmesports.sports/Jordan+Men%27s+VI+Retro+TD+Football+Cleat\",\n",
       " '7,2,Schutt Youth Recruit Hybrid Custom Football H,,99.99,http://images.acmesports.sports/Schutt+Youth+Recruit+Hybrid+Custom+Football+Helmet+2014',\n",
       " \"8,2,Nike Men's Vapor Carbon Elite TD Football Cle,,129.99,http://images.acmesports.sports/Nike+Men%27s+Vapor+Carbon+Elite+TD+Football+Cleat\",\n",
       " '9,2,Nike Adult Vapor Jet 3.0 Receiver Gloves,,50.0,http://images.acmesports.sports/Nike+Adult+Vapor+Jet+3.0+Receiver+Gloves',\n",
       " \"10,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " '11,2,Fitness Gear 300 lb Olympic Weight Set,,209.99,http://images.acmesports.sports/Fitness+Gear+300+lb+Olympic+Weight+Set',\n",
       " \"12,2,Under Armour Men's Highlight MC Alter Ego Fla,,139.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Alter+Ego+Flash+Football...\",\n",
       " \"13,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " '14,2,Quik Shade Summit SX170 10 FT. x 10 FT. Canop,,199.99,http://images.acmesports.sports/Quik+Shade+Summit+SX170+10+FT.+x+10+FT.+Canopy',\n",
       " \"15,2,Under Armour Kids' Highlight RM Alter Ego Sup,,59.99,http://images.acmesports.sports/Under+Armour+Kids%27+Highlight+RM+Alter+Ego+Superman+Football...\",\n",
       " '16,2,Riddell Youth 360 Custom Football Helmet,,299.99,http://images.acmesports.sports/Riddell+Youth+360+Custom+Football+Helmet',\n",
       " \"17,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"18,2,Reebok Men's Full Zip Training Jacket,,29.97,http://images.acmesports.sports/Reebok+Men%27s+Full+Zip+Training+Jacket\",\n",
       " \"19,2,Nike Men's Fingertrap Max Training Shoe,,124.99,http://images.acmesports.sports/Nike+Men%27s+Fingertrap+Max+Training+Shoe\",\n",
       " \"20,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"21,2,Under Armour Kids' Highlight RM Football Clea,,54.99,http://images.acmesports.sports/Under+Armour+Kids%27+Highlight+RM+Football+Cleat\",\n",
       " '22,2,Kijaro Dual Lock Chair,,29.99,http://images.acmesports.sports/Kijaro+Dual+Lock+Chair',\n",
       " \"23,2,Under Armour Men's Highlight MC Alter Ego Hul,,139.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Alter+Ego+Hulk+Football...\",\n",
       " '24,2,Elevation Training Mask 2.0,,79.99,http://images.acmesports.sports/Elevation+Training+Mask+2.0',\n",
       " '25,3,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy',\n",
       " \"26,3,Nike Men's USA White Home Stadium Soccer Jers,,90.0,http://images.acmesports.sports/Nike+Men%27s+USA+White+Home+Stadium+Soccer+Jersey\",\n",
       " '27,3,Nike Youth USA Away Stadium Replica Soccer Je,,75.0,http://images.acmesports.sports/Nike+Youth+USA+Away+Stadium+Replica+Soccer+Jersey',\n",
       " '28,3,adidas Brazuca 2014 Top Glider Soccer Ball,,29.99,http://images.acmesports.sports/adidas+Brazuca+2014+Top+Glider+Soccer+Ball',\n",
       " \"29,3,Nike Men's USA Away Stadium Replica Soccer Je,,90.0,http://images.acmesports.sports/Nike+Men%27s+USA+Away+Stadium+Replica+Soccer+Jersey\",\n",
       " \"30,3,adidas Men's Germany Home Soccer Jersey,,90.0,http://images.acmesports.sports/adidas+Men%27s+Germany+Home+Soccer+Jersey\",\n",
       " '31,3,Nike+ Fuelband SE,,99.0,http://images.acmesports.sports/Nike%2B+Fuelband+SE',\n",
       " \"32,3,PUMA Men's evoPOWER 1 Tricks FG Soccer Cleat,,189.99,http://images.acmesports.sports/PUMA+Men%27s+evoPOWER+1+Tricks+FG+Soccer+Cleat\",\n",
       " '33,3,adidas Brazuca 2014 Top Repliqué Soccer Ball,,39.99,http://images.acmesports.sports/adidas+Brazuca+2014+Top+Repliqu%C3%A9+Soccer+Ball',\n",
       " '34,3,\"Nike Women\\'s Pro Core 3\"\" Compression Shorts\",,28.0,http://images.acmesports.sports/Nike+Women%27s+Pro+Core+3%22+Compression+Shorts',\n",
       " '35,3,adidas Brazuca 2014 Official Match Ball,,159.99,http://images.acmesports.sports/adidas+Brazuca+2014+Official+Match+Ball',\n",
       " \"36,3,adidas Men's Germany Black/Red Away Match Soc,,90.0,http://images.acmesports.sports/adidas+Men%27s+Germany+Black%2FRed+Away+Match+Soccer+Jersey\",\n",
       " \"37,3,adidas Kids' F5 Messi FG Soccer Cleat,,34.99,http://images.acmesports.sports/adidas+Kids%27+F5+Messi+FG+Soccer+Cleat\",\n",
       " \"38,3,Nike Men's Hypervenom Phantom Premium FG Socc,,0.0,http://images.acmesports.sports/Nike+Men%27s+Hypervenom+Phantom+Premium+FG+Soccer+Cleat\",\n",
       " \"39,3,Nike Women's Pro Victory Compression Bra,,21.99,http://images.acmesports.sports/Nike+Women%27s+Pro+Victory+Compression+Bra\",\n",
       " '40,3,Quik Shade Summit SX170 10 FT. x 10 FT. Canop,,199.99,http://images.acmesports.sports/Quik+Shade+Summit+SX170+10+FT.+x+10+FT.+Canopy',\n",
       " \"41,3,adidas Men's Mexico Home Soccer Jersey,,90.0,http://images.acmesports.sports/adidas+Men%27s+Mexico+Home+Soccer+Jersey\",\n",
       " \"42,3,adidas Kids' F10 Messi TRX FG Soccer Cleat,,44.99,http://images.acmesports.sports/adidas+Kids%27+F10+Messi+TRX+FG+Soccer+Cleat\",\n",
       " '43,3,Kijaro Dual Lock Chair,,29.99,http://images.acmesports.sports/Kijaro+Dual+Lock+Chair',\n",
       " \"44,3,adidas Men's F10 Messi TRX FG Soccer Cleat,,59.99,http://images.acmesports.sports/adidas+Men%27s+F10+Messi+TRX+FG+Soccer+Cleat\",\n",
       " \"45,3,adidas Men's F10 Messi FG Soccer Cleat,,59.99,http://images.acmesports.sports/adidas+Men%27s+F10+Messi+FG+Soccer+Cleat\",\n",
       " \"46,3,Quest 12' x 12' Dome Canopy,,149.99,http://images.acmesports.sports/Quest+12%27+x+12%27+Dome+Canopy\",\n",
       " \"47,3,Nike Women's Pro Hyperwarm Fitted Tights,,24.97,http://images.acmesports.sports/Nike+Women%27s+Pro+Hyperwarm+Fitted+Tights\",\n",
       " '48,3,adidas Brazuca Final Rio Official Match Ball,,159.99,http://images.acmesports.sports/adidas+Brazuca+Final+Rio+Official+Match+Ball',\n",
       " '49,4,Diamondback Adult Sorrento Mountain Bike 2014,,299.98,http://images.acmesports.sports/Diamondback+Adult+Sorrento+Mountain+Bike+2014',\n",
       " '50,4,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy',\n",
       " '51,4,MAC Sports Collapsible Wagon,,69.99,http://images.acmesports.sports/MAC+Sports+Collapsible+Wagon',\n",
       " '52,4,Easton Mako Youth Bat 2014 (-11),,249.97,http://images.acmesports.sports/Easton+Mako+Youth+Bat+2014+%28-11%29',\n",
       " '53,4,adidas Brazuca 2014 Top Glider Soccer Ball,,29.99,http://images.acmesports.sports/adidas+Brazuca+2014+Top+Glider+Soccer+Ball',\n",
       " '54,4,Nike+ Fuelband SE,,99.0,http://images.acmesports.sports/Nike%2B+Fuelband+SE',\n",
       " '55,4,adidas Brazuca 2014 Top Repliqué Soccer Ball,,39.99,http://images.acmesports.sports/adidas+Brazuca+2014+Top+Repliqu%C3%A9+Soccer+Ball',\n",
       " '56,4,Fitbit Flex Wireless Activity & Sleep Wristba,,99.95,http://images.acmesports.sports/Fitbit+Flex+Wireless+Activity+%26+Sleep+Wristband',\n",
       " '57,4,\"Nike Women\\'s Pro Core 3\"\" Compression Shorts\",,28.0,http://images.acmesports.sports/Nike+Women%27s+Pro+Core+3%22+Compression+Shorts',\n",
       " \"58,4,Diamondback Boys' Insight 24 Performance Hybr,,299.99,http://images.acmesports.sports/Diamondback+Boys%27+Insight+24+Performance+Hybrid+Bike+2014\",\n",
       " '59,4,adidas Brazuca 2014 Official Match Ball,,159.99,http://images.acmesports.sports/adidas+Brazuca+2014+Official+Match+Ball',\n",
       " '60,4,SOLE E25 Elliptical,,999.99,http://images.acmesports.sports/SOLE+E25+Elliptical',\n",
       " \"61,4,Diamondback Girls' Clarity 24 Hybrid Bike 201,,299.99,http://images.acmesports.sports/Diamondback+Girls%27+Clarity+24+Hybrid+Bike+2014\",\n",
       " '62,4,Easton XL1 Youth Bat 2014 (-10),,179.97,http://images.acmesports.sports/Easton+XL1+Youth+Bat+2014+%28-10%29',\n",
       " '63,4,Fitness Gear 300 lb Olympic Weight Set,,209.99,http://images.acmesports.sports/Fitness+Gear+300+lb+Olympic+Weight+Set',\n",
       " \"64,4,Nike Women's Pro Victory Compression Bra,,21.99,http://images.acmesports.sports/Nike+Women%27s+Pro+Victory+Compression+Bra\",\n",
       " '65,4,Quik Shade Summit SX170 10 FT. x 10 FT. Canop,,199.99,http://images.acmesports.sports/Quik+Shade+Summit+SX170+10+FT.+x+10+FT.+Canopy',\n",
       " '66,4,SOLE F85 Treadmill,,1799.99,http://images.acmesports.sports/SOLE+F85+Treadmill',\n",
       " '67,4,Kijaro Dual Lock Chair,,29.99,http://images.acmesports.sports/Kijaro+Dual+Lock+Chair',\n",
       " '68,4,Diamondback Adult Outlook Mountain Bike 2014,,309.99,http://images.acmesports.sports/Diamondback+Adult+Outlook+Mountain+Bike+2014',\n",
       " '69,4,Easton S1 Youth Bat 2014 (-12),,179.97,http://images.acmesports.sports/Easton+S1+Youth+Bat+2014+%28-12%29',\n",
       " '70,4,Elevation Training Mask 2.0,,79.99,http://images.acmesports.sports/Elevation+Training+Mask+2.0',\n",
       " '71,4,Diamondback Adult Response XE Mountain Bike 2,,349.98,http://images.acmesports.sports/Diamondback+Adult+Response+XE+Mountain+Bike+2014',\n",
       " \"72,4,Quest 12' x 12' Dome Canopy,,149.99,http://images.acmesports.sports/Quest+12%27+x+12%27+Dome+Canopy\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodDf.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36a769fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prodGrp=prodDf.map(lambda x :(int(x.split(',')[1]),x)).groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "889bc1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, <pyspark.resultiterable.ResultIterable at 0x21405368790>),\n",
       " (4, <pyspark.resultiterable.ResultIterable at 0x21405368f50>),\n",
       " (3, <pyspark.resultiterable.ResultIterable at 0x214053ac910>)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodGrp.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "606f62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = prodGrp.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54cea14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, <pyspark.resultiterable.ResultIterable at 0x21405532d50>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "580d0939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16,2,Riddell Youth 360 Custom Football Helmet,,299.99,http://images.acmesports.sports/Riddell+Youth+360+Custom+Football+Helmet',\n",
       " '11,2,Fitness Gear 300 lb Olympic Weight Set,,209.99,http://images.acmesports.sports/Fitness+Gear+300+lb+Olympic+Weight+Set',\n",
       " '5,2,Riddell Youth Revolution Speed Custom Footbal,,199.99,http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet',\n",
       " '14,2,Quik Shade Summit SX170 10 FT. x 10 FT. Canop,,199.99,http://images.acmesports.sports/Quik+Shade+Summit+SX170+10+FT.+x+10+FT.+Canopy',\n",
       " \"12,2,Under Armour Men's Highlight MC Alter Ego Fla,,139.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Alter+Ego+Flash+Football...\",\n",
       " \"23,2,Under Armour Men's Highlight MC Alter Ego Hul,,139.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Alter+Ego+Hulk+Football...\",\n",
       " \"6,2,Jordan Men's VI Retro TD Football Cleat,,134.99,http://images.acmesports.sports/Jordan+Men%27s+VI+Retro+TD+Football+Cleat\",\n",
       " \"2,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"8,2,Nike Men's Vapor Carbon Elite TD Football Cle,,129.99,http://images.acmesports.sports/Nike+Men%27s+Vapor+Carbon+Elite+TD+Football+Cleat\",\n",
       " \"10,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"17,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"20,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\",\n",
       " \"19,2,Nike Men's Fingertrap Max Training Shoe,,124.99,http://images.acmesports.sports/Nike+Men%27s+Fingertrap+Max+Training+Shoe\",\n",
       " '7,2,Schutt Youth Recruit Hybrid Custom Football H,,99.99,http://images.acmesports.sports/Schutt+Youth+Recruit+Hybrid+Custom+Football+Helmet+2014',\n",
       " \"3,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " \"4,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " \"13,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\",\n",
       " '24,2,Elevation Training Mask 2.0,,79.99,http://images.acmesports.sports/Elevation+Training+Mask+2.0',\n",
       " \"15,2,Under Armour Kids' Highlight RM Alter Ego Sup,,59.99,http://images.acmesports.sports/Under+Armour+Kids%27+Highlight+RM+Alter+Ego+Superman+Football...\",\n",
       " '1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy',\n",
       " \"21,2,Under Armour Kids' Highlight RM Football Clea,,54.99,http://images.acmesports.sports/Under+Armour+Kids%27+Highlight+RM+Football+Cleat\",\n",
       " '9,2,Nike Adult Vapor Jet 3.0 Receiver Gloves,,50.0,http://images.acmesports.sports/Nike+Adult+Vapor+Jet+3.0+Receiver+Gloves',\n",
       " '22,2,Kijaro Dual Lock Chair,,29.99,http://images.acmesports.sports/Kijaro+Dual+Lock+Chair',\n",
       " \"18,2,Reebok Men's Full Zip Training Jacket,,29.97,http://images.acmesports.sports/Reebok+Men%27s+Full+Zip+Training+Jacket\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(first[1],key =lambda x : float(x.split(',')[4]) ,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4acdf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=prodGrp.flatMap(lambda x :sorted(x[1],key =lambda x : float(x.split(',')[4]) ,reverse=True)[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea0624cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16,2,Riddell Youth 360 Custom Football Helmet,,299.99,http://images.acmesports.sports/Riddell+Youth+360+Custom+Football+Helmet',\n",
       " '11,2,Fitness Gear 300 lb Olympic Weight Set,,209.99,http://images.acmesports.sports/Fitness+Gear+300+lb+Olympic+Weight+Set',\n",
       " '66,4,SOLE F85 Treadmill,,1799.99,http://images.acmesports.sports/SOLE+F85+Treadmill',\n",
       " '60,4,SOLE E25 Elliptical,,999.99,http://images.acmesports.sports/SOLE+E25+Elliptical',\n",
       " '40,3,Quik Shade Summit SX170 10 FT. x 10 FT. Canop,,199.99,http://images.acmesports.sports/Quik+Shade+Summit+SX170+10+FT.+x+10+FT.+Canopy',\n",
       " \"32,3,PUMA Men's evoPOWER 1 Tricks FG Soccer Cleat,,189.99,http://images.acmesports.sports/PUMA+Men%27s+evoPOWER+1+Tricks+FG+Soccer+Cleat\"]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b99194d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Union\n",
    "#Number of customer placed orders in july and august"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0cbbd252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,2013-07-25 00:00:00.0,11599,CLOSED',\n",
       " '2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n",
       " '3,2013-07-25 00:00:00.0,12111,COMPLETE',\n",
       " '4,2013-07-25 00:00:00.0,8827,CLOSED',\n",
       " '5,2013-07-25 00:00:00.0,11318,COMPLETE']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0628d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "jlyOrd =ord.filter(lambda x : x.split(',')[1].split('-')[1]==\"07\" ).map(lambda x : x.split(',')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e364439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6001"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jlyOrd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc59240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augOrd =ord.filter(lambda x : x.split(',')[1].split('-')[1]==\"08\" ).map(lambda x : x.split(',')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b495e763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5680"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augOrd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "73b2166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11681"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jlyOrd.union(augOrd).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0221057c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7633"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jlyOrd.union(augOrd).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5be34f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jlyOrd.intersection(augOrd).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "66f8f1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3836"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jlyOrd.subtract(augOrd).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a52f2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =spark.sparkContext.parallelize(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cde4a914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 19, 20, 29, 35, 47, 61, 62, 71, 72, 77, 81, 86, 87, 91]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sample(withReplacement=False,fraction=0.1,seed=10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eefbf164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 14, 14, 18, 45, 76, 89]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sample(withReplacement=True,fraction=0.1,seed=10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1a770b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 14, 14, 18, 45, 76, 89]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sample(withReplacement=True,fraction=0.1,seed=10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12dc5616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 56, 81, 11, 71, 22, 96, 34, 4, 82]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeSample(withReplacement=True,num=10,seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e0002b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87, 23, 24, 71, 20, 9, 91, 77, 84, 68]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.takeSample(withReplacement=False,num=10,seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f652719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.range(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04d535a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.select(df.id, df.id * 2, df.id*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3a7e2d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =df.rdd.map(lambda x : str(x[0]) +','+str(x[1])+','+str(x[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "617fae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,0,0', '1,2,3', '2,4,6', '3,6,9']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b57913fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =spark.sparkContext.textFile('c:/practice/orders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f033b6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8cb3f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1= rdd.repartition(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a829389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912031aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b03f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [('babjee',45),('ram',40),('sham',40),('sruthi',25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3caeb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(lst,schema=[\"Name\",\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469b51e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|babjee| 45|\n",
      "|   ram| 40|\n",
      "|  sham| 40|\n",
      "|sruthi| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ffe4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b62342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(Name='babjee', Age=45), Row(Name='ram', Age=40)],\n",
       " [Row(Name='sham', Age=40), Row(Name='sruthi', Age=25)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77526f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6014f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a7eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0003f324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04bdb1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c231944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.range(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd35ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a7a72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method range in module pyspark.sql.session:\n",
      "\n",
      "range(start: int, end: Optional[int] = None, step: int = 1, numPartitions: Optional[int] = None) -> pyspark.sql.dataframe.DataFrame method of pyspark.sql.session.SparkSession instance\n",
      "    Create a :class:`DataFrame` with single :class:`pyspark.sql.types.LongType` column named\n",
      "    ``id``, containing elements in a range from ``start`` to ``end`` (exclusive) with\n",
      "    step value ``step``.\n",
      "    \n",
      "    .. versionadded:: 2.0.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    start : int\n",
      "        the start value\n",
      "    end : int, optional\n",
      "        the end value (exclusive)\n",
      "    step : int, optional\n",
      "        the incremental step (default: 1)\n",
      "    numPartitions : int, optional\n",
      "        the number of partitions of the DataFrame\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`DataFrame`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> spark.range(1, 7, 2).show()\n",
      "    +---+\n",
      "    | id|\n",
      "    +---+\n",
      "    |  1|\n",
      "    |  3|\n",
      "    |  5|\n",
      "    +---+\n",
      "    \n",
      "    If only one argument is specified, it will be used as the end value.\n",
      "    \n",
      "    >>> spark.range(3).show()\n",
      "    +---+\n",
      "    | id|\n",
      "    +---+\n",
      "    |  0|\n",
      "    |  1|\n",
      "    |  2|\n",
      "    +---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spark.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9cc8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(0,11,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0596b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  2|\n",
      "|  4|\n",
      "|  6|\n",
      "|  8|\n",
      "| 10|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "defc3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(1000,numPartitions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5aa04a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f11dbf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab5887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data frame from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d270542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[('Robert',40),('James',25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f65a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc77ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|    _1| _2|\n",
      "+------+---+\n",
      "|Robert| 40|\n",
      "| James| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a6a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2271b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(lst,[\"Name\",\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13f94704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Robert| 40|\n",
      "| James| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5124eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(lst ,schema=('Name string, Age int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f3bb2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58bd2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic =[{\"Name\":\"Robert\", \"Age\":20},{\"Name\":\"Jame\", \"Age\":25}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64c3f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5eec8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|Age|  Name|\n",
      "+---+------+\n",
      "| 20|Robert|\n",
      "| 25|  Jame|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae9c5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [('Robert',40),('James',40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66d20375",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =spark.sparkContext.parallelize(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1d50b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(rdd,['Name','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d2668c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Robert| 40|\n",
      "| James| 40|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7058bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d5e94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r =Row(Name='Ram',Age=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46f564ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ram'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6007a986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce17bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd =spark.sparkContext.parallelize([Row(Name='Ram',Age=30),Row(Name='James',Age=25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20a461f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Name='Ram', Age=30)\n",
      "Row(Name='James', Age=25)\n"
     ]
    }
   ],
   "source": [
    "for i in rdd.collect():print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb13686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92123b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|  Ram| 30|\n",
      "|James| 25|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1ca2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prands as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5fc73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating data frame using pyhon pands\n",
    "data =[['tom',30],['james',30],['sunil',20]]\n",
    "df_pandas =pd.DataFrame(data,columns=['Name','Age'])\n",
    "df=spark.createDataFrame(df_panda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "076c1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst =[('Robet',101),('James',102)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7aedd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(lst,[\"EmpName\",\"DeptNo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce09c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"emp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "233d2c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|EmpName|DeptNo|\n",
      "+-------+------+\n",
      "|  Robet|   101|\n",
      "|  James|   102|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from emp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8adaa4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|EmpName|DeptNo|\n",
      "+-------+------+\n",
      "|  James|   102|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from emp where EmpName='James'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f29bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GlobalTempView\n",
    "df.createOrReplaceGlobalTempView(\"emp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1f79840",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `emp1` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [emp1], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m spark\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect * from emp1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[1;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[0;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[0;32m   1630\u001b[0m         )\n\u001b[1;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39msql(sqlQuery, litArgs), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `emp1` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [emp1], [], false\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from emp1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46676be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|EmpName|DeptNo|\n",
      "+-------+------+\n",
      "|  Robet|   101|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from global_temp.emp1 where deptno=101\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b2a92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d26eecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"emp_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a14cb692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|EmpName|DeptNo|\n",
      "+-------+------+\n",
      "|  Robet|   101|\n",
      "|  James|   102|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from emp_v\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e56ddc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.table(\"emp_v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc28bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|EmpName|DeptNo|\n",
      "+-------+------+\n",
      "|  Robet|   101|\n",
      "|  James|   102|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17277a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-LJE0474:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=Demo>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9264382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76de3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions',300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc24b417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'300'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get('spark.sql.shuffle.partitions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1bf5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.read.load('c:/practice/orders',format='csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "057589d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+---------------+\n",
      "|_c0|                 _c1|  _c2|            _c3|\n",
      "+---+--------------------+-----+---------------+\n",
      "|  1|2013-07-25 00:00:...|11599|         CLOSED|\n",
      "|  2|2013-07-25 00:00:...|  256|PENDING_PAYMENT|\n",
      "|  3|2013-07-25 00:00:...|12111|       COMPLETE|\n",
      "|  4|2013-07-25 00:00:...| 8827|         CLOSED|\n",
      "|  5|2013-07-25 00:00:...|11318|       COMPLETE|\n",
      "|  6|2013-07-25 00:00:...| 7130|       COMPLETE|\n",
      "|  7|2013-07-25 00:00:...| 4530|       COMPLETE|\n",
      "|  8|2013-07-25 00:00:...| 2911|     PROCESSING|\n",
      "|  9|2013-07-25 00:00:...| 5657|PENDING_PAYMENT|\n",
      "| 10|2013-07-25 00:00:...| 5648|PENDING_PAYMENT|\n",
      "| 11|2013-07-25 00:00:...|  918| PAYMENT_REVIEW|\n",
      "| 12|2013-07-25 00:00:...| 1837|         CLOSED|\n",
      "| 13|2013-07-25 00:00:...| 9149|PENDING_PAYMENT|\n",
      "| 14|2013-07-25 00:00:...| 9842|     PROCESSING|\n",
      "| 15|2013-07-25 00:00:...| 2568|       COMPLETE|\n",
      "| 16|2013-07-25 00:00:...| 7276|PENDING_PAYMENT|\n",
      "| 17|2013-07-25 00:00:...| 2667|       COMPLETE|\n",
      "| 18|2013-07-25 00:00:...| 1205|         CLOSED|\n",
      "| 19|2013-07-25 00:00:...| 9488|PENDING_PAYMENT|\n",
      "| 20|2013-07-25 00:00:...| 9198|     PROCESSING|\n",
      "+---+--------------------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "268cfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord=spark.read.load('c:/practice/orders',format='csv',schema=('OrderId int, OrderDate String,CustomerId int,OrderStatus String'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "70396111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+---------------+\n",
      "|OrderId|           OrderDate|CustomerId|    OrderStatus|\n",
      "+-------+--------------------+----------+---------------+\n",
      "|      1|2013-07-25 00:00:...|     11599|         CLOSED|\n",
      "|      2|2013-07-25 00:00:...|       256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25 00:00:...|     12111|       COMPLETE|\n",
      "|      4|2013-07-25 00:00:...|      8827|         CLOSED|\n",
      "|      5|2013-07-25 00:00:...|     11318|       COMPLETE|\n",
      "|      6|2013-07-25 00:00:...|      7130|       COMPLETE|\n",
      "|      7|2013-07-25 00:00:...|      4530|       COMPLETE|\n",
      "|      8|2013-07-25 00:00:...|      2911|     PROCESSING|\n",
      "|      9|2013-07-25 00:00:...|      5657|PENDING_PAYMENT|\n",
      "|     10|2013-07-25 00:00:...|      5648|PENDING_PAYMENT|\n",
      "|     11|2013-07-25 00:00:...|       918| PAYMENT_REVIEW|\n",
      "|     12|2013-07-25 00:00:...|      1837|         CLOSED|\n",
      "|     13|2013-07-25 00:00:...|      9149|PENDING_PAYMENT|\n",
      "|     14|2013-07-25 00:00:...|      9842|     PROCESSING|\n",
      "|     15|2013-07-25 00:00:...|      2568|       COMPLETE|\n",
      "|     16|2013-07-25 00:00:...|      7276|PENDING_PAYMENT|\n",
      "|     17|2013-07-25 00:00:...|      2667|       COMPLETE|\n",
      "|     18|2013-07-25 00:00:...|      1205|         CLOSED|\n",
      "|     19|2013-07-25 00:00:...|      9488|PENDING_PAYMENT|\n",
      "|     20|2013-07-25 00:00:...|      9198|     PROCESSING|\n",
      "+-------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83cd8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OrderId: integer (nullable = true)\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- OrderStatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1717e653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+----------+---------------+\n",
      "|OrderId|OrderDate            |CustomerId|OrderStatus    |\n",
      "+-------+---------------------+----------+---------------+\n",
      "|1      |2013-07-25 00:00:00.0|11599     |CLOSED         |\n",
      "|2      |2013-07-25 00:00:00.0|256       |PENDING_PAYMENT|\n",
      "|3      |2013-07-25 00:00:00.0|12111     |COMPLETE       |\n",
      "|4      |2013-07-25 00:00:00.0|8827      |CLOSED         |\n",
      "|5      |2013-07-25 00:00:00.0|11318     |COMPLETE       |\n",
      "+-------+---------------------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "badce0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.read.load('c:/practice/orders',format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a57e4810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22977fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.read.load(path='c:/practice/orders',format='csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e503bf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: timestamp (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "83e418f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.read.load('c:/practice/orders1',format='csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c77cd34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------+---------------+\n",
      "|OrderId|          OrderDate|CustomerId|    OrderStatus|\n",
      "+-------+-------------------+----------+---------------+\n",
      "|      1|2013-07-25 00:00:00|     11599|         CLOSED|\n",
      "|      2|2013-07-25 00:00:00|       256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25 00:00:00|     12111|       COMPLETE|\n",
      "|      4|2013-07-25 00:00:00|      8827|         CLOSED|\n",
      "|      5|2013-07-25 00:00:00|     11318|       COMPLETE|\n",
      "|      6|2013-07-25 00:00:00|      7130|       COMPLETE|\n",
      "|      7|2013-07-25 00:00:00|      4530|       COMPLETE|\n",
      "|      8|2013-07-25 00:00:00|      2911|     PROCESSING|\n",
      "|      9|2013-07-25 00:00:00|      5657|PENDING_PAYMENT|\n",
      "|     10|2013-07-25 00:00:00|      5648|PENDING_PAYMENT|\n",
      "|     11|2013-07-25 00:00:00|       918| PAYMENT_REVIEW|\n",
      "|     12|2013-07-25 00:00:00|      1837|         CLOSED|\n",
      "|     13|2013-07-25 00:00:00|      9149|PENDING_PAYMENT|\n",
      "|     14|2013-07-25 00:00:00|      9842|     PROCESSING|\n",
      "|     15|2013-07-25 00:00:00|      2568|       COMPLETE|\n",
      "|     16|2013-07-25 00:00:00|      7276|PENDING_PAYMENT|\n",
      "|     17|2013-07-25 00:00:00|      2667|       COMPLETE|\n",
      "|     18|2013-07-25 00:00:00|      1205|         CLOSED|\n",
      "|     19|2013-07-25 00:00:00|      9488|PENDING_PAYMENT|\n",
      "|     20|2013-07-25 00:00:00|      9198|     PROCESSING|\n",
      "+-------+-------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "456c0df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OrderId: integer (nullable = true)\n",
      " |-- OrderDate: timestamp (nullable = true)\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- OrderStatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bc6a72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#textfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "067a48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.read.load('c:/practice/orders',format='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "61f522fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|value                                        |\n",
      "+---------------------------------------------+\n",
      "|1,2013-07-25 00:00:00.0,11599,CLOSED         |\n",
      "|2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT  |\n",
      "|3,2013-07-25 00:00:00.0,12111,COMPLETE       |\n",
      "|4,2013-07-25 00:00:00.0,8827,CLOSED          |\n",
      "|5,2013-07-25 00:00:00.0,11318,COMPLETE       |\n",
      "|6,2013-07-25 00:00:00.0,7130,COMPLETE        |\n",
      "|7,2013-07-25 00:00:00.0,4530,COMPLETE        |\n",
      "|8,2013-07-25 00:00:00.0,2911,PROCESSING      |\n",
      "|9,2013-07-25 00:00:00.0,5657,PENDING_PAYMENT |\n",
      "|10,2013-07-25 00:00:00.0,5648,PENDING_PAYMENT|\n",
      "|11,2013-07-25 00:00:00.0,918,PAYMENT_REVIEW  |\n",
      "|12,2013-07-25 00:00:00.0,1837,CLOSED         |\n",
      "|13,2013-07-25 00:00:00.0,9149,PENDING_PAYMENT|\n",
      "|14,2013-07-25 00:00:00.0,9842,PROCESSING     |\n",
      "|15,2013-07-25 00:00:00.0,2568,COMPLETE       |\n",
      "|16,2013-07-25 00:00:00.0,7276,PENDING_PAYMENT|\n",
      "|17,2013-07-25 00:00:00.0,2667,COMPLETE       |\n",
      "|18,2013-07-25 00:00:00.0,1205,CLOSED         |\n",
      "|19,2013-07-25 00:00:00.0,9488,PENDING_PAYMENT|\n",
      "|20,2013-07-25 00:00:00.0,9198,PROCESSING     |\n",
      "+---------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ef313a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "159f1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.read.load('c:/practice/Order.parquet',format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d714113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+--------+---------------+\n",
      "|column_1|column_2             |column_3|column_4       |\n",
      "+--------+---------------------+--------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599   |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256     |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111   |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827    |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318   |COMPLETE       |\n",
      "|6       |2013-07-25 00:00:00.0|7130    |COMPLETE       |\n",
      "|7       |2013-07-25 00:00:00.0|4530    |COMPLETE       |\n",
      "|8       |2013-07-25 00:00:00.0|2911    |PROCESSING     |\n",
      "|9       |2013-07-25 00:00:00.0|5657    |PENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00.0|5648    |PENDING_PAYMENT|\n",
      "|11      |2013-07-25 00:00:00.0|918     |PAYMENT_REVIEW |\n",
      "|12      |2013-07-25 00:00:00.0|1837    |CLOSED         |\n",
      "|13      |2013-07-25 00:00:00.0|9149    |PENDING_PAYMENT|\n",
      "|14      |2013-07-25 00:00:00.0|9842    |PROCESSING     |\n",
      "|15      |2013-07-25 00:00:00.0|2568    |COMPLETE       |\n",
      "|16      |2013-07-25 00:00:00.0|7276    |PENDING_PAYMENT|\n",
      "|17      |2013-07-25 00:00:00.0|2667    |COMPLETE       |\n",
      "|18      |2013-07-25 00:00:00.0|1205    |CLOSED         |\n",
      "|19      |2013-07-25 00:00:00.0|9488    |PENDING_PAYMENT|\n",
      "|20      |2013-07-25 00:00:00.0|9198    |PROCESSING     |\n",
      "+--------+---------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e7897913",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of Apache Avro Data Source Guide.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39mspark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc:/practice/order.avro\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(path))\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of Apache Avro Data Source Guide."
     ]
    }
   ],
   "source": [
    "df =spark.read.load('c:/practice/order.avro',format='avro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35dfde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spark ETl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262b8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b701add",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord =spark.read.load('c:/practice/orders',format='csv',sep=',', schema=('order_id int, order_date timestamp,\\\n",
    "                                                                         order_customer_id int, order_status string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2519e6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717a728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('Robet',30,40,40),('Ram',31,33,29),('Ram',31,33,99),('Ram',31,33,29)]\n",
    "emp=spark.createDataFrame(data =data, schema=['Name','score1','score2','score3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3abd469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+\n",
      "| Name|score1|score2|score3|\n",
      "+-----+------+------+------+\n",
      "|Robet|    30|    40|    40|\n",
      "|  Ram|    31|    33|    29|\n",
      "|  Ram|    31|    33|    99|\n",
      "|  Ram|    31|    33|    29|\n",
      "+-----+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081643b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+-------+\n",
      "|order_id|order_id|order_id|order10|\n",
      "+--------+--------+--------+-------+\n",
      "|       1|       1|       1|     11|\n",
      "|       2|       2|       2|     12|\n",
      "|       3|       3|       3|     13|\n",
      "|       4|       4|       4|     14|\n",
      "|       5|       5|       5|     15|\n",
      "|       6|       6|       6|     16|\n",
      "|       7|       7|       7|     17|\n",
      "|       8|       8|       8|     18|\n",
      "|       9|       9|       9|     19|\n",
      "|      10|      10|      10|     20|\n",
      "|      11|      11|      11|     21|\n",
      "|      12|      12|      12|     22|\n",
      "|      13|      13|      13|     23|\n",
      "|      14|      14|      14|     24|\n",
      "|      15|      15|      15|     25|\n",
      "|      16|      16|      16|     26|\n",
      "|      17|      17|      17|     27|\n",
      "|      18|      18|      18|     28|\n",
      "|      19|      19|      19|     29|\n",
      "|      20|      20|      20|     30|\n",
      "+--------+--------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_id, 'order_id', \"order_id\", (ord.order_id+10).alias('order10')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0075ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38c81db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|   order_status|order_status_lower|\n",
      "+---------------+------------------+\n",
      "|         CLOSED|            closed|\n",
      "|PENDING_PAYMENT|   pending_payment|\n",
      "|       COMPLETE|          complete|\n",
      "|         CLOSED|            closed|\n",
      "|       COMPLETE|          complete|\n",
      "|       COMPLETE|          complete|\n",
      "|       COMPLETE|          complete|\n",
      "|     PROCESSING|        processing|\n",
      "|PENDING_PAYMENT|   pending_payment|\n",
      "|PENDING_PAYMENT|   pending_payment|\n",
      "| PAYMENT_REVIEW|    payment_review|\n",
      "|         CLOSED|            closed|\n",
      "|PENDING_PAYMENT|   pending_payment|\n",
      "|     PROCESSING|        processing|\n",
      "|       COMPLETE|          complete|\n",
      "|PENDING_PAYMENT|   pending_payment|\n",
      "|       COMPLETE|          complete|\n",
      "|         CLOSED|            closed|\n",
      "|PENDING_PAYMENT|   pending_payment|\n",
      "|     PROCESSING|        processing|\n",
      "+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_status, lower(ord.order_status).alias('order_status_lower')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb6ffcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e484d2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|orderyear|\n",
      "+---------+\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "|     2013|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(substring(ord.order_date,1,4).alias('orderyear')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5626f7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|order_year|\n",
      "+----------+\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "|      2013|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.selectExpr(\"substring(order_date,1,4) as order_year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff2ed1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|lower_order_status|\n",
      "+------------------+\n",
      "|            closed|\n",
      "|   pending_payment|\n",
      "|          complete|\n",
      "|            closed|\n",
      "|          complete|\n",
      "|          complete|\n",
      "|          complete|\n",
      "|        processing|\n",
      "|   pending_payment|\n",
      "|   pending_payment|\n",
      "|    payment_review|\n",
      "|            closed|\n",
      "|   pending_payment|\n",
      "|        processing|\n",
      "|          complete|\n",
      "|   pending_payment|\n",
      "|          complete|\n",
      "|            closed|\n",
      "|   pending_payment|\n",
      "|        processing|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.selectExpr(\" lower(order_status) as lower_order_status\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2eff1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6f4b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|lower(order_status)|\n",
      "+-------------------+\n",
      "|             closed|\n",
      "|    pending_payment|\n",
      "|           complete|\n",
      "|             closed|\n",
      "|           complete|\n",
      "|           complete|\n",
      "|           complete|\n",
      "|         processing|\n",
      "|    pending_payment|\n",
      "|    pending_payment|\n",
      "|     payment_review|\n",
      "|             closed|\n",
      "|    pending_payment|\n",
      "|         processing|\n",
      "|           complete|\n",
      "|    pending_payment|\n",
      "|           complete|\n",
      "|             closed|\n",
      "|    pending_payment|\n",
      "|         processing|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(lower(ord.order_status)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f97b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With colum api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92cd7a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47140260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|order_year|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|      2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|      2013|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|      2013|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|      2013|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|      2013|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|      2013|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|      2013|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|      2013|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|      2013|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|      2013|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|      2013|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|      2013|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|      2013|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|      2013|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|      2013|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|      2013|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|      2013|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|      2013|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|      2013|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|      2013|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('order_year',substring(ord.order_date,1,4)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7bbe9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|      2013|            11599|         CLOSED|\n",
      "|       2|      2013|              256|PENDING_PAYMENT|\n",
      "|       3|      2013|            12111|       COMPLETE|\n",
      "|       4|      2013|             8827|         CLOSED|\n",
      "|       5|      2013|            11318|       COMPLETE|\n",
      "|       6|      2013|             7130|       COMPLETE|\n",
      "|       7|      2013|             4530|       COMPLETE|\n",
      "|       8|      2013|             2911|     PROCESSING|\n",
      "|       9|      2013|             5657|PENDING_PAYMENT|\n",
      "|      10|      2013|             5648|PENDING_PAYMENT|\n",
      "|      11|      2013|              918| PAYMENT_REVIEW|\n",
      "|      12|      2013|             1837|         CLOSED|\n",
      "|      13|      2013|             9149|PENDING_PAYMENT|\n",
      "|      14|      2013|             9842|     PROCESSING|\n",
      "|      15|      2013|             2568|       COMPLETE|\n",
      "|      16|      2013|             7276|PENDING_PAYMENT|\n",
      "|      17|      2013|             2667|       COMPLETE|\n",
      "|      18|      2013|             1205|         CLOSED|\n",
      "|      19|      2013|             9488|PENDING_PAYMENT|\n",
      "|      20|      2013|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#if you give alias name as colum name it will modify existing colum\n",
    "ord.withColumn('order_date',substring(ord.order_date,1,4)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a43a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#withColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e1f4751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|           New_Date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumnRenamed('order_date','New_Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f39d8faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d05082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+\n",
      "|order_customer_id|   order_status|\n",
      "+-----------------+---------------+\n",
      "|            11599|         CLOSED|\n",
      "|              256|PENDING_PAYMENT|\n",
      "|            12111|       COMPLETE|\n",
      "|             8827|         CLOSED|\n",
      "|            11318|       COMPLETE|\n",
      "|             7130|       COMPLETE|\n",
      "|             4530|       COMPLETE|\n",
      "|             2911|     PROCESSING|\n",
      "|             5657|PENDING_PAYMENT|\n",
      "|             5648|PENDING_PAYMENT|\n",
      "|              918| PAYMENT_REVIEW|\n",
      "|             1837|         CLOSED|\n",
      "|             9149|PENDING_PAYMENT|\n",
      "|             9842|     PROCESSING|\n",
      "|             2568|       COMPLETE|\n",
      "|             7276|PENDING_PAYMENT|\n",
      "|             2667|       COMPLETE|\n",
      "|             1205|         CLOSED|\n",
      "|             9488|PENDING_PAYMENT|\n",
      "|             9198|     PROCESSING|\n",
      "+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.drop('order_id','order_date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fba5218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropDuplicate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a0bdf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+\n",
      "| Name|score1|score2|score3|\n",
      "+-----+------+------+------+\n",
      "|Robet|    30|    40|    40|\n",
      "|  Ram|    31|    33|    29|\n",
      "|  Ram|    31|    33|    99|\n",
      "|  Ram|    31|    33|    29|\n",
      "+-----+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f57d7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+\n",
      "| Name|score1|score2|score3|\n",
      "+-----+------+------+------+\n",
      "|Robet|    30|    40|    40|\n",
      "|  Ram|    31|    33|    99|\n",
      "|  Ram|    31|    33|    29|\n",
      "+-----+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8259866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+\n",
      "| Name|score1|score2|score3|\n",
      "+-----+------+------+------+\n",
      "|  Ram|    31|    33|    29|\n",
      "|Robet|    30|    40|    40|\n",
      "+-----+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp.dropDuplicates(['Name','score1','score2']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31a97c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filer api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c229ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|(order_id < 5)|\n",
      "+--------------+\n",
      "|          true|\n",
      "|          true|\n",
      "|          true|\n",
      "|          true|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "|         false|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_id <5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d10e51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.where(ord.order_id <5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "922374ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|      CLOSED|\n",
      "|       4|2013-07-25 00:00:00|             8827|      CLOSED|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.where((ord.order_id <10) & (ord.order_status=='CLOSED')) .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e5f71fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|order_id|order_status|\n",
      "+--------+------------+\n",
      "|       1|      CLOSED|\n",
      "|       4|      CLOSED|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_id,ord.order_status).where((ord.order_id <10) & (ord.order_status=='CLOSED')) .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fade0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|      CLOSED|\n",
      "|       3|2013-07-25 00:00:00|            12111|    COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|      CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|    COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|    COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|    COMPLETE|\n",
      "|      12|2013-07-25 00:00:00|             1837|      CLOSED|\n",
      "|      15|2013-07-25 00:00:00|             2568|    COMPLETE|\n",
      "|      17|2013-07-25 00:00:00|             2667|    COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|      CLOSED|\n",
      "|      22|2013-07-25 00:00:00|              333|    COMPLETE|\n",
      "|      24|2013-07-25 00:00:00|            11441|      CLOSED|\n",
      "|      25|2013-07-25 00:00:00|             9503|      CLOSED|\n",
      "|      26|2013-07-25 00:00:00|             7562|    COMPLETE|\n",
      "|      28|2013-07-25 00:00:00|              656|    COMPLETE|\n",
      "|      32|2013-07-25 00:00:00|             3960|    COMPLETE|\n",
      "|      35|2013-07-25 00:00:00|             4840|    COMPLETE|\n",
      "|      37|2013-07-25 00:00:00|             5863|      CLOSED|\n",
      "|      45|2013-07-25 00:00:00|             2636|    COMPLETE|\n",
      "|      51|2013-07-25 00:00:00|            12271|      CLOSED|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.where(\"order_status in ('CLOSED','COMPLETE')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18c87f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|      CLOSED|\n",
      "|       4|2013-07-25 00:00:00|             8827|      CLOSED|\n",
      "|      12|2013-07-25 00:00:00|             1837|      CLOSED|\n",
      "|      18|2013-07-25 00:00:00|             1205|      CLOSED|\n",
      "|      24|2013-07-25 00:00:00|            11441|      CLOSED|\n",
      "|      25|2013-07-25 00:00:00|             9503|      CLOSED|\n",
      "|      37|2013-07-25 00:00:00|             5863|      CLOSED|\n",
      "|      51|2013-07-25 00:00:00|            12271|      CLOSED|\n",
      "|      57|2013-07-25 00:00:00|             7073|      CLOSED|\n",
      "|      61|2013-07-25 00:00:00|             4791|      CLOSED|\n",
      "|      62|2013-07-25 00:00:00|             9111|      CLOSED|\n",
      "|      87|2013-07-25 00:00:00|             3065|      CLOSED|\n",
      "|      90|2013-07-25 00:00:00|             9131|      CLOSED|\n",
      "|     101|2013-07-25 00:00:00|             5116|      CLOSED|\n",
      "|     116|2013-07-26 00:00:00|             8763|      CLOSED|\n",
      "|     129|2013-07-26 00:00:00|             9937|      CLOSED|\n",
      "|     133|2013-07-26 00:00:00|            10604|      CLOSED|\n",
      "|     191|2013-07-26 00:00:00|               16|      CLOSED|\n",
      "|     201|2013-07-26 00:00:00|             9055|      CLOSED|\n",
      "|     211|2013-07-26 00:00:00|            10372|      CLOSED|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.where(ord.order_status.isin(['CLOSED'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27935cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.filter(ord.order_id <10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b1c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c73d152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+------------+\n",
      "|order_id|         order_date|order_customer_id|order_status|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "|     527|2013-07-28 00:00:00|             5426|    CANCELED|\n",
      "|    1435|2013-08-01 00:00:00|             1879|    CANCELED|\n",
      "|     552|2013-07-28 00:00:00|             1445|    CANCELED|\n",
      "|     112|2013-07-26 00:00:00|             5375|    CANCELED|\n",
      "|     564|2013-07-28 00:00:00|             2216|    CANCELED|\n",
      "|     955|2013-07-30 00:00:00|             8117|    CANCELED|\n",
      "|    1383|2013-08-01 00:00:00|             1753|    CANCELED|\n",
      "|     962|2013-07-30 00:00:00|             9492|    CANCELED|\n",
      "|     607|2013-07-28 00:00:00|             6376|    CANCELED|\n",
      "|    1013|2013-07-30 00:00:00|             1903|    CANCELED|\n",
      "|     667|2013-07-28 00:00:00|             4726|    CANCELED|\n",
      "|    1169|2013-07-31 00:00:00|             3971|    CANCELED|\n",
      "|     717|2013-07-29 00:00:00|             8208|    CANCELED|\n",
      "|    1186|2013-07-31 00:00:00|            11947|    CANCELED|\n",
      "|     753|2013-07-29 00:00:00|             5094|    CANCELED|\n",
      "|    1190|2013-07-31 00:00:00|            12360|    CANCELED|\n",
      "|      50|2013-07-25 00:00:00|             5225|    CANCELED|\n",
      "|    1313|2013-08-01 00:00:00|             3471|    CANCELED|\n",
      "|     716|2013-07-29 00:00:00|             2581|    CANCELED|\n",
      "|    1365|2013-08-01 00:00:00|             8567|    CANCELED|\n",
      "+--------+-------------------+-----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.sort(ord.order_status.asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4e0ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|      69|2013-07-25 00:00:00|             2821|SUSPECTED_FRAUD|\n",
      "|   57770|2013-07-25 00:00:00|             7451|SUSPECTED_FRAUD|\n",
      "|      29|2013-07-25 00:00:00|              196|     PROCESSING|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "|      34|2013-07-25 00:00:00|             4189|     PROCESSING|\n",
      "|      38|2013-07-25 00:00:00|            11586|     PROCESSING|\n",
      "|      48|2013-07-25 00:00:00|            12186|     PROCESSING|\n",
      "|      53|2013-07-25 00:00:00|             4701|     PROCESSING|\n",
      "|      81|2013-07-25 00:00:00|              674|     PROCESSING|\n",
      "|      84|2013-07-25 00:00:00|             6789|     PROCESSING|\n",
      "|      94|2013-07-25 00:00:00|            11589|     PROCESSING|\n",
      "|     100|2013-07-25 00:00:00|            12131|     PROCESSING|\n",
      "|     103|2013-07-25 00:00:00|            12256|     PROCESSING|\n",
      "|   57765|2013-07-25 00:00:00|             2876|     PROCESSING|\n",
      "|   57783|2013-07-25 00:00:00|             2884|     PROCESSING|\n",
      "|   57785|2013-07-25 00:00:00|            12347|     PROCESSING|\n",
      "|      58|2013-07-25 00:00:00|             9213|PENDING_PAYMENT|\n",
      "|      59|2013-07-25 00:00:00|            11644|PENDING_PAYMENT|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.sort(ord.order_date.asc(),ord.order_status.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae188d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|      69|2013-07-25 00:00:00|             2821|SUSPECTED_FRAUD|\n",
      "|   57770|2013-07-25 00:00:00|             7451|SUSPECTED_FRAUD|\n",
      "|      29|2013-07-25 00:00:00|              196|     PROCESSING|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "|      34|2013-07-25 00:00:00|             4189|     PROCESSING|\n",
      "|      38|2013-07-25 00:00:00|            11586|     PROCESSING|\n",
      "|      48|2013-07-25 00:00:00|            12186|     PROCESSING|\n",
      "|      53|2013-07-25 00:00:00|             4701|     PROCESSING|\n",
      "|      81|2013-07-25 00:00:00|              674|     PROCESSING|\n",
      "|      84|2013-07-25 00:00:00|             6789|     PROCESSING|\n",
      "|      94|2013-07-25 00:00:00|            11589|     PROCESSING|\n",
      "|     100|2013-07-25 00:00:00|            12131|     PROCESSING|\n",
      "|     103|2013-07-25 00:00:00|            12256|     PROCESSING|\n",
      "|   57765|2013-07-25 00:00:00|             2876|     PROCESSING|\n",
      "|   57783|2013-07-25 00:00:00|             2884|     PROCESSING|\n",
      "|   57785|2013-07-25 00:00:00|            12347|     PROCESSING|\n",
      "|      58|2013-07-25 00:00:00|             9213|PENDING_PAYMENT|\n",
      "|      59|2013-07-25 00:00:00|            11644|PENDING_PAYMENT|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.sort(ord.order_date,ord.order_status,ascending=[1,0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdca9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('a',1),('d',4),('c',3),('b',3),('e',5)]\n",
    "df =spark.createDataFrame(data,schema='col1 string, col2 int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3065f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   d|   4|\n",
      "|   c|   3|\n",
      "|   b|   3|\n",
      "|   e|   5|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a29f681f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(col1='a', col2=1), Row(col1='d', col2=4)],\n",
       " [Row(col1='c', col2=3), Row(col1='b', col2=3), Row(col1='e', col2=5)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f053ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   d|   4|\n",
      "|   a|   1|\n",
      "|   e|   5|\n",
      "|   c|   3|\n",
      "|   b|   3|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sortWithinPartitions( df.col2.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f05947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ac3ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =spark.createDataFrame([('apple',10),('orange',20),('mango',10),('pinaple',10)],schema='Name string, price int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44b83723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|price|\n",
      "+-------+-----+\n",
      "|  apple|   10|\n",
      "| orange|   20|\n",
      "|  mango|   10|\n",
      "|pinaple|   10|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5713a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =spark.createDataFrame([('apple',10),('orange',20),('sapota',10),('fig',10)],schema='Name string, price int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b2870ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  Name|price|\n",
      "+------+-----+\n",
      "| apple|   10|\n",
      "|orange|   20|\n",
      "|sapota|   10|\n",
      "|   fig|   10|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78571588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|price|\n",
      "+-------+-----+\n",
      "|  apple|   10|\n",
      "| orange|   20|\n",
      "|  mango|   10|\n",
      "|pinaple|   10|\n",
      "|  apple|   10|\n",
      "| orange|   20|\n",
      "| sapota|   10|\n",
      "|    fig|   10|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcf450c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|price|\n",
      "+-------+-----+\n",
      "|  apple|   10|\n",
      "| orange|   20|\n",
      "|  mango|   10|\n",
      "|pinaple|   10|\n",
      "| sapota|   10|\n",
      "|    fig|   10|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19d16db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|price|\n",
      "+-------+-----+\n",
      "|  apple|   10|\n",
      "| orange|   20|\n",
      "|  mango|   10|\n",
      "|pinaple|   10|\n",
      "|  apple|   10|\n",
      "| orange|   20|\n",
      "| sapota|   10|\n",
      "|    fig|   10|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d44e4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame([('a',1),('b',2)] ,schema='col1 string ,col2 int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d409b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5772890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame([(3,'c'),(4,'d')] ,schema='col2 int ,col1 string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32bb9fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col2|col1|\n",
      "+----+----+\n",
      "|   3|   c|\n",
      "|   4|   d|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ff6e229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   3|   c|\n",
      "|   4|   d|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b49bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "|   d|   4|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.unionByName(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dda0bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =spark.createDataFrame([('apple',10),('orange',20),('mango',10),('pinaple',10)],schema='Name string, price int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f688114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =spark.createDataFrame([('apple',10),('orange',20),('sapota',10),('fig',10)],schema='Name string, price int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aed76616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  Name|price|\n",
      "+------+-----+\n",
      "| apple|   10|\n",
      "|orange|   20|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersect(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c03396c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  Name|price|\n",
      "+------+-----+\n",
      "| apple|   10|\n",
      "|orange|   20|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.intersectAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ace10522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|price|\n",
      "+-------+-----+\n",
      "|  mango|   10|\n",
      "|pinaple|   10|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.exceptAll(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa4580df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4dd734fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame([(1,'Robert'),(2,'James'),(3,'Riya')], schema='empid int, ename string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "712b418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =spark.createDataFrame([(2,'India'),(4,'USA')], schema='empid int, country string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f31d8921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|empid| ename|\n",
      "+-----+------+\n",
      "|    1|Robert|\n",
      "|    2| James|\n",
      "|    3|  Riya|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1fc92b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|empid|country|\n",
      "+-----+-------+\n",
      "|    2|  India|\n",
      "|    4|    USA|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38018856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|empid|ename|country|\n",
      "+-----+-----+-------+\n",
      "|    2|James|  India|\n",
      "+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df2.empid).select(df1.empid,df1.ename,df2.country).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eeea4a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|empid|ename|country|\n",
      "+-----+-----+-------+\n",
      "|    2|James|  India|\n",
      "+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df2.empid , 'inner').select(df1.empid,df1.ename,df2.country).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05d07fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+\n",
      "|empid| ename|country|\n",
      "+-----+------+-------+\n",
      "|    1|Robert|   NULL|\n",
      "|    3|  Riya|   NULL|\n",
      "|    2| James|  India|\n",
      "+-----+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df2.empid , 'left').select(df1.empid,df1.ename,df2.country).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d7d40cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+\n",
      "|empid|ename|country|\n",
      "+-----+-----+-------+\n",
      "|    2|James|  India|\n",
      "| NULL| NULL|    USA|\n",
      "+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df2.empid , 'right').select(df1.empid,df1.ename,df2.country).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "048a5882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+\n",
      "|empid| ename|country|\n",
      "+-----+------+-------+\n",
      "|    1|Robert|   NULL|\n",
      "|    2| James|  India|\n",
      "|    3|  Riya|   NULL|\n",
      "| NULL|  NULL|    USA|\n",
      "+-----+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df2.empid , 'full').select(df1.empid,df1.ename,df2.country).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fb32a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+-------+\n",
      "|empid| ename|empid|country|\n",
      "+-----+------+-----+-------+\n",
      "|    1|Robert|    2|  India|\n",
      "|    1|Robert|    4|    USA|\n",
      "|    2| James|    2|  India|\n",
      "|    3|  Riya|    2|  India|\n",
      "|    2| James|    4|    USA|\n",
      "|    3|  Riya|    4|    USA|\n",
      "+-----+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df1.empid , 'cross').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "916dbcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|empid| ename|\n",
      "+-----+------+\n",
      "|    1|Robert|\n",
      "|    3|  Riya|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df2.empid , 'leftanti').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f6832687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You cant select column from df2 data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3921101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|empid|ename|\n",
      "+-----+-----+\n",
      "|    2|James|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,df1.empid ==df2.empid , 'leftsemi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7674627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+\n",
      "|empid| ename|country|\n",
      "+-----+------+-------+\n",
      "|    1|Robert|  India|\n",
      "|    1|Robert|    USA|\n",
      "|    2| James|  India|\n",
      "|    3|  Riya|  India|\n",
      "|    2| James|    USA|\n",
      "|    3|  Riya|    USA|\n",
      "+-----+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.crossJoin(df2).select(df1.empid,df1.ename,df2.country).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a33448a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =spark.createDataFrame([(1,'Robert',2),(2,'Riya',3),(3,'James',5)],'empid int, ename string, managerid int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c9d4ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+\n",
      "|empid| ename|managerid|\n",
      "+-----+------+---------+\n",
      "|    1|Robert|        2|\n",
      "|    2|  Riya|        3|\n",
      "|    3| James|        5|\n",
      "+-----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "26dd41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99e059d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function col in module pyspark.sql.functions:\n",
      "\n",
      "col(col: str) -> pyspark.sql.column.Column\n",
      "    Returns a :class:`~pyspark.sql.Column` based on the given column name.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    .. versionchanged:: 3.4.0\n",
      "        Supports Spark Connect.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    col : str\n",
      "        the name for the column\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    :class:`~pyspark.sql.Column`\n",
      "        the corresponding column instance.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> col('x')\n",
      "    Column<'x'>\n",
      "    >>> column('x')\n",
      "    Column<'x'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c66516ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+\n",
      "|empid| ename|managerid|\n",
      "+-----+------+---------+\n",
      "|    1|Robert|        2|\n",
      "|    2|  Riya|        3|\n",
      "|    3| James|        5|\n",
      "+-----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54c62cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+-----------+\n",
      "|empid| ename|managerid|managername|\n",
      "+-----+------+---------+-----------+\n",
      "|    1|Robert|        2|       Riya|\n",
      "|    2|  Riya|        3|      James|\n",
      "+-----+------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.alias(\"emp1\").join(df1.alias(\"emp2\"), col(\"emp1.managerid\")==col(\"emp2.empid\"), 'inner').\\\n",
    "    select(col(\"emp1.empid\"),col(\"emp1.ename\"),col(\"emp1.managerid\"),col(\"emp2.ename\").alias(\"managername\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "17ad58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+-----------+\n",
      "|empid| ename|managerid|managername|\n",
      "+-----+------+---------+-----------+\n",
      "|    1|Robert|        2|       Riya|\n",
      "|    2|  Riya|        3|      James|\n",
      "|    3| James|        5|       NULL|\n",
      "+-----+------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.alias(\"emp1\").join(df1.alias(\"emp2\"), col(\"emp1.managerid\")==col(\"emp2.empid\"), 'left').\\\n",
    "    select(col(\"emp1.empid\"),col(\"emp1.ename\"),col(\"emp1.managerid\"),col(\"emp2.ename\").alias(\"managername\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ac311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe api summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "88052ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordItems =spark.read.load('c:/practice/order_items',format='csv',sep=',',schema=\\\n",
    "        'order_item_id int, order_id int, product_id int, qunatity int, subtotal float, price float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa987a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+------+\n",
      "|order_item_id|order_id|product_id|qunatity|subtotal| price|\n",
      "+-------------+--------+----------+--------+--------+------+\n",
      "|            1|       1|       957|       1|  299.98|299.98|\n",
      "|            2|       2|      1073|       1|  199.99|199.99|\n",
      "|            3|       2|       502|       5|   250.0|  50.0|\n",
      "|            4|       2|       403|       1|  129.99|129.99|\n",
      "|            5|       4|       897|       2|   49.98| 24.99|\n",
      "|            6|       4|       365|       5|  299.95| 59.99|\n",
      "|            7|       4|       502|       3|   150.0|  50.0|\n",
      "|            8|       4|      1014|       4|  199.92| 49.98|\n",
      "|            9|       5|       957|       1|  299.98|299.98|\n",
      "|           10|       5|       365|       5|  299.95| 59.99|\n",
      "|           11|       5|      1014|       2|   99.96| 49.98|\n",
      "|           12|       5|       957|       1|  299.98|299.98|\n",
      "|           13|       5|       403|       1|  129.99|129.99|\n",
      "|           14|       7|      1073|       1|  199.99|199.99|\n",
      "|           15|       7|       957|       1|  299.98|299.98|\n",
      "|           16|       7|       926|       5|   79.95| 15.99|\n",
      "|           17|       8|       365|       3|  179.97| 59.99|\n",
      "|           18|       8|       365|       5|  299.95| 59.99|\n",
      "|           19|       8|      1014|       4|  199.92| 49.98|\n",
      "|           20|       8|       502|       1|    50.0|  50.0|\n",
      "+-------------+--------+----------+--------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3d19d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "|summary|    order_item_id|          order_id|       product_id|          qunatity|          subtotal|             price|\n",
      "+-------+-----------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "|  count|           172198|            172198|           172198|            172198|            172198|            172198|\n",
      "|   mean|          86099.5| 34442.56682423721|660.4877176273824|2.1821275508426345|199.32066922046081|133.75906959048717|\n",
      "| stddev|49709.42516431533|19883.325171992223|310.5144727900077|1.4663523175387168|112.74303987146766| 118.5589363325847|\n",
      "|    min|                1|                 1|               19|                 1|              9.99|              9.99|\n",
      "|    25%|            43033|             17204|              403|                 1|            119.98|              50.0|\n",
      "|    50%|            86085|             34464|              627|                 1|            199.92|             59.99|\n",
      "|    75%|           129134|             51682|             1004|                 3|            299.95|            199.99|\n",
      "|    max|           172198|             68883|             1073|                 5|           1999.99|           1999.99|\n",
      "+-------+-----------------+------------------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a76cee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             price|\n",
      "+-------+------------------+\n",
      "|  count|            172198|\n",
      "|   mean|133.75906959048717|\n",
      "| stddev| 118.5589363325847|\n",
      "|    min|              9.99|\n",
      "|    25%|              50.0|\n",
      "|    50%|             59.99|\n",
      "|    75%|            199.99|\n",
      "|    max|           1999.99|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.select(ordItems.price).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cf96845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "72152751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   avg|\n",
      "+------+\n",
      "|133.76|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.select(round(avg(ordItems.price),2).alias(\"avg\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b0c6e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----+--------------------+\n",
      "|avg   |max    |max |sum                 |\n",
      "+------+-------+----+--------------------+\n",
      "|133.76|1999.99|9.99|2.3033044265342712E7|\n",
      "+------+-------+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.select(round(avg(ordItems.price),2).alias(\"avg\"),\\\n",
    "                max(ordItems.price).alias(\"max\"),\\\n",
    "                min(ordItems.price).alias(\"max\"),\\\n",
    "                sum(ordItems.price).alias(\"sum\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "134261a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|sum                 |sumdistinct     |\n",
      "+--------------------+----------------+\n",
      "|2.3033044265342712E7|9832.41999053955|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.select(\n",
    "                sum(ordItems.price).alias(\"sum\"), sum_distinct(ordItems.price).alias(\"sumdistinct\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "24c90f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "| count|countdistinct|\n",
      "+------+-------------+\n",
      "|172198|           57|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.select(count(ordItems.price).alias(\"count\"), count_distinct(ordItems.price).alias(\"countdistinct\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "345af4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+-----+\n",
      "|order_item_id|order_id|product_id|qunatity|subtotal|price|\n",
      "+-------------+--------+----------+--------+--------+-----+\n",
      "|         6533|    2605|       775|       4|   39.96| 9.99|\n",
      "|        17878|    7140|       775|       4|   39.96| 9.99|\n",
      "|         6813|    2721|       775|       4|   39.96| 9.99|\n",
      "|          137|      58|       775|       2|   19.98| 9.99|\n",
      "|         7024|    2797|       775|       5|   49.95| 9.99|\n",
      "|          604|     243|       775|       3|   29.97| 9.99|\n",
      "|         8935|    3595|       775|       5|   49.95| 9.99|\n",
      "|         4264|    1713|       775|       2|   19.98| 9.99|\n",
      "|         9199|    3698|       775|       4|   39.96| 9.99|\n",
      "|         4548|    1820|       775|       4|   39.96| 9.99|\n",
      "|         9252|    3720|       775|       3|   29.97| 9.99|\n",
      "|         4866|    1944|       775|       1|    9.99| 9.99|\n",
      "|         9757|    3926|       775|       4|   39.96| 9.99|\n",
      "|         5409|    2159|       775|       5|   49.95| 9.99|\n",
      "|        10283|    4122|       775|       2|   19.98| 9.99|\n",
      "|         5613|    2241|       775|       3|   29.97| 9.99|\n",
      "|        10669|    4268|       775|       3|   29.97| 9.99|\n",
      "|         6391|    2558|       775|       4|   39.96| 9.99|\n",
      "|        11135|    4449|       775|       3|   29.97| 9.99|\n",
      "|        11535|    4600|       775|       2|   19.98| 9.99|\n",
      "+-------------+--------+----------+--------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.sort(ordItems.price).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c774ddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|first(price)|\n",
      "+------------+\n",
      "|        9.99|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.sort(ordItems.price).select(first(ordItems.price)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3ae135f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|last(price)|\n",
      "+-----------+\n",
      "|    1999.99|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.sort(ordItems.price).select(last(ordItems.price)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9dd50efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame([(1,100),(2,200),(3,50),(4,50)],'id int, salary int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0890b96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|salary|\n",
      "+---+------+\n",
      "|  1|   100|\n",
      "|  2|   200|\n",
      "|  3|    50|\n",
      "|  4|    50|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ec3bd549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+\n",
      "|list              |set           |\n",
      "+------------------+--------------+\n",
      "|[100, 200, 50, 50]|[100, 50, 200]|\n",
      "+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(collect_list(df.salary).alias('list'), collect_set(df.salary).alias('set')).show(truncate=False)\n",
    "#list contain duplicate values and set contain unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc4cda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('James','Sales','NY',9000,34),\n",
    "       ('Alicia','Sales','NY',8600,56),\n",
    "       ('Robert','Sales','CA',8100,30),\n",
    "       ('Lisa','Finance','CA',9000,24),\n",
    "       ('Deja','Finance','CA',9900,40),\n",
    "       ('Sugie','Finance','NY',8300,36),\n",
    "       ('Ram','Finance','NY',7900,53),\n",
    "       ('Kyle','Marketing','CA',8000,25),\n",
    "       ('Reid','Marketing','NY',9100,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a61b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=['ename','dept','state','salary','age'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4804413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame(data,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "76cc3f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+\n",
      "| ename|     dept|state|salary|age|\n",
      "+------+---------+-----+------+---+\n",
      "| James|    Sales|   NY|  9000| 34|\n",
      "|Alicia|    Sales|   NY|  8600| 56|\n",
      "|Robert|    Sales|   CA|  8100| 30|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|\n",
      "|  Deja|  Finance|   CA|  9900| 40|\n",
      "| Sugie|  Finance|   NY|  8300| 36|\n",
      "|   Ram|  Finance|   NY|  7900| 53|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|\n",
      "|  Reid|Marketing|   NY|  9100| 50|\n",
      "+------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5f4c286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ename: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c527b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|     dept|      avg(salary)|\n",
      "+---------+-----------------+\n",
      "|    Sales|8566.666666666666|\n",
      "|  Finance|           8775.0|\n",
      "|Marketing|           8550.0|\n",
      "+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept).avg(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "09300180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|     dept|sum_sal|\n",
      "+---------+-------+\n",
      "|    Sales|  25700|\n",
      "|  Finance|  35100|\n",
      "|Marketing|  17100|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept).sum(\"salary\").withColumnRenamed('sum(salary)','sum_sal').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4a2207b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|     dept|max_sal|\n",
      "+---------+-------+\n",
      "|    Sales|   9000|\n",
      "|  Finance|   9900|\n",
      "|Marketing|   9100|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept).max(\"salary\").withColumnRenamed('max(salary)','max_sal').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6e0ee6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+\n",
      "| ename|     dept|state|salary|age|\n",
      "+------+---------+-----+------+---+\n",
      "| James|    Sales|   NY|  9000| 34|\n",
      "|Alicia|    Sales|   NY|  8600| 56|\n",
      "|Robert|    Sales|   CA|  8100| 30|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|\n",
      "|  Deja|  Finance|   CA|  9900| 40|\n",
      "| Sugie|  Finance|   NY|  8300| 36|\n",
      "|   Ram|  Finance|   NY|  7900| 53|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|\n",
      "|  Reid|Marketing|   NY|  9100| 50|\n",
      "+------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "56d12d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+\n",
      "|     dept|state|sum(salary)|\n",
      "+---------+-----+-----------+\n",
      "|    Sales|   CA|       8100|\n",
      "|  Finance|   CA|      18900|\n",
      "|    Sales|   NY|      17600|\n",
      "|  Finance|   NY|      16200|\n",
      "|Marketing|   NY|       9100|\n",
      "|Marketing|   CA|       8000|\n",
      "+---------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept,df.state).sum(\"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "81f4b98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+--------+\n",
      "|     dept|state|min(salary)|min(age)|\n",
      "+---------+-----+-----------+--------+\n",
      "|    Sales|   CA|       8100|      30|\n",
      "|  Finance|   CA|       9000|      24|\n",
      "|    Sales|   NY|       8600|      34|\n",
      "|  Finance|   NY|       7900|      36|\n",
      "|Marketing|   NY|       9100|      50|\n",
      "|Marketing|   CA|       8000|      25|\n",
      "+---------+-----+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept,df.state).min(\"salary\",\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "16ff02a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-----------------+-------+\n",
      "|     dept|max_sal|min_sal|          avg_sal|sum_sal|\n",
      "+---------+-------+-------+-----------------+-------+\n",
      "|    Sales|   9000|   8100|8566.666666666666|  25700|\n",
      "|  Finance|   9900|   7900|           8775.0|  35100|\n",
      "|Marketing|   9100|   8000|           8550.0|  17100|\n",
      "+---------+-------+-------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept).agg(max(\"salary\").alias('max_sal'),\n",
    "                        min(\"salary\").alias('min_sal'),\n",
    "                        avg(\"salary\").alias('avg_sal'),\n",
    "                       sum(\"salary\").alias('sum_sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5247cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-------+-------+\n",
      "|     dept|max_sal|min_sal|avg_sal|sum_sal|\n",
      "+---------+-------+-------+-------+-------+\n",
      "|    Sales|   9000|   8600| 8800.0|  17600|\n",
      "|  Finance|   8300|   7900| 8100.0|  16200|\n",
      "|Marketing|   9100|   9100| 9100.0|   9100|\n",
      "+---------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.state=='NY').groupBy(df.dept).agg(max(\"salary\").alias('max_sal'),\n",
    "                        min(\"salary\").alias('min_sal'),\n",
    "                        avg(\"salary\").alias('avg_sal'),\n",
    "                       sum(\"salary\").alias('sum_sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "06c1871a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-----------------+-------+\n",
      "|     dept|max_sal|min_sal|          avg_sal|sum_sal|\n",
      "+---------+-------+-------+-----------------+-------+\n",
      "|    Sales|   9000|   8100|8566.666666666666|  25700|\n",
      "|  Finance|   9900|   7900|           8775.0|  35100|\n",
      "|Marketing|   9100|   8000|           8550.0|  17100|\n",
      "+---------+-------+-------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept).agg(max(\"salary\").alias('max_sal'),\n",
    "                        min(\"salary\").alias('min_sal'),\n",
    "                        avg(\"salary\").alias('avg_sal'),\n",
    "                       sum(\"salary\").alias('sum_sal')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3ef85a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+-----------------+-------+\n",
      "|     dept|max_sal|min_sal|          avg_sal|sum_sal|\n",
      "+---------+-------+-------+-----------------+-------+\n",
      "|    Sales|   9000|   8100|8566.666666666666|  25700|\n",
      "|Marketing|   9100|   8000|           8550.0|  17100|\n",
      "+---------+-------+-------+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.dept).agg(max(\"salary\").alias('max_sal'),\n",
    "                        min(\"salary\").alias('min_sal'),\n",
    "                        avg(\"salary\").alias('avg_sal'),\n",
    "                       sum(\"salary\").alias('sum_sal')).where(col('min_sal') >=8000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9afd03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=df.groupBy(df.dept).pivot('state').sum('salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cf5ef6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n",
      "|     dept|   CA|   NY|\n",
      "+---------+-----+-----+\n",
      "|    Sales| 8100|17600|\n",
      "|  Finance|18900|16200|\n",
      "|Marketing| 8000| 9100|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dft.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "83e48cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0cc4de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "262f6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.orderBy(df.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1f1bf33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----------+\n",
      "| ename|     dept|salary|row_number|\n",
      "+------+---------+------+----------+\n",
      "|  Deja|  Finance|  9900|         1|\n",
      "|  Reid|Marketing|  9100|         2|\n",
      "| James|    Sales|  9000|         3|\n",
      "|  Lisa|  Finance|  9000|         4|\n",
      "|Alicia|    Sales|  8600|         5|\n",
      "| Sugie|  Finance|  8300|         6|\n",
      "|Robert|    Sales|  8100|         7|\n",
      "|  Kyle|Marketing|  8000|         8|\n",
      "|   Ram|  Finance|  7900|         9|\n",
      "+------+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary).withColumn(\"row_number\",row_number().over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1a47559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.partitionBy(df.dept).orderBy(df.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5d65a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----------+\n",
      "| ename|     dept|salary|row_number|\n",
      "+------+---------+------+----------+\n",
      "|  Deja|  Finance|  9900|         1|\n",
      "|  Lisa|  Finance|  9000|         2|\n",
      "| Sugie|  Finance|  8300|         3|\n",
      "|   Ram|  Finance|  7900|         4|\n",
      "|  Reid|Marketing|  9100|         1|\n",
      "|  Kyle|Marketing|  8000|         2|\n",
      "| James|    Sales|  9000|         1|\n",
      "|Alicia|    Sales|  8600|         2|\n",
      "|Robert|    Sales|  8100|         3|\n",
      "+------+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary).withColumn(\"row_number\",row_number().over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "35f7245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.orderBy(df.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "83eb823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----+\n",
      "| ename|     dept|salary|rank|\n",
      "+------+---------+------+----+\n",
      "|  Deja|  Finance|  9900|   1|\n",
      "|  Reid|Marketing|  9100|   2|\n",
      "| James|    Sales|  9000|   3|\n",
      "|  Lisa|  Finance|  9000|   3|\n",
      "|Alicia|    Sales|  8600|   5|\n",
      "| Sugie|  Finance|  8300|   6|\n",
      "|Robert|    Sales|  8100|   7|\n",
      "|  Kyle|Marketing|  8000|   8|\n",
      "|   Ram|  Finance|  7900|   9|\n",
      "+------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary).withColumn(\"rank\",rank().over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b91500cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.partitionBy(df.dept).orderBy(df.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7030aee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----+\n",
      "| ename|     dept|salary|rank|\n",
      "+------+---------+------+----+\n",
      "|  Deja|  Finance|  9900|   1|\n",
      "|  Lisa|  Finance|  9000|   2|\n",
      "| Sugie|  Finance|  8300|   3|\n",
      "|   Ram|  Finance|  7900|   4|\n",
      "|  Reid|Marketing|  9100|   1|\n",
      "|  Kyle|Marketing|  8000|   2|\n",
      "| James|    Sales|  9000|   1|\n",
      "|Alicia|    Sales|  8600|   2|\n",
      "|Robert|    Sales|  8100|   3|\n",
      "+------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary).withColumn(\"rank\",rank().over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b5a1f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.orderBy(df.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3ad5f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----------+\n",
      "| ename|     dept|salary|dense_rank|\n",
      "+------+---------+------+----------+\n",
      "|  Deja|  Finance|  9900|         1|\n",
      "|  Reid|Marketing|  9100|         2|\n",
      "| James|    Sales|  9000|         3|\n",
      "|  Lisa|  Finance|  9000|         3|\n",
      "|Alicia|    Sales|  8600|         4|\n",
      "| Sugie|  Finance|  8300|         5|\n",
      "|Robert|    Sales|  8100|         6|\n",
      "|  Kyle|Marketing|  8000|         7|\n",
      "|   Ram|  Finance|  7900|         8|\n",
      "+------+---------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary).withColumn(\"dense_rank\",dense_rank().over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "954ef911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----+----------+\n",
      "| ename|     dept|salary|rank|dense_rank|\n",
      "+------+---------+------+----+----------+\n",
      "|  Deja|  Finance|  9900|   1|         1|\n",
      "|  Reid|Marketing|  9100|   2|         2|\n",
      "| James|    Sales|  9000|   3|         3|\n",
      "|  Lisa|  Finance|  9000|   3|         3|\n",
      "|Alicia|    Sales|  8600|   5|         4|\n",
      "| Sugie|  Finance|  8300|   6|         5|\n",
      "|Robert|    Sales|  8100|   7|         6|\n",
      "|  Kyle|Marketing|  8000|   8|         7|\n",
      "|   Ram|  Finance|  7900|   9|         8|\n",
      "+------+---------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"rank\",rank().over(spec))\\\n",
    ".withColumn(\"dense_rank\",dense_rank().over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d36a5893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------------+\n",
      "| ename|     dept|salary|percent_rank|\n",
      "+------+---------+------+------------+\n",
      "|  Deja|  Finance|  9900|         0.0|\n",
      "|  Reid|Marketing|  9100|       0.125|\n",
      "| James|    Sales|  9000|        0.25|\n",
      "|  Lisa|  Finance|  9000|        0.25|\n",
      "|Alicia|    Sales|  8600|         0.5|\n",
      "| Sugie|  Finance|  8300|       0.625|\n",
      "|Robert|    Sales|  8100|        0.75|\n",
      "|  Kyle|Marketing|  8000|       0.875|\n",
      "|   Ram|  Finance|  7900|         1.0|\n",
      "+------+---------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"percent_rank\",percent_rank().over(spec)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "303c086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------------------+\n",
      "| ename|     dept|salary|         cume_dist|\n",
      "+------+---------+------+------------------+\n",
      "|  Deja|  Finance|  9900|0.1111111111111111|\n",
      "|  Reid|Marketing|  9100|0.2222222222222222|\n",
      "| James|    Sales|  9000|0.4444444444444444|\n",
      "|  Lisa|  Finance|  9000|0.4444444444444444|\n",
      "|Alicia|    Sales|  8600|0.5555555555555556|\n",
      "| Sugie|  Finance|  8300|0.6666666666666666|\n",
      "|Robert|    Sales|  8100|0.7777777777777778|\n",
      "|  Kyle|Marketing|  8000|0.8888888888888888|\n",
      "|   Ram|  Finance|  7900|               1.0|\n",
      "+------+---------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"cume_dist\",cume_dist().over(spec)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "78d7adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+-----+\n",
      "| ename|     dept|salary|ntile|\n",
      "+------+---------+------+-----+\n",
      "|  Deja|  Finance|  9900|    1|\n",
      "|  Reid|Marketing|  9100|    1|\n",
      "| James|    Sales|  9000|    1|\n",
      "|  Lisa|  Finance|  9000|    2|\n",
      "|Alicia|    Sales|  8600|    2|\n",
      "| Sugie|  Finance|  8300|    3|\n",
      "|Robert|    Sales|  8100|    3|\n",
      "|  Kyle|Marketing|  8000|    4|\n",
      "|   Ram|  Finance|  7900|    4|\n",
      "+------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"ntile\",ntile(4).over(spec)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0b73567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----+\n",
      "| ename|     dept|salary| lag|\n",
      "+------+---------+------+----+\n",
      "|  Deja|  Finance|  9900|   0|\n",
      "|  Reid|Marketing|  9100|9900|\n",
      "| James|    Sales|  9000|9100|\n",
      "|  Lisa|  Finance|  9000|9000|\n",
      "|Alicia|    Sales|  8600|9000|\n",
      "| Sugie|  Finance|  8300|8600|\n",
      "|Robert|    Sales|  8100|8300|\n",
      "|  Kyle|Marketing|  8000|8100|\n",
      "|   Ram|  Finance|  7900|8000|\n",
      "+------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"lag\",lag(df.salary,1,0).over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9d5d665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.partitionBy(df.dept).orderBy(df.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aa18331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----+\n",
      "| ename|     dept|salary| lag|\n",
      "+------+---------+------+----+\n",
      "|  Deja|  Finance|  9900|   0|\n",
      "|  Lisa|  Finance|  9000|9900|\n",
      "| Sugie|  Finance|  8300|9000|\n",
      "|   Ram|  Finance|  7900|8300|\n",
      "|  Reid|Marketing|  9100|   0|\n",
      "|  Kyle|Marketing|  8000|9100|\n",
      "| James|    Sales|  9000|   0|\n",
      "|Alicia|    Sales|  8600|9000|\n",
      "|Robert|    Sales|  8100|8600|\n",
      "+------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"lag\",lag(df.salary,1,0).over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "aa2edb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.partitionBy(df.dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "14442abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+----+\n",
      "| ename|     dept|salary|lead|\n",
      "+------+---------+------+----+\n",
      "|  Deja|  Finance|  9900|9100|\n",
      "|  Reid|Marketing|  9100|9000|\n",
      "| James|    Sales|  9000|9000|\n",
      "|  Lisa|  Finance|  9000|8600|\n",
      "|Alicia|    Sales|  8600|8300|\n",
      "| Sugie|  Finance|  8300|8100|\n",
      "|Robert|    Sales|  8100|8000|\n",
      "|  Kyle|Marketing|  8000|7900|\n",
      "|   Ram|  Finance|  7900|   0|\n",
      "+------+---------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"lead\",lead(df.salary,1,0).over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3c2bcca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.partitionBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4986a1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+-----+-----------------+----+----+\n",
      "| ename|     dept|salary|  sum|              avg| max| min|\n",
      "+------+---------+------+-----+-----------------+----+----+\n",
      "| James|    Sales|  9000|77900|8655.555555555555|9900|7900|\n",
      "|Alicia|    Sales|  8600|77900|8655.555555555555|9900|7900|\n",
      "|Robert|    Sales|  8100|77900|8655.555555555555|9900|7900|\n",
      "|  Lisa|  Finance|  9000|77900|8655.555555555555|9900|7900|\n",
      "|  Deja|  Finance|  9900|77900|8655.555555555555|9900|7900|\n",
      "| Sugie|  Finance|  8300|77900|8655.555555555555|9900|7900|\n",
      "|   Ram|  Finance|  7900|77900|8655.555555555555|9900|7900|\n",
      "|  Kyle|Marketing|  8000|77900|8655.555555555555|9900|7900|\n",
      "|  Reid|Marketing|  9100|77900|8655.555555555555|9900|7900|\n",
      "+------+---------+------+-----+-----------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"sum\",sum(df.salary).over(spec))\\\n",
    ".withColumn(\"avg\",avg(df.salary).over(spec))\\\n",
    ".withColumn(\"max\",max(df.salary).over(spec))\\\n",
    ".withColumn(\"min\",min(df.salary).over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b8884589",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.partitionBy(df.dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a23dc110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+-----+-----------------+----+----+\n",
      "| ename|     dept|salary|  sum|              avg| max| min|\n",
      "+------+---------+------+-----+-----------------+----+----+\n",
      "|  Lisa|  Finance|  9000|35100|           8775.0|9900|7900|\n",
      "|  Deja|  Finance|  9900|35100|           8775.0|9900|7900|\n",
      "| Sugie|  Finance|  8300|35100|           8775.0|9900|7900|\n",
      "|   Ram|  Finance|  7900|35100|           8775.0|9900|7900|\n",
      "|  Kyle|Marketing|  8000|17100|           8550.0|9100|8000|\n",
      "|  Reid|Marketing|  9100|17100|           8550.0|9100|8000|\n",
      "| James|    Sales|  9000|25700|8566.666666666666|9000|8100|\n",
      "|Alicia|    Sales|  8600|25700|8566.666666666666|9000|8100|\n",
      "|Robert|    Sales|  8100|25700|8566.666666666666|9000|8100|\n",
      "+------+---------+------+-----+-----------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"sum\",sum(df.salary).over(spec))\\\n",
    ".withColumn(\"avg\",avg(df.salary).over(spec))\\\n",
    ".withColumn(\"max\",max(df.salary).over(spec))\\\n",
    ".withColumn(\"min\",min(df.salary).over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "02365299",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec =Window.orderBy(df.salary.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "13c9d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+-----+\n",
      "| ename|     dept|salary|first|\n",
      "+------+---------+------+-----+\n",
      "|  Deja|  Finance|  9900| 9900|\n",
      "|  Reid|Marketing|  9100| 9900|\n",
      "| James|    Sales|  9000| 9900|\n",
      "|  Lisa|  Finance|  9000| 9900|\n",
      "|Alicia|    Sales|  8600| 9900|\n",
      "| Sugie|  Finance|  8300| 9900|\n",
      "|Robert|    Sales|  8100| 9900|\n",
      "|  Kyle|Marketing|  8000| 9900|\n",
      "|   Ram|  Finance|  7900| 9900|\n",
      "+------+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.dept,df.salary)\\\n",
    ".withColumn(\"first\",first(df.salary).over(spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4f7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8791dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1875e9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "| 16|\n",
      "| 22|\n",
      "| 27|\n",
      "| 34|\n",
      "| 60|\n",
      "| 69|\n",
      "| 81|\n",
      "| 91|\n",
      "| 93|\n",
      "| 96|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(fraction=0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442aefde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  5|\n",
      "|  8|\n",
      "|  9|\n",
      "| 13|\n",
      "| 17|\n",
      "| 19|\n",
      "| 20|\n",
      "| 22|\n",
      "| 37|\n",
      "| 43|\n",
      "| 54|\n",
      "| 55|\n",
      "| 55|\n",
      "| 64|\n",
      "| 71|\n",
      "| 74|\n",
      "| 80|\n",
      "| 85|\n",
      "| 86|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(withReplacement=True,fraction=0.2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e18ae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  3|\n",
      "| 11|\n",
      "| 21|\n",
      "| 21|\n",
      "| 23|\n",
      "| 32|\n",
      "| 33|\n",
      "| 34|\n",
      "| 40|\n",
      "| 40|\n",
      "| 42|\n",
      "| 51|\n",
      "| 54|\n",
      "| 60|\n",
      "| 60|\n",
      "| 62|\n",
      "| 64|\n",
      "| 67|\n",
      "| 68|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(withReplacement=True,fraction=0.2,seed=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79191d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82d509d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+\n",
      "| ename|     dept|state|salary|age|\n",
      "+------+---------+-----+------+---+\n",
      "| James|    Sales|   NY|  9000| 34|\n",
      "|Alicia|    Sales|   NY|  8600| 56|\n",
      "|Robert|    Sales|   CA|  8100| 30|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|\n",
      "|  Deja|  Finance|   CA|  9900| 40|\n",
      "| Sugie|  Finance|   NY|  8300| 36|\n",
      "|   Ram|  Finance|   NY|  7900| 53|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|\n",
      "|  Reid|Marketing|   NY|  9100| 50|\n",
      "+------+---------+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monotonically_increasing_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff40d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+----------+\n",
      "| ename|     dept|state|salary|age|        id|\n",
      "+------+---------+-----+------+---+----------+\n",
      "| James|    Sales|   NY|  9000| 34|         0|\n",
      "|Alicia|    Sales|   NY|  8600| 56|         1|\n",
      "|Robert|    Sales|   CA|  8100| 30|         2|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|         3|\n",
      "|  Deja|  Finance|   CA|  9900| 40|8589934592|\n",
      "| Sugie|  Finance|   NY|  8300| 36|8589934593|\n",
      "|   Ram|  Finance|   NY|  7900| 53|8589934594|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|8589934595|\n",
      "|  Reid|Marketing|   NY|  9100| 50|8589934596|\n",
      "+------+---------+-----+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('id',monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34cbe7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+-------+\n",
      "| ename|     dept|state|salary|age|Country|\n",
      "+------+---------+-----+------+---+-------+\n",
      "| James|    Sales|   NY|  9000| 34|    USA|\n",
      "|Alicia|    Sales|   NY|  8600| 56|    USA|\n",
      "|Robert|    Sales|   CA|  8100| 30|    USA|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|    USA|\n",
      "|  Deja|  Finance|   CA|  9900| 40|    USA|\n",
      "| Sugie|  Finance|   NY|  8300| 36|    USA|\n",
      "|   Ram|  Finance|   NY|  7900| 53|    USA|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|    USA|\n",
      "|  Reid|Marketing|   NY|  9100| 50|    USA|\n",
      "+------+---------+-----+------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('Country',lit('USA')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81f95d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+-----------+\n",
      "| ename|     dept|state|salary|age|       col1|\n",
      "+------+---------+-----+------+---+-----------+\n",
      "| James|    Sales|   NY|  9000| 34| James:9000|\n",
      "|Alicia|    Sales|   NY|  8600| 56|Alicia:8600|\n",
      "|Robert|    Sales|   CA|  8100| 30|Robert:8100|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|  Lisa:9000|\n",
      "|  Deja|  Finance|   CA|  9900| 40|  Deja:9900|\n",
      "| Sugie|  Finance|   NY|  8300| 36| Sugie:8300|\n",
      "|   Ram|  Finance|   NY|  7900| 53|   Ram:7900|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|  Kyle:8000|\n",
      "|  Reid|Marketing|   NY|  9100| 50|  Reid:9100|\n",
      "+------+---------+-----+------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('col1',concat(df.ename,lit(':'),df.salary)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58702f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63aaef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+------+\n",
      "| ename|     dept|state|salary|age|length|\n",
      "+------+---------+-----+------+---+------+\n",
      "| James|    Sales|   NY|  9000| 34|     5|\n",
      "|Alicia|    Sales|   NY|  8600| 56|     6|\n",
      "|Robert|    Sales|   CA|  8100| 30|     6|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|     4|\n",
      "|  Deja|  Finance|   CA|  9900| 40|     4|\n",
      "| Sugie|  Finance|   NY|  8300| 36|     5|\n",
      "|   Ram|  Finance|   NY|  7900| 53|     3|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|     4|\n",
      "|  Reid|Marketing|   NY|  9100| 50|     4|\n",
      "+------+---------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('length',expr(\"length(ename)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b1ecdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+------+\n",
      "| ename|     dept|state|salary|age|length|\n",
      "+------+---------+-----+------+---+------+\n",
      "| James|    Sales|   NY|  9000| 34| JAMES|\n",
      "|Alicia|    Sales|   NY|  8600| 56|ALICIA|\n",
      "|Robert|    Sales|   CA|  8100| 30|ROBERT|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|  LISA|\n",
      "|  Deja|  Finance|   CA|  9900| 40|  DEJA|\n",
      "| Sugie|  Finance|   NY|  8300| 36| SUGIE|\n",
      "|   Ram|  Finance|   NY|  7900| 53|   RAM|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|  KYLE|\n",
      "|  Reid|Marketing|   NY|  9100| 50|  REID|\n",
      "+------+---------+-----+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('length',expr(\"upper(ename)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f925f8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+-------+\n",
      "| ename|     dept|state|salary|age|age_des|\n",
      "+------+---------+-----+------+---+-------+\n",
      "| James|    Sales|   NY|  9000| 34|  Adult|\n",
      "|Alicia|    Sales|   NY|  8600| 56| Senior|\n",
      "|Robert|    Sales|   CA|  8100| 30|  Adult|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|  Adult|\n",
      "|  Deja|  Finance|   CA|  9900| 40|  Adult|\n",
      "| Sugie|  Finance|   NY|  8300| 36|  Adult|\n",
      "|   Ram|  Finance|   NY|  7900| 53| Senior|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|  Adult|\n",
      "|  Reid|Marketing|   NY|  9100| 50|  Adult|\n",
      "+------+---------+-----+------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('age_des',expr(\"case when age >50 then 'Senior' else 'Adult' end\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a457d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+--------------+\n",
      "| ename|     dept|state|salary|age|      emp-dept|\n",
      "+------+---------+-----+------+---+--------------+\n",
      "| James|    Sales|   NY|  9000| 34|   James-Sales|\n",
      "|Alicia|    Sales|   NY|  8600| 56|  Alicia-Sales|\n",
      "|Robert|    Sales|   CA|  8100| 30|  Robert-Sales|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|  Lisa-Finance|\n",
      "|  Deja|  Finance|   CA|  9900| 40|  Deja-Finance|\n",
      "| Sugie|  Finance|   NY|  8300| 36| Sugie-Finance|\n",
      "|   Ram|  Finance|   NY|  7900| 53|   Ram-Finance|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|Kyle-Marketing|\n",
      "|  Reid|Marketing|   NY|  9100| 50|Reid-Marketing|\n",
      "+------+---------+-----+------+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('emp-dept',expr(\"ename ||'-'||dept\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "63d2428e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "| ename|age|age_10|\n",
      "+------+---+------+\n",
      "| James| 34|    44|\n",
      "|Alicia| 56|    66|\n",
      "|Robert| 30|    40|\n",
      "|  Lisa| 24|    34|\n",
      "|  Deja| 40|    50|\n",
      "| Sugie| 36|    46|\n",
      "|   Ram| 53|    63|\n",
      "|  Kyle| 25|    35|\n",
      "|  Reid| 50|    60|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,df.age,expr(\"age+10\").alias('age_10')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c17373e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark_partition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a7f3fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "003dcdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+-----------+\n",
      "| ename|     dept|state|salary|age|partitionid|\n",
      "+------+---------+-----+------+---+-----------+\n",
      "| James|    Sales|   NY|  9000| 34|          0|\n",
      "|Alicia|    Sales|   NY|  8600| 56|          0|\n",
      "|Robert|    Sales|   CA|  8100| 30|          0|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|          0|\n",
      "|  Deja|  Finance|   CA|  9900| 40|          1|\n",
      "| Sugie|  Finance|   NY|  8300| 36|          1|\n",
      "|   Ram|  Finance|   NY|  7900| 53|          1|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|          1|\n",
      "|  Reid|Marketing|   NY|  9100| 50|          1|\n",
      "+------+---------+-----+------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"partitionid\", spark_partition_id()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e10326ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "696ebf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+-------------------+\n",
      "| ename|     dept|state|salary|age|               rand|\n",
      "+------+---------+-----+------+---+-------------------+\n",
      "| James|    Sales|   NY|  9000| 34| 0.5996723933366402|\n",
      "|Alicia|    Sales|   NY|  8600| 56| 0.5649185186102964|\n",
      "|Robert|    Sales|   CA|  8100| 30| 0.9388775895322536|\n",
      "|  Lisa|  Finance|   CA|  9000| 24|0.17935290010205296|\n",
      "|  Deja|  Finance|   CA|  9900| 40| 0.6396141227834357|\n",
      "| Sugie|  Finance|   NY|  8300| 36|0.07022155145032771|\n",
      "|   Ram|  Finance|   NY|  7900| 53| 0.3103281117295451|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|0.36386047804145194|\n",
      "|  Reid|Marketing|   NY|  9100| 50| 0.7677060586249027|\n",
      "+------+---------+-----+------+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"rand\",rand(20)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "944deb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae982877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+------+---+--------------------+\n",
      "| ename|     dept|state|salary|age|               randn|\n",
      "+------+---------+-----+------+---+--------------------+\n",
      "| James|    Sales|   NY|  9000| 34|  0.5060974463351131|\n",
      "|Alicia|    Sales|   NY|  8600| 56|  0.3202289933218433|\n",
      "|Robert|    Sales|   CA|  8100| 30|  0.7885168481267597|\n",
      "|  Lisa|  Finance|   CA|  9000| 24| -0.3496663257478285|\n",
      "|  Deja|  Finance|   CA|  9900| 40|  1.6128589974640997|\n",
      "| Sugie|  Finance|   NY|  8300| 36|-0.16386638151271365|\n",
      "|   Ram|  Finance|   NY|  7900| 53| -0.6594558232170213|\n",
      "|  Kyle|Marketing|   CA|  8000| 25|  0.8456550639941086|\n",
      "|  Reid|Marketing|   NY|  9100| 50|  0.7301071180491999|\n",
      "+------+---------+-----+------+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('randn',randn(70)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13215b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#String Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16a7d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cb3bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord =spark.read.load('c:/practice/orders',format='csv',sep=',', schema=('order_id int, order_date timestamp,\\\n",
    "                                                                         order_customer_id int, order_status string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ac604b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "234bae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+\n",
      "|order_date         |order_split            |\n",
      "+-------------------+-----------------------+\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "|2013-07-25 00:00:00|[2013, 07, 25 00:00:00]|\n",
      "+-------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_date,split(ord.order_date,'-').alias('order_split')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eee970fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|order_date         |order_year|\n",
      "+-------------------+----------+\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "|2013-07-25 00:00:00|2013      |\n",
      "+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_date,\\\n",
    "           split(ord.order_date,'-')[0].alias('order_year')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48761c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-----------+----------+\n",
      "|order_date         |order_year|order_month|order_date|\n",
      "+-------------------+----------+-----------+----------+\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "|2013-07-25 00:00:00|2013      |07         |25        |\n",
      "+-------------------+----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_date,\n",
    "           split(ord.order_date,'-')[0].alias('order_year'),\n",
    "           split(ord.order_date,'-')[1].alias('order_month'),\n",
    "           split(split(ord.order_date,'-')[2],' ')[0].alias('order_date')\n",
    "          ).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a4174d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =spark.createDataFrame([('ab12cd23ef34ij',)],['s',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e40153e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|             s|\n",
      "+--------------+\n",
      "|ab12cd23ef34ij|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f89ae678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            col1|\n",
      "+----------------+\n",
      "|[ab, cd, ef, ij]|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(split(df1.s,'[1-9]+').alias('col1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dd5a3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "610933a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| ename|no of char|\n",
      "+------+----------+\n",
      "| James|         5|\n",
      "|Alicia|         6|\n",
      "|Robert|         6|\n",
      "|  Lisa|         4|\n",
      "|  Deja|         4|\n",
      "| Sugie|         5|\n",
      "|   Ram|         3|\n",
      "|  Kyle|         4|\n",
      "|  Reid|         4|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.ename,length(df.ename).alias('no of char')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "772f66b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|   order_status| initcap_status|\n",
      "+---------------+---------------+\n",
      "|         CLOSED|         Closed|\n",
      "|PENDING_PAYMENT|Pending_payment|\n",
      "|       COMPLETE|       Complete|\n",
      "|         CLOSED|         Closed|\n",
      "|       COMPLETE|       Complete|\n",
      "|       COMPLETE|       Complete|\n",
      "|       COMPLETE|       Complete|\n",
      "|     PROCESSING|     Processing|\n",
      "|PENDING_PAYMENT|Pending_payment|\n",
      "|PENDING_PAYMENT|Pending_payment|\n",
      "| PAYMENT_REVIEW| Payment_review|\n",
      "|         CLOSED|         Closed|\n",
      "|PENDING_PAYMENT|Pending_payment|\n",
      "|     PROCESSING|     Processing|\n",
      "|       COMPLETE|       Complete|\n",
      "|PENDING_PAYMENT|Pending_payment|\n",
      "|       COMPLETE|       Complete|\n",
      "|         CLOSED|         Closed|\n",
      "|PENDING_PAYMENT|Pending_payment|\n",
      "|     PROCESSING|     Processing|\n",
      "+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_status,initcap(ord.order_status).alias('initcap_status')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "25ade17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|   order_status|   upper_status|\n",
      "+---------------+---------------+\n",
      "|         CLOSED|         CLOSED|\n",
      "|PENDING_PAYMENT|PENDING_PAYMENT|\n",
      "|       COMPLETE|       COMPLETE|\n",
      "|         CLOSED|         CLOSED|\n",
      "|       COMPLETE|       COMPLETE|\n",
      "|       COMPLETE|       COMPLETE|\n",
      "|       COMPLETE|       COMPLETE|\n",
      "|     PROCESSING|     PROCESSING|\n",
      "|PENDING_PAYMENT|PENDING_PAYMENT|\n",
      "|PENDING_PAYMENT|PENDING_PAYMENT|\n",
      "| PAYMENT_REVIEW| PAYMENT_REVIEW|\n",
      "|         CLOSED|         CLOSED|\n",
      "|PENDING_PAYMENT|PENDING_PAYMENT|\n",
      "|     PROCESSING|     PROCESSING|\n",
      "|       COMPLETE|       COMPLETE|\n",
      "|PENDING_PAYMENT|PENDING_PAYMENT|\n",
      "|       COMPLETE|       COMPLETE|\n",
      "|         CLOSED|         CLOSED|\n",
      "|PENDING_PAYMENT|PENDING_PAYMENT|\n",
      "|     PROCESSING|     PROCESSING|\n",
      "+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_status,upper(ord.order_status).alias('upper_status')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "454733a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|   order_status|   lower_status|\n",
      "+---------------+---------------+\n",
      "|         CLOSED|         closed|\n",
      "|PENDING_PAYMENT|pending_payment|\n",
      "|       COMPLETE|       complete|\n",
      "|         CLOSED|         closed|\n",
      "|       COMPLETE|       complete|\n",
      "|       COMPLETE|       complete|\n",
      "|       COMPLETE|       complete|\n",
      "|     PROCESSING|     processing|\n",
      "|PENDING_PAYMENT|pending_payment|\n",
      "|PENDING_PAYMENT|pending_payment|\n",
      "| PAYMENT_REVIEW| payment_review|\n",
      "|         CLOSED|         closed|\n",
      "|PENDING_PAYMENT|pending_payment|\n",
      "|     PROCESSING|     processing|\n",
      "|       COMPLETE|       complete|\n",
      "|PENDING_PAYMENT|pending_payment|\n",
      "|       COMPLETE|       complete|\n",
      "|         CLOSED|         closed|\n",
      "|PENDING_PAYMENT|pending_payment|\n",
      "|     PROCESSING|     processing|\n",
      "+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_status,lower(ord.order_status).alias('lower_status')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e21379f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc89dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|   order_status|left_3|\n",
      "+---------------+------+\n",
      "|         CLOSED|   CLO|\n",
      "|PENDING_PAYMENT|   PEN|\n",
      "|       COMPLETE|   COM|\n",
      "|         CLOSED|   CLO|\n",
      "|       COMPLETE|   COM|\n",
      "|       COMPLETE|   COM|\n",
      "|       COMPLETE|   COM|\n",
      "|     PROCESSING|   PRO|\n",
      "|PENDING_PAYMENT|   PEN|\n",
      "|PENDING_PAYMENT|   PEN|\n",
      "| PAYMENT_REVIEW|   PAY|\n",
      "|         CLOSED|   CLO|\n",
      "|PENDING_PAYMENT|   PEN|\n",
      "|     PROCESSING|   PRO|\n",
      "|       COMPLETE|   COM|\n",
      "|PENDING_PAYMENT|   PEN|\n",
      "|       COMPLETE|   COM|\n",
      "|         CLOSED|   CLO|\n",
      "|PENDING_PAYMENT|   PEN|\n",
      "|     PROCESSING|   PRO|\n",
      "+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_status,expr(\"left(order_status,3)\").alias(\"left_3\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a93198dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|   order_status|rigth_3|\n",
      "+---------------+-------+\n",
      "|         CLOSED|    SED|\n",
      "|PENDING_PAYMENT|    ENT|\n",
      "|       COMPLETE|    ETE|\n",
      "|         CLOSED|    SED|\n",
      "|       COMPLETE|    ETE|\n",
      "|       COMPLETE|    ETE|\n",
      "|       COMPLETE|    ETE|\n",
      "|     PROCESSING|    ING|\n",
      "|PENDING_PAYMENT|    ENT|\n",
      "|PENDING_PAYMENT|    ENT|\n",
      "| PAYMENT_REVIEW|    IEW|\n",
      "|         CLOSED|    SED|\n",
      "|PENDING_PAYMENT|    ENT|\n",
      "|     PROCESSING|    ING|\n",
      "|       COMPLETE|    ETE|\n",
      "|PENDING_PAYMENT|    ENT|\n",
      "|       COMPLETE|    ETE|\n",
      "|         CLOSED|    SED|\n",
      "|PENDING_PAYMENT|    ENT|\n",
      "|     PROCESSING|    ING|\n",
      "+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(ord.order_status,expr(\"right(order_status,3)\").alias(\"rigth_3\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ltrim,rtrim,trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "62398c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =spark.createDataFrame([('    spark',),('     spark   ',)],('col1',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f29c2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         col1|ltrim|\n",
      "+-------------+-----+\n",
      "|        spark|spark|\n",
      "|     spark   |spark|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.col1,trim(df1.col1).alias('ltrim')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "48a65c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lpad,rpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0525f421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c92e059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|  lapd|\n",
      "+--------+-------------------+-----------------+---------------+------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|000001|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|000002|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|000003|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|000004|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|000005|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|000006|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|000007|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|000008|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|000009|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|000010|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|000011|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|000012|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|000013|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|000014|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|000015|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|000016|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|000017|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|000018|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|000019|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|000020|\n",
      "+--------+-------------------+-----------------+---------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('lapd',lpad(ord.order_id,6,'0')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "464695fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2bb05103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|    reverstring|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|         DESOLC|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|       ETELPMOC|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|         DESOLC|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|       ETELPMOC|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|       ETELPMOC|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|       ETELPMOC|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|     GNISSECORP|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW| WEIVER_TNEMYAP|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|         DESOLC|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|     GNISSECORP|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|       ETELPMOC|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|       ETELPMOC|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|         DESOLC|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|TNEMYAP_GNIDNEP|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|     GNISSECORP|\n",
      "+--------+-------------------+-----------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('reverstring',reverse(ord.order_status)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b3a20a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3483c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+---------------------------------------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |repeat                                       |\n",
      "+--------+-------------------+-----------------+---------------+---------------------------------------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |CLOSEDCLOSEDCLOSED                           |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|PENDING_PAYMENTPENDING_PAYMENTPENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |COMPLETECOMPLETECOMPLETE                     |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |CLOSEDCLOSEDCLOSED                           |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |COMPLETECOMPLETECOMPLETE                     |\n",
      "|6       |2013-07-25 00:00:00|7130             |COMPLETE       |COMPLETECOMPLETECOMPLETE                     |\n",
      "|7       |2013-07-25 00:00:00|4530             |COMPLETE       |COMPLETECOMPLETECOMPLETE                     |\n",
      "|8       |2013-07-25 00:00:00|2911             |PROCESSING     |PROCESSINGPROCESSINGPROCESSING               |\n",
      "|9       |2013-07-25 00:00:00|5657             |PENDING_PAYMENT|PENDING_PAYMENTPENDING_PAYMENTPENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00|5648             |PENDING_PAYMENT|PENDING_PAYMENTPENDING_PAYMENTPENDING_PAYMENT|\n",
      "|11      |2013-07-25 00:00:00|918              |PAYMENT_REVIEW |PAYMENT_REVIEWPAYMENT_REVIEWPAYMENT_REVIEW   |\n",
      "|12      |2013-07-25 00:00:00|1837             |CLOSED         |CLOSEDCLOSEDCLOSED                           |\n",
      "|13      |2013-07-25 00:00:00|9149             |PENDING_PAYMENT|PENDING_PAYMENTPENDING_PAYMENTPENDING_PAYMENT|\n",
      "|14      |2013-07-25 00:00:00|9842             |PROCESSING     |PROCESSINGPROCESSINGPROCESSING               |\n",
      "|15      |2013-07-25 00:00:00|2568             |COMPLETE       |COMPLETECOMPLETECOMPLETE                     |\n",
      "|16      |2013-07-25 00:00:00|7276             |PENDING_PAYMENT|PENDING_PAYMENTPENDING_PAYMENTPENDING_PAYMENT|\n",
      "|17      |2013-07-25 00:00:00|2667             |COMPLETE       |COMPLETECOMPLETECOMPLETE                     |\n",
      "|18      |2013-07-25 00:00:00|1205             |CLOSED         |CLOSEDCLOSEDCLOSED                           |\n",
      "|19      |2013-07-25 00:00:00|9488             |PENDING_PAYMENT|PENDING_PAYMENTPENDING_PAYMENTPENDING_PAYMENT|\n",
      "|20      |2013-07-25 00:00:00|9198             |PROCESSING     |PROCESSINGPROCESSINGPROCESSING               |\n",
      "+--------+-------------------+-----------------+---------------+---------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('repeat',repeat(ord.order_status,3)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7dc6a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f66b1832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+------------------------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |hex                           |\n",
      "+--------+-------------------+-----------------+---------------+------------------------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |434C4F534544                  |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|50454E44494E475F5041594D454E54|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |434F4D504C455445              |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |434C4F534544                  |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |434F4D504C455445              |\n",
      "|6       |2013-07-25 00:00:00|7130             |COMPLETE       |434F4D504C455445              |\n",
      "|7       |2013-07-25 00:00:00|4530             |COMPLETE       |434F4D504C455445              |\n",
      "|8       |2013-07-25 00:00:00|2911             |PROCESSING     |50524F43455353494E47          |\n",
      "|9       |2013-07-25 00:00:00|5657             |PENDING_PAYMENT|50454E44494E475F5041594D454E54|\n",
      "|10      |2013-07-25 00:00:00|5648             |PENDING_PAYMENT|50454E44494E475F5041594D454E54|\n",
      "|11      |2013-07-25 00:00:00|918              |PAYMENT_REVIEW |5041594D454E545F524556494557  |\n",
      "|12      |2013-07-25 00:00:00|1837             |CLOSED         |434C4F534544                  |\n",
      "|13      |2013-07-25 00:00:00|9149             |PENDING_PAYMENT|50454E44494E475F5041594D454E54|\n",
      "|14      |2013-07-25 00:00:00|9842             |PROCESSING     |50524F43455353494E47          |\n",
      "|15      |2013-07-25 00:00:00|2568             |COMPLETE       |434F4D504C455445              |\n",
      "|16      |2013-07-25 00:00:00|7276             |PENDING_PAYMENT|50454E44494E475F5041594D454E54|\n",
      "|17      |2013-07-25 00:00:00|2667             |COMPLETE       |434F4D504C455445              |\n",
      "|18      |2013-07-25 00:00:00|1205             |CLOSED         |434C4F534544                  |\n",
      "|19      |2013-07-25 00:00:00|9488             |PENDING_PAYMENT|50454E44494E475F5041594D454E54|\n",
      "|20      |2013-07-25 00:00:00|9198             |PROCESSING     |50524F43455353494E47          |\n",
      "+--------+-------------------+-----------------+---------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('hex',hex(ord.order_status)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "31145274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9ca28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+------------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|          idstatus|\n",
      "+--------+-------------------+-----------------+---------------+------------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|          1 CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT| 2 PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|        3 COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|          4 CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|        5 COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|        6 COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|        7 COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|      8 PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT| 9 PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|10 PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW| 11 PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|         12 CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|13 PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|     14 PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|       15 COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|16 PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|       17 COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|         18 CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|19 PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|     20 PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('idstatus',concat(ord.order_id,lit(' '),ord.order_status)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be428f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1a897ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+------------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|          idstatus|\n",
      "+--------+-------------------+-----------------+---------------+------------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|          1 CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT| 2 PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|        3 COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|          4 CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|        5 COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|        6 COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|        7 COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|      8 PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT| 9 PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|10 PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW| 11 PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|         12 CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|13 PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|     14 PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|       15 COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|16 PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|       17 COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|         18 CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|19 PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|     20 PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('idstatus',concat_ws(' ',ord.order_id,ord.order_status)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9cee5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e9ea68c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|order_year|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|      2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|      2013|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|      2013|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|      2013|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|      2013|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|      2013|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|      2013|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|      2013|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|      2013|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|      2013|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|      2013|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|      2013|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|      2013|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|      2013|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|      2013|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|      2013|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|      2013|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|      2013|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|      2013|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|      2013|\n",
      "+--------+-------------------+-----------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('order_year',substring(ord.order_date,1,4)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eaeecf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#substring_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "701bbe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|dummy|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED| 2013|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT| 2013|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE| 2013|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED| 2013|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE| 2013|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE| 2013|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE| 2013|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING| 2013|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT| 2013|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT| 2013|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW| 2013|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED| 2013|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT| 2013|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING| 2013|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE| 2013|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT| 2013|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE| 2013|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED| 2013|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT| 2013|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING| 2013|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('dummy',substring_index(ord.order_date,'-',1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cb44c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|  dummy|\n",
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|2013-07|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|2013-07|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|2013-07|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|2013-07|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|2013-07|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|2013-07|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|2013-07|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|2013-07|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|2013-07|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|2013-07|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|2013-07|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|2013-07|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|2013-07|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|2013-07|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|2013-07|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|2013-07|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|2013-07|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|2013-07|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|2013-07|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|2013-07|\n",
      "+--------+-------------------+-----------------+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('dummy',substring_index(ord.order_date,'-',2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "75b6d67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|      dummy|\n",
      "+--------+-------------------+-----------------+---------------+-----------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|25 00:00:00|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|25 00:00:00|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|25 00:00:00|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|25 00:00:00|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|25 00:00:00|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|25 00:00:00|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|25 00:00:00|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|25 00:00:00|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|25 00:00:00|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|25 00:00:00|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|25 00:00:00|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|25 00:00:00|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|25 00:00:00|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|25 00:00:00|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|25 00:00:00|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|25 00:00:00|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|25 00:00:00|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|25 00:00:00|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|25 00:00:00|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|25 00:00:00|\n",
      "+--------+-------------------+-----------------+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('dummy',substring_index(ord.order_date,'-',-1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7d1ac04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|order_id|         order_date|order_customer_id|   order_status|instr|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|    2|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|    0|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|    0|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|    2|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|    0|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|    0|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|    0|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|    0|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|    0|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|    0|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|    0|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|    2|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|    0|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|    0|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|    0|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|    0|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|    0|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|    2|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|    0|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|    0|\n",
      "+--------+-------------------+-----------------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.withColumn('instr',instr(ord.order_status,'LO')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "012c36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rgular expression extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0bc6f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =spark.createDataFrame([('11ssl ab',)],schema=['col1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7c80a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    col1|\n",
      "+--------+\n",
      "|11ssl ab|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e70bff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|regexp_extract(col1, (\\d+), 1)|\n",
      "+------------------------------+\n",
      "|                            11|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(regexp_extract(df1.col1,'(\\d+)' ,1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ad16f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|regexp_extract(col1, (\\d+)(\\w+), 2)|\n",
      "+-----------------------------------+\n",
      "|                                ssl|\n",
      "+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(regexp_extract(df1.col1,'(\\d+)(\\w+)' ,2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4bf6c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|regexp_extract(col1, (\\d+)(\\w+)(\\s), 3)|\n",
      "+---------------------------------------+\n",
      "|                                       |\n",
      "+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(regexp_extract(df1.col1,'(\\d+)(\\w+)(\\s)' ,3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2672f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|output|\n",
      "+------+\n",
      "|    ab|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(regexp_extract(df1.col1,'(\\d+)(\\w+)(\\s)([a-z]+)' ,4).alias(\"output\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bc048575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  output|\n",
      "+--------+\n",
      "|xxssl ab|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(regexp_replace(df1.col1,'(\\d+)' ,\"xx\").alias(\"output\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c498bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "add =spark.createDataFrame([(1,'Mount rd','chennai'),\n",
    "                             (2, 'Church rd','chennai')],schema=['id','street','city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f09dc81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+\n",
      "| id|   street|   city|\n",
      "+---+---------+-------+\n",
      "|  1| Mount rd|chennai|\n",
      "|  2|Church rd|chennai|\n",
      "+---+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1fd898be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------+\n",
      "| id|   street|   city|Reg_replace|\n",
      "+---+---------+-------+-----------+\n",
      "|  1| Mount rd|chennai| Mount road|\n",
      "|  2|Church rd|chennai|Church road|\n",
      "+---+---------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add.withColumn('Reg_replace',regexp_replace(add.street,'rd','road')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4af8235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dcd996",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord =spark.read.load('c:/practice/orders',format='csv',sep=',', schema=('order_id int, order_date timestamp,\\\n",
    "                                                                         order_customer_id int, order_status string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a915a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a8d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_new=ord.withColumn('new_order_date',date_add( ord.order_date,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "813a4948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+--------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|new_order_date|\n",
      "+--------+-------------------+-----------------+---------------+--------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|    2013-09-13|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|    2013-09-13|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|    2013-09-13|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|    2013-09-13|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|    2013-09-13|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|    2013-09-13|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|    2013-09-13|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|    2013-09-13|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|    2013-09-13|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|    2013-09-13|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|    2013-09-13|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|    2013-09-13|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|    2013-09-13|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|    2013-09-13|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|    2013-09-13|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|    2013-09-13|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|    2013-09-13|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|    2013-09-13|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|    2013-09-13|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|    2013-09-13|\n",
      "+--------+-------------------+-----------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b0d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5468702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "|    2024-03-27|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select(current_date()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bb3d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43c6ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2024-03-27|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50af042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e30cd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|current_timestamp()       |\n",
      "+--------------------------+\n",
      "|2024-03-27 09:37:12.478795|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_timestamp()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be187524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b3e657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|next_day(current_date(), sun)|\n",
      "+-----------------------------+\n",
      "|                   2024-03-31|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(next_day(current_date(),'sun')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7855b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lastday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf93c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|last_day(current_date())|\n",
      "+------------------------+\n",
      "|              2024-03-31|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(last_day(current_date())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1725f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8686bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|dayofweek(current_date())|\n",
      "+-------------------------+\n",
      "|                        4|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofweek(current_date())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f000d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dayofmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8dfdf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|dayofmonth(current_date())|\n",
      "+--------------------------+\n",
      "|                        27|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofmonth(current_date())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e985ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51a5a680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|dayofyear(current_date())|\n",
      "+-------------------------+\n",
      "|                       87|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(dayofyear(current_date())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa984f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30db74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|weekofyear(current_date())|\n",
      "+--------------------------+\n",
      "|                        13|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(weekofyear(current_date())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a75fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|second(current_timestamp())|\n",
      "+---------------------------+\n",
      "|                         42|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select (second(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8a24514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|hour(current_timestamp())|\n",
      "+-------------------------+\n",
      "|                        9|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select (hour(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2d93207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|minute(current_timestamp())|\n",
      "+---------------------------+\n",
      "|                         44|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select (minute(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5997b89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|year(current_timestamp())|\n",
      "+-------------------------+\n",
      "|                     2024|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select (year(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb5211e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|quarter(current_timestamp())|\n",
      "+----------------------------+\n",
      "|                           1|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select (quarter(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3fcfd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|month(current_timestamp())|\n",
      "+--------------------------+\n",
      "|                         3|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select (month(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9181404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|day(current_timestamp())|\n",
      "+------------------------+\n",
      "|                      27|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select (day(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "905acf0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'week' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mselect (week(current_timestamp()))\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'week' is not defined"
     ]
    }
   ],
   "source": [
    "df.select (week(current_timestamp())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5a4b051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+--------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|new_order_date|\n",
      "+--------+-------------------+-----------------+---------------+--------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|    2013-09-13|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|    2013-09-13|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|    2013-09-13|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|    2013-09-13|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|    2013-09-13|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|    2013-09-13|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|    2013-09-13|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|    2013-09-13|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|    2013-09-13|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|    2013-09-13|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|    2013-09-13|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|    2013-09-13|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|    2013-09-13|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|    2013-09-13|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|    2013-09-13|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|    2013-09-13|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|    2013-09-13|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|    2013-09-13|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|    2013-09-13|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|    2013-09-13|\n",
      "+--------+-------------------+-----------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b7bec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------------------------------------------+\n",
      "|new_order_date|         order_date|months_between(new_order_date, order_date, false)|\n",
      "+--------------+-------------------+-------------------------------------------------+\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "|    2013-09-13|2013-07-25 00:00:00|                               1.6129032258064515|\n",
      "+--------------+-------------------+-------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord_new.select(ord_new.new_order_date,ord_new.order_date,\n",
    "               months_between(ord_new.new_order_date,ord_new.order_date,roundOff=False)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a62ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|date_add(current_date(), 10)|\n",
      "+----------------------------+\n",
      "|                  2024-04-06|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(date_add(current_date(),10)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa9bf6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|date_sub(current_date(), 3)|\n",
      "+---------------------------+\n",
      "|                 2024-03-24|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select( date_sub(current_date(),3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23e0ad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|add_months(current_date(), 3)|\n",
      "+-----------------------------+\n",
      "|                   2024-06-27|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select( add_months(current_date(),3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9295530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+--------+\n",
      "|         order_date|current_date()|diffdate|\n",
      "+-------------------+--------------+--------+\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "|2013-07-25 00:00:00|    2024-03-27|    3898|\n",
      "+-------------------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.select( ord.order_date,current_date(),date_diff(current_date(), ord.order_date).alias('diffdate')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c888a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|current_date()|date_formate|\n",
      "+--------------+------------+\n",
      "|    2024-03-27|  27/00/2024|\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(current_date(),date_format(current_date(),'dd/mm/yyyy').alias('date_formate')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a9fc3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame([('1924-01-01 10:03:30',)],schema=['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "701fd37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|                  t|\n",
      "+-------------------+\n",
      "|1924-01-01 10:03:30|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "251aabee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- t: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52129264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- to_timestamp(t): timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(to_timestamp(df2.t)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64e942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =df2.select(to_date(df2.t,'yyyy-mm-dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d875d4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|                  t|\n",
      "+-------------------+\n",
      "|1924-01-01 10:03:30|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "94ceb723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#null functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c0b42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([('Robert',1,None,114.0),('Jhon',None,2577,float('nan'))], [\"name\",\"id\",\"phone\",\"stAddr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "28e3d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+------+\n",
      "|  name|  id|phone|stAddr|\n",
      "+------+----+-----+------+\n",
      "|Robert|   1| NULL| 114.0|\n",
      "|  Jhon|NULL| 2577|   NaN|\n",
      "+------+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56427c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+------+\n",
      "|  name| id|phone|stAddr|\n",
      "+------+---+-----+------+\n",
      "|Robert|  1| NULL| 114.0|\n",
      "+------+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(isnull(df.phone)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a470667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|phone|(phone IS NULL)|\n",
      "+-----+---------------+\n",
      "| NULL|           true|\n",
      "| 2577|          false|\n",
      "+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.phone,isnull(df.phone)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "673cf6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|stAddr|isnan(stAddr)|\n",
      "+------+-------------+\n",
      "| 114.0|        false|\n",
      "|   NaN|         true|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.stAddr,isnan(df.stAddr)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "75c8e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------------------+\n",
      "|phone|stAddr|coalesce(phone, stAddr)|\n",
      "+-----+------+-----------------------+\n",
      "| NULL| 114.0|                  114.0|\n",
      "| 2577|   NaN|                 2577.0|\n",
      "+-----+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.phone,df.stAddr,coalesce(df.phone,df.stAddr)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c23aff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "62265561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('Alicia','Joesph',['Java','Scala','Spark'],{'hair':'black','eye':'brown'}),\\\n",
    "      ('Robert','Gee',['Spark','Java'],{'hair':'brown','eye':None}),\\\n",
    "      ('Mike','Bianca',['Csharp',''],{'hair':'red','eye':''}),\\\n",
    "      ('Jhon','Kumar',None,None),\\\n",
    "      ('Jeff','L',['1','2'],{})]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "97dd73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema =['FirstName','LastName','Languages','Properties']\n",
    "\n",
    "emp1 =spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3fb98540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+-----------------------------+\n",
      "|FirstName|LastName|Languages           |Properties                   |\n",
      "+---------+--------+--------------------+-----------------------------+\n",
      "|Alicia   |Joesph  |[Java, Scala, Spark]|{eye -> brown, hair -> black}|\n",
      "|Robert   |Gee     |[Spark, Java]       |{eye -> NULL, hair -> brown} |\n",
      "|Mike     |Bianca  |[Csharp, ]          |{eye -> , hair -> red}       |\n",
      "|Jhon     |Kumar   |NULL                |NULL                         |\n",
      "|Jeff     |L       |[1, 2]              |{}                           |\n",
      "+---------+--------+--------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "341dbeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('Robert',35,40,40),('Ram',31,33,29),('Jhon',95,89,91)]\n",
    "schema =['name','score1','score2','score3']\n",
    "emp2 =spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4cd30b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "|  Jhon|    95|    89|    91|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eb7797c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('Jhon',[10,20,20],[25,11,10]),\\\n",
    "        ('Robert',[15,13,55],[5,None,29]),\\\n",
    "        ('James',[11,13,45],[5,89,79])]\n",
    "\n",
    "schema =['empName','score_arr1','score_arr2']\n",
    "\n",
    "emp3 =spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "80a63f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+\n",
      "|empName|  score_arr1|   score_arr2|\n",
      "+-------+------------+-------------+\n",
      "|   Jhon|[10, 20, 20]| [25, 11, 10]|\n",
      "| Robert|[15, 13, 55]|[5, NULL, 29]|\n",
      "|  James|[11, 13, 45]|  [5, 89, 79]|\n",
      "+-------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "675edb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.sql(\"select array(struct(1,'a'),struct(2,'b')) as data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "883df4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = false)\n",
      " |    |    |-- col1: integer (nullable = false)\n",
      " |    |    |-- col2: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "03489e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f655f975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+-----------------------------+\n",
      "|FirstName|LastName|Languages           |Properties                   |\n",
      "+---------+--------+--------------------+-----------------------------+\n",
      "|Alicia   |Joesph  |[Java, Scala, Spark]|{eye -> brown, hair -> black}|\n",
      "|Robert   |Gee     |[Spark, Java]       |{eye -> NULL, hair -> brown} |\n",
      "|Mike     |Bianca  |[Csharp, ]          |{eye -> , hair -> red}       |\n",
      "|Jhon     |Kumar   |NULL                |NULL                         |\n",
      "|Jeff     |L       |[1, 2]              |{}                           |\n",
      "+---------+--------+--------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e494b157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+\n",
      "|size(Languages)|size(Properties)|\n",
      "+---------------+----------------+\n",
      "|              3|               2|\n",
      "|              2|               2|\n",
      "|              2|               2|\n",
      "|             -1|              -1|\n",
      "|              2|               0|\n",
      "+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select(size(emp1.Languages),size(emp1.Properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c3051ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#element_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e1d92855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+-----------------------------+\n",
      "|FirstName|LastName|Languages           |Properties                   |\n",
      "+---------+--------+--------------------+-----------------------------+\n",
      "|Alicia   |Joesph  |[Java, Scala, Spark]|{eye -> brown, hair -> black}|\n",
      "|Robert   |Gee     |[Spark, Java]       |{eye -> NULL, hair -> brown} |\n",
      "|Mike     |Bianca  |[Csharp, ]          |{eye -> , hair -> red}       |\n",
      "|Jhon     |Kumar   |NULL                |NULL                         |\n",
      "|Jeff     |L       |[1, 2]              |{}                           |\n",
      "+---------+--------+--------------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b66ef4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+---------------------------+\n",
      "|FirstName|element_at(Languages, 1)|element_at(Properties, eye)|\n",
      "+---------+------------------------+---------------------------+\n",
      "|   Alicia|                    Java|                      brown|\n",
      "|   Robert|                   Spark|                       NULL|\n",
      "|     Mike|                  Csharp|                           |\n",
      "|     Jhon|                    NULL|                       NULL|\n",
      "|     Jeff|                       1|                       NULL|\n",
      "+---------+------------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select(emp1.FirstName, element_at(emp1.Languages,1),element_at(emp1.Properties,'eye') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fc265d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "90de630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------------------------+\n",
      "|FirstName|LastName|struct(FirstName, LastName)|\n",
      "+---------+--------+---------------------------+\n",
      "|   Alicia|  Joesph|           {Alicia, Joesph}|\n",
      "|   Robert|     Gee|              {Robert, Gee}|\n",
      "|     Mike|  Bianca|             {Mike, Bianca}|\n",
      "|     Jhon|   Kumar|              {Jhon, Kumar}|\n",
      "|     Jeff|       L|                  {Jeff, L}|\n",
      "+---------+--------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select(emp1.FirstName,emp1.LastName,struct(emp1.FirstName,emp1.LastName)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac902444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dc0ad26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "|  Jhon|    95|    89|    91|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "261e6906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------+\n",
      "|  name|array(score1, score2, score3)|\n",
      "+------+-----------------------------+\n",
      "|Robert|                 [35, 40, 40]|\n",
      "|   Ram|                 [31, 33, 29]|\n",
      "|  Jhon|                 [95, 89, 91]|\n",
      "+------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp2.select(emp2.name,array(emp2.score1,emp2.score2,emp2.score3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "12c87259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- array(score1, score2, score3): array (nullable = false)\n",
      " |    |-- element: long (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp2.select(emp2.name,array(emp2.score1,emp2.score2,emp2.score3)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e768bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arry_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "472eb726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+\n",
      "|empName|  score_arr1|   score_arr2|\n",
      "+-------+------------+-------------+\n",
      "|   Jhon|[10, 20, 20]| [25, 11, 10]|\n",
      "| Robert|[15, 13, 55]|[5, NULL, 29]|\n",
      "|  James|[11, 13, 45]|  [5, 89, 79]|\n",
      "+-------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da54384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arry_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "748aa45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|empName|array_max(score_arr1)|\n",
      "+-------+---------------------+\n",
      "|   Jhon|                   20|\n",
      "| Robert|                   55|\n",
      "|  James|                   45|\n",
      "+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.empName,array_max(emp3.score_arr1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "275315e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6d54d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------------+\n",
      "|  score_arr1|array_distinct(score_arr1)|\n",
      "+------------+--------------------------+\n",
      "|[10, 20, 20]|                  [10, 20]|\n",
      "|[15, 13, 55]|              [15, 13, 55]|\n",
      "|[11, 13, 45]|              [11, 13, 45]|\n",
      "+------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1, array_distinct(emp3.score_arr1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "694b0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arry_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9c799057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------------------------------+\n",
      "|score_arr1  |array_repeat(score_arr1, 3)               |\n",
      "+------------+------------------------------------------+\n",
      "|[10, 20, 20]|[[10, 20, 20], [10, 20, 20], [10, 20, 20]]|\n",
      "|[15, 13, 55]|[[15, 13, 55], [15, 13, 55], [15, 13, 55]]|\n",
      "|[11, 13, 45]|[[11, 13, 45], [11, 13, 45], [11, 13, 45]]|\n",
      "+------------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1, array_repeat(emp3.score_arr1,3)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "03561606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+--------------------+\n",
      "|FirstName|LastName|           Languages|          Properties|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "|   Alicia|  Joesph|[Java, Scala, Spark]|{eye -> brown, ha...|\n",
      "|   Robert|     Gee|       [Spark, Java]|{eye -> NULL, hai...|\n",
      "|     Mike|  Bianca|          [Csharp, ]|{eye -> , hair ->...|\n",
      "|     Jhon|   Kumar|                NULL|                NULL|\n",
      "|     Jeff|       L|              [1, 2]|                  {}|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "02300d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b7dc9530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|           Languages|slice(Languages, 2, 2)|\n",
      "+--------------------+----------------------+\n",
      "|[Java, Scala, Spark]|        [Scala, Spark]|\n",
      "|       [Spark, Java]|                [Java]|\n",
      "|          [Csharp, ]|                    []|\n",
      "|                NULL|                  NULL|\n",
      "|              [1, 2]|                   [2]|\n",
      "+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select(emp1.Languages, slice(emp1.Languages,2,2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arry_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bb96037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+\n",
      "|empName|  score_arr1|   score_arr2|\n",
      "+-------+------------+-------------+\n",
      "|   Jhon|[10, 20, 20]| [25, 11, 10]|\n",
      "| Robert|[15, 13, 55]|[5, NULL, 29]|\n",
      "|  James|[11, 13, 45]|  [5, 89, 79]|\n",
      "+-------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a420106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------------------+\n",
      "|  score_arr1|array_position(score_arr1, 13)|\n",
      "+------------+------------------------------+\n",
      "|[10, 20, 20]|                             0|\n",
      "|[15, 13, 55]|                             2|\n",
      "|[11, 13, 45]|                             2|\n",
      "+------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,array_position(emp3.score_arr1,13)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d1fa80e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------------+\n",
      "|  score_arr1|array_remove(score_arr1, 13)|\n",
      "+------------+----------------------------+\n",
      "|[10, 20, 20]|                [10, 20, 20]|\n",
      "|[15, 13, 55]|                    [15, 55]|\n",
      "|[11, 13, 45]|                    [11, 45]|\n",
      "+------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,array_remove(emp3.score_arr1,13)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "576700a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+\n",
      "|empName|  score_arr1|   score_arr2|\n",
      "+-------+------------+-------------+\n",
      "|   Jhon|[10, 20, 20]| [25, 11, 10]|\n",
      "| Robert|[15, 13, 55]|[5, NULL, 29]|\n",
      "|  James|[11, 13, 45]|  [5, 89, 79]|\n",
      "+-------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "00fc2a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|  score_arr1|array_sort(score_arr1, lambdafunction((IF(((namedlambdavariable() IS NULL) AND (namedlambdavariable() IS NULL)), 0, (IF((namedlambdavariable() IS NULL), 1, (IF((namedlambdavariable() IS NULL), -1, (IF((namedlambdavariable() < namedlambdavariable()), -1, (IF((namedlambdavariable() > namedlambdavariable()), 1, 0)))))))))), namedlambdavariable(), namedlambdavariable()))|\n",
      "+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[10, 20, 20]|                                                                                                                                                                                                                                                                                                                                                                     [10, 20, 20]|\n",
      "|[15, 13, 55]|                                                                                                                                                                                                                                                                                                                                                                     [13, 15, 55]|\n",
      "|[11, 13, 45]|                                                                                                                                                                                                                                                                                                                                                                     [11, 13, 45]|\n",
      "+------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,array_sort(emp3.score_arr1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "aeb8218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fa352c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------------+\n",
      "|  score_arr1|sort_array(score_arr1, false)|\n",
      "+------------+-----------------------------+\n",
      "|[10, 20, 20]|                 [20, 20, 10]|\n",
      "|[15, 13, 55]|                 [55, 15, 13]|\n",
      "|[11, 13, 45]|                 [45, 13, 11]|\n",
      "+------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,sort_array(emp3.score_arr1,asc=False)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cbafb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e5c681e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------------------+\n",
      "|   score_arr2|array_contains(score_arr2, 25)|\n",
      "+-------------+------------------------------+\n",
      "| [25, 11, 10]|                          true|\n",
      "|[5, NULL, 29]|                          NULL|\n",
      "|  [5, 89, 79]|                         false|\n",
      "+-------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr2,array_contains(emp3.score_arr2,25)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7a45c781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------------------------------+\n",
      "|score_arr1  |score_arr2   |array_union(score_arr1, score_arr2)|\n",
      "+------------+-------------+-----------------------------------+\n",
      "|[10, 20, 20]|[25, 11, 10] |[10, 20, 25, 11]                   |\n",
      "|[15, 13, 55]|[5, NULL, 29]|[15, 13, 55, 5, NULL, 29]          |\n",
      "|[11, 13, 45]|[5, 89, 79]  |[11, 13, 45, 5, 89, 79]            |\n",
      "+------------+-------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,emp3.score_arr2,array_union(emp3.score_arr1,emp3.score_arr2)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "597d0cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------------------------------+\n",
      "|score_arr1  |score_arr2   |array_except(score_arr1, score_arr2)|\n",
      "+------------+-------------+------------------------------------+\n",
      "|[10, 20, 20]|[25, 11, 10] |[20]                                |\n",
      "|[15, 13, 55]|[5, NULL, 29]|[15, 13, 55]                        |\n",
      "|[11, 13, 45]|[5, 89, 79]  |[11, 13, 45]                        |\n",
      "+------------+-------------+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,emp3.score_arr2,array_except(emp3.score_arr1,emp3.score_arr2)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "97dad308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------------------------------+\n",
      "|score_arr1  |score_arr2   |array_intersect(score_arr1, score_arr2)|\n",
      "+------------+-------------+---------------------------------------+\n",
      "|[10, 20, 20]|[25, 11, 10] |[10]                                   |\n",
      "|[15, 13, 55]|[5, NULL, 29]|[]                                     |\n",
      "|[11, 13, 45]|[5, 89, 79]  |[]                                     |\n",
      "+------------+-------------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,emp3.score_arr2,array_intersect(emp3.score_arr1,emp3.score_arr2)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1dfcab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------------+\n",
      "|   score_arr2|array_join(score_arr2, #, *)|\n",
      "+-------------+----------------------------+\n",
      "| [25, 11, 10]|                    25#11#10|\n",
      "|[5, NULL, 29]|                      5#*#29|\n",
      "|  [5, 89, 79]|                     5#89#79|\n",
      "+-------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr2,array_join(emp3.score_arr2,'#',null_replacement='*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9783403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-------------------------------+\n",
      "|score_arr1  |score_arr2   |arry_zip                       |\n",
      "+------------+-------------+-------------------------------+\n",
      "|[10, 20, 20]|[25, 11, 10] |[{10, 25}, {20, 11}, {20, 10}] |\n",
      "|[15, 13, 55]|[5, NULL, 29]|[{15, 5}, {13, NULL}, {55, 29}]|\n",
      "|[11, 13, 45]|[5, 89, 79]  |[{11, 5}, {13, 89}, {45, 79}]  |\n",
      "+------------+-------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp3.select(emp3.score_arr1,emp3.score_arr2,arrays_zip(emp3.score_arr1,emp3.score_arr2).alias('arry_zip')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5f674c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3dd149b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+--------------------+\n",
      "|FirstName|LastName|           Languages|          Properties|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "|   Alicia|  Joesph|[Java, Scala, Spark]|{eye -> brown, ha...|\n",
      "|   Robert|     Gee|       [Spark, Java]|{eye -> NULL, hai...|\n",
      "|     Mike|  Bianca|          [Csharp, ]|{eye -> , hair ->...|\n",
      "|     Jhon|   Kumar|                NULL|                NULL|\n",
      "|     Jeff|       L|              [1, 2]|                  {}|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5a05fc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|map(FirstName, LastName)|\n",
      "+------------------------+\n",
      "|      {Alicia -> Joesph}|\n",
      "|         {Robert -> Gee}|\n",
      "|        {Mike -> Bianca}|\n",
      "|         {Jhon -> Kumar}|\n",
      "|             {Jeff -> L}|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select(create_map(emp1.FirstName, emp1.LastName)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1b7e12ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+--------------------+\n",
      "|FirstName|LastName|           Languages|          Properties|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "|   Alicia|  Joesph|[Java, Scala, Spark]|{eye -> brown, ha...|\n",
      "|   Robert|     Gee|       [Spark, Java]|{eye -> NULL, hai...|\n",
      "|     Mike|  Bianca|          [Csharp, ]|{eye -> , hair ->...|\n",
      "|     Jhon|   Kumar|                NULL|                NULL|\n",
      "|     Jeff|       L|              [1, 2]|                  {}|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f34f245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|map_keys(Properties)|\n",
      "+--------------------+\n",
      "|         [eye, hair]|\n",
      "|         [eye, hair]|\n",
      "|         [eye, hair]|\n",
      "|                NULL|\n",
      "|                  []|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select(map_keys(emp1.Properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4d048ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|map_values(Properties)|\n",
      "+----------------------+\n",
      "|        [brown, black]|\n",
      "|         [NULL, brown]|\n",
      "|               [, red]|\n",
      "|                  NULL|\n",
      "|                    []|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select(map_values(emp1.Properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "19d7610f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "|  name|score1|score2|score3|\n",
      "+------+------+------+------+\n",
      "|Robert|    35|    40|    40|\n",
      "|   Ram|    31|    33|    29|\n",
      "|  Jhon|    95|    89|    91|\n",
      "+------+------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b4005c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7b9b9323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------------------------+\n",
      "|score1|score2|sequence(score1, score2)    |\n",
      "+------+------+----------------------------+\n",
      "|35    |40    |[35, 36, 37, 38, 39, 40]    |\n",
      "|31    |33    |[31, 32, 33]                |\n",
      "|95    |89    |[95, 94, 93, 92, 91, 90, 89]|\n",
      "+------+------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp2.select(emp2.score1,emp2.score2,sequence(emp2.score1,emp2.score2)).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1fe24ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[('Alice',80,60),('Bob',None,5),(None,None,None),('Robet',30,35)]\n",
    "schema='name string,age int, hight int'\n",
    "df =spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b2127cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| name| age|hight|\n",
      "+-----+----+-----+\n",
      "|Alice|  80|   60|\n",
      "|  Bob|NULL|    5|\n",
      "| NULL|NULL| NULL|\n",
      "|Robet|  30|   35|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0a022cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| name| age|hight|\n",
      "+-----+----+-----+\n",
      "|Alice|  80|   60|\n",
      "|  Bob|NULL|    5|\n",
      "|Robet|  30|   35|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ce98104f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "| 80|\n",
      "| 30|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.age).na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ac6573c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| name| age|hight|\n",
      "+-----+----+-----+\n",
      "|Alice|  80|   60|\n",
      "|  Bob|NULL|    5|\n",
      "| NULL|NULL| NULL|\n",
      "|Robet|  30|   35|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "31cbae17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age|hight|\n",
      "+-----+---+-----+\n",
      "|Alice| 80|   60|\n",
      "|Robet| 30|   35|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset='age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "376068e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| name| age|hight|\n",
      "+-----+----+-----+\n",
      "|Alice|  80|   60|\n",
      "|  Bob|NULL|    5|\n",
      "| NULL|NULL| NULL|\n",
      "|Robet|  30|   35|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1818808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age|hight|\n",
      "+-----+---+-----+\n",
      "|Alice| 80|   60|\n",
      "|  Bob| 50|    5|\n",
      "| NULL| 50|   50|\n",
      "|Robet| 30|   35|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(50).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ddf4f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+\n",
      "| name| age|hight|\n",
      "+-----+----+-----+\n",
      "|Alice|  80|   60|\n",
      "|  Bob|NULL|    5|\n",
      "|  Ram|NULL| NULL|\n",
      "|Robet|  30|   35|\n",
      "+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('Ram').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "00b9164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+\n",
      "| name|age|hight|\n",
      "+-----+---+-----+\n",
      "|Alice| 80|   60|\n",
      "|  Bob| 50|    5|\n",
      "|  ram| 50|   30|\n",
      "|Robet| 30|   35|\n",
      "+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill({'age':50, 'name':'ram','hight':30}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "36a99643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame([(-5,0),(1,3),(7,9)],['COL1','COL2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6e4bb817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|COL1|COL2|\n",
      "+----+----+\n",
      "|  -5|   0|\n",
      "|   1|   3|\n",
      "|   7|   9|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "59c7311a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|abs(COL1)|\n",
      "+---------+\n",
      "|        5|\n",
      "|        1|\n",
      "|        7|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(abs('COL1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c28100b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|COL1|           EXP(COL1)|\n",
      "+----+--------------------+\n",
      "|  -5|0.006737946999085467|\n",
      "|   1|  2.7182818284590455|\n",
      "|   7|  1096.6331584284585|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('COL1',exp('COL1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3b22dee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|COL1|factorial(COL1)|\n",
      "+----+---------------+\n",
      "|  -5|           NULL|\n",
      "|   1|              1|\n",
      "|   7|           5040|\n",
      "+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    df.select('COL1',factorial('COL1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "367f05e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|COL1|        SQRT(COL1)|\n",
      "+----+------------------+\n",
      "|  -5|               NaN|\n",
      "|   1|               1.0|\n",
      "|   7|2.6457513110645907|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('COL1',sqrt('COL1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e26db003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|COL1|POWER(COL1, 3)|\n",
      "+----+--------------+\n",
      "|  -5|        -125.0|\n",
      "|   1|           1.0|\n",
      "|   7|         343.0|\n",
      "+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('COL1',pow('COL1',3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7ae189d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|COL1|FLOOR(COL1)|\n",
      "+----+-----------+\n",
      "|  -5|         -5|\n",
      "|   1|          1|\n",
      "|   7|          7|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    df.select('COL1',floor('COL1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1c4b62e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|COL1|CEIL(COL1)|\n",
      "+----+----------+\n",
      "|  -5|        -5|\n",
      "|   1|         1|\n",
      "|   7|         7|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('COL1',ceil('COL1')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6806d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|COL1|COL2|\n",
      "+----+----+\n",
      "|  -5|   0|\n",
      "|   1|   3|\n",
      "|   7|   9|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d1d634ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sum(COL1)|\n",
      "+---------+\n",
      "|        3|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum(df.COL1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "91ad6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|avg(COL1)|\n",
      "+---------+\n",
      "|      1.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(avg(df.COL1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1a636c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|max(COL1)|\n",
      "+---------+\n",
      "|        7|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max(df.COL1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "43d9fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|min(COL1)|\n",
      "+---------+\n",
      "|       -5|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min(df.COL1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "84d88114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+--------------------+\n",
      "|FirstName|LastName|           Languages|          Properties|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "|   Alicia|  Joesph|[Java, Scala, Spark]|{eye -> brown, ha...|\n",
      "|   Robert|     Gee|       [Spark, Java]|{eye -> NULL, hai...|\n",
      "|     Mike|  Bianca|          [Csharp, ]|{eye -> , hair ->...|\n",
      "|     Jhon|   Kumar|                NULL|                NULL|\n",
      "|     Jeff|       L|              [1, 2]|                  {}|\n",
      "+---------+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6b478d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|FirstName|   col|\n",
      "+---------+------+\n",
      "|   Alicia|  Java|\n",
      "|   Alicia| Scala|\n",
      "|   Alicia| Spark|\n",
      "|   Robert| Spark|\n",
      "|   Robert|  Java|\n",
      "|     Mike|Csharp|\n",
      "|     Mike|      |\n",
      "|     Jeff|     1|\n",
      "|     Jeff|     2|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select  (emp1.FirstName, explode(emp1.Languages)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "917f03b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+\n",
      "|FirstName| key|value|\n",
      "+---------+----+-----+\n",
      "|   Alicia| eye|brown|\n",
      "|   Alicia|hair|black|\n",
      "|   Robert| eye| NULL|\n",
      "|   Robert|hair|brown|\n",
      "|     Mike| eye|     |\n",
      "|     Mike|hair|  red|\n",
      "+---------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select  (emp1.FirstName, explode(emp1.Properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a5a34c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|FirstName|   col|\n",
      "+---------+------+\n",
      "|   Alicia|  Java|\n",
      "|   Alicia| Scala|\n",
      "|   Alicia| Spark|\n",
      "|   Robert| Spark|\n",
      "|   Robert|  Java|\n",
      "|     Mike|Csharp|\n",
      "|     Mike|      |\n",
      "|     Jhon|  NULL|\n",
      "|     Jeff|     1|\n",
      "|     Jeff|     2|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp1.select  (emp1.FirstName, explode_outer(emp1.Languages)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5d677723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2873717",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordItems =spark.read.load('c:/practice/order_items',format='csv',sep=',',schema=\\\n",
    "        'order_item_id int, order_id int, product_id int, qunatity int, subtotal float, price float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d945482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+----------+--------+--------+------+\n",
      "|order_item_id|order_id|product_id|qunatity|subtotal| price|\n",
      "+-------------+--------+----------+--------+--------+------+\n",
      "|            1|       1|       957|       1|  299.98|299.98|\n",
      "|            2|       2|      1073|       1|  199.99|199.99|\n",
      "|            3|       2|       502|       5|   250.0|  50.0|\n",
      "|            4|       2|       403|       1|  129.99|129.99|\n",
      "|            5|       4|       897|       2|   49.98| 24.99|\n",
      "|            6|       4|       365|       5|  299.95| 59.99|\n",
      "|            7|       4|       502|       3|   150.0|  50.0|\n",
      "|            8|       4|      1014|       4|  199.92| 49.98|\n",
      "|            9|       5|       957|       1|  299.98|299.98|\n",
      "|           10|       5|       365|       5|  299.95| 59.99|\n",
      "|           11|       5|      1014|       2|   99.96| 49.98|\n",
      "|           12|       5|       957|       1|  299.98|299.98|\n",
      "|           13|       5|       403|       1|  129.99|129.99|\n",
      "|           14|       7|      1073|       1|  199.99|199.99|\n",
      "|           15|       7|       957|       1|  299.98|299.98|\n",
      "|           16|       7|       926|       5|   79.95| 15.99|\n",
      "|           17|       8|       365|       3|  179.97| 59.99|\n",
      "|           18|       8|       365|       5|  299.95| 59.99|\n",
      "|           19|       8|      1014|       4|  199.92| 49.98|\n",
      "|           20|       8|       502|       1|    50.0|  50.0|\n",
      "+-------------+--------+----------+--------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "97d740cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+\n",
      "| price|format_number(price, 1)|\n",
      "+------+-----------------------+\n",
      "|299.98|                  300.0|\n",
      "|199.99|                  200.0|\n",
      "|  50.0|                   50.0|\n",
      "|129.99|                  130.0|\n",
      "| 24.99|                   25.0|\n",
      "| 59.99|                   60.0|\n",
      "|  50.0|                   50.0|\n",
      "| 49.98|                   50.0|\n",
      "|299.98|                  300.0|\n",
      "| 59.99|                   60.0|\n",
      "| 49.98|                   50.0|\n",
      "|299.98|                  300.0|\n",
      "|129.99|                  130.0|\n",
      "|199.99|                  200.0|\n",
      "|299.98|                  300.0|\n",
      "| 15.99|                   16.0|\n",
      "| 59.99|                   60.0|\n",
      "| 59.99|                   60.0|\n",
      "| 49.98|                   50.0|\n",
      "|  50.0|                   50.0|\n",
      "+------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordItems.select(ordItems.price,format_number(ordItems.price,1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "43f411ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+\n",
      "|3.5|format_number(3.5, 0)|\n",
      "+---+---------------------+\n",
      "|3.5|                    4|\n",
      "+---+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(1).select(lit(3.5),format_number(lit(3.5),0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "45bedaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+\n",
      "|4.5|format_number(4.5, 0)|\n",
      "+---+---------------------+\n",
      "|4.5|                    4|\n",
      "+---+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(1).select(lit(4.5),format_number(lit(4.5),0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5a3d5d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =spark.createDataFrame([(5,'hello')],['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b9b4a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|  a|    b|\n",
      "+---+-----+\n",
      "|  5|hello|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f3e3da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "32c68e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|format_string(%d %s, a, b)|\n",
      "+--------------------------+\n",
      "|                   5 hello|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(format_string('%d %s', df.a, df.b)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0652f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord=spark.read.load('c:/practice/orders',format='csv',\n",
    "                    schema=('OrderId int, OrderDate String,CustomerId int,OrderStatus String'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49eb8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+---------------+\n",
      "|OrderId|           OrderDate|CustomerId|    OrderStatus|\n",
      "+-------+--------------------+----------+---------------+\n",
      "|      1|2013-07-25 00:00:...|     11599|         CLOSED|\n",
      "|      2|2013-07-25 00:00:...|       256|PENDING_PAYMENT|\n",
      "|      3|2013-07-25 00:00:...|     12111|       COMPLETE|\n",
      "|      4|2013-07-25 00:00:...|      8827|         CLOSED|\n",
      "|      5|2013-07-25 00:00:...|     11318|       COMPLETE|\n",
      "|      6|2013-07-25 00:00:...|      7130|       COMPLETE|\n",
      "|      7|2013-07-25 00:00:...|      4530|       COMPLETE|\n",
      "|      8|2013-07-25 00:00:...|      2911|     PROCESSING|\n",
      "|      9|2013-07-25 00:00:...|      5657|PENDING_PAYMENT|\n",
      "|     10|2013-07-25 00:00:...|      5648|PENDING_PAYMENT|\n",
      "|     11|2013-07-25 00:00:...|       918| PAYMENT_REVIEW|\n",
      "|     12|2013-07-25 00:00:...|      1837|         CLOSED|\n",
      "|     13|2013-07-25 00:00:...|      9149|PENDING_PAYMENT|\n",
      "|     14|2013-07-25 00:00:...|      9842|     PROCESSING|\n",
      "|     15|2013-07-25 00:00:...|      2568|       COMPLETE|\n",
      "|     16|2013-07-25 00:00:...|      7276|PENDING_PAYMENT|\n",
      "|     17|2013-07-25 00:00:...|      2667|       COMPLETE|\n",
      "|     18|2013-07-25 00:00:...|      1205|         CLOSED|\n",
      "|     19|2013-07-25 00:00:...|      9488|PENDING_PAYMENT|\n",
      "|     20|2013-07-25 00:00:...|      9198|     PROCESSING|\n",
      "+-------+--------------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ord.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "300c0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordCountByStatus = ord.groupBy(ord.OrderStatus).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5edffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|    OrderStatus|count|\n",
      "+---------------+-----+\n",
      "|PENDING_PAYMENT|15030|\n",
      "|       COMPLETE|22899|\n",
      "|        ON_HOLD| 3798|\n",
      "| PAYMENT_REVIEW|  729|\n",
      "|     PROCESSING| 8275|\n",
      "|         CLOSED| 7556|\n",
      "|SUSPECTED_FRAUD| 1558|\n",
      "|        PENDING| 7610|\n",
      "|       CANCELED| 1428|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordCountByStatus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b95705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordCountByStatus.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e01c794b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o95.save.\n: java.lang.RuntimeException: java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\\winutils\\bin\\bin -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:188)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:374)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:402)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:374)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\\winutils\\bin\\bin -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ordCountByStatus\u001b[38;5;241m.\u001b[39mcoalesce(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:///C:/practice/out1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m,sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:1463\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o95.save.\n: java.lang.RuntimeException: java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\\winutils\\bin\\bin -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:188)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:269)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:304)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:190)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:190)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$executeCollect$1(AdaptiveSparkPlanExec.scala:374)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:402)\r\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:374)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\r\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\r\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\r\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:240)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.io.FileNotFoundException: Hadoop bin directory does not exist: C:\\winutils\\bin\\bin -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBinInner(Shell.java:607)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:242)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir(SparkFileUtils.scala:103)\r\n\tat org.apache.spark.util.SparkFileUtils.createTempDir$(SparkFileUtils.scala:102)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:94)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:372)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:964)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:194)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:217)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1120)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1129)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n"
     ]
    }
   ],
   "source": [
    "ordCountByStatus.coalesce(1).write.save(\"file:///C:/practice/out1.csv\",format='csv',sep=',',mode='overwrite')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babje\\anaconda3\\Lib\\site-packages\\pyspark\\streaming\\context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2024-04-05 16:58:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 16:58:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 16:59:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:00:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:00:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:01:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:02:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:02:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:03:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:04:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:04:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:05:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:06:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:06:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:07:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:08:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:08:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:09:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:10:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:10:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:11:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:12:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:12:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:13:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:14:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:14:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:15:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:16:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:16:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:17:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:18:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:18:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:19:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:20:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:20:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:21:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:22:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:22:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:23:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:24:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:24:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:25:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:26:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:26:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:27:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:28:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:28:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:29:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:30:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:30:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:31:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:32:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:32:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:33:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:34:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:34:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:35:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:36:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:36:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:37:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:38:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:38:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:39:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:40:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:40:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:41:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:42:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:42:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:43:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:44:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:44:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:45:20\n",
      "-------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:46:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:46:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:47:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:48:00\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:48:40\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:49:20\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2024-04-05 17:50:00\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "ssc = StreamingContext(sc, 40)\n",
    "lines = ssc.textFileStream(\"c:/training/words\")\n",
    "words = lines.flatMap(lambda line: line.split(\" \"))\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "wordCounts = pairs.reduceByKey(lambda x, y: x + y)\n",
    "wordCounts.pprint()\n",
    "ssc.start()             # Start the computation\n",
    "ssc.awaitTermination()  # Wait for the computation to terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3718889f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
